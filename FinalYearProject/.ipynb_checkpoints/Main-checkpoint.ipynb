{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b09e7e71-4bd0-4b10-a5f0-6db3f76fc269",
   "metadata": {},
   "source": [
    "# Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8105b0e-f5fc-420e-8890-65b29f0ba1bb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install alpha_vantage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d28813-f656-4b20-ba0e-08fffef6cae8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install mplfinance pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2276bc0f-371b-4e4a-b017-7355d6448b04",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install fastapi uvicorn pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7335ede-2176-4fe6-8d12-e4c6b6466007",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langdetect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2a09800-9073-4bc6-a11a-a39b492dc553",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import requests\n",
    "from datetime import datetime, timedelta\n",
    "import re\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "import torch\n",
    "import os\n",
    "from alpha_vantage.timeseries import TimeSeries\n",
    "import time\n",
    "import mplfinance as mpf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c99692c-1981-46d0-ac93-65f348b7a02c",
   "metadata": {},
   "source": [
    "# Data Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc4db003-6bff-4ea4-b04d-6a959e35c323",
   "metadata": {},
   "source": [
    "## Stock Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d053816-e892-4c45-8182-eb85ab2d5484",
   "metadata": {},
   "source": [
    "### Alpha Vantage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46573ca0-d0a3-4e46-9815-24ff46f63862",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Api Key\n",
    "api = X29K76EJP70V2JGP\n",
    "FOD3B9ESO9W0Y9UE\n",
    "SRKSUHDAW2DL6Y3B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca69f212-5610-45e1-a3a3-35de3385de1a",
   "metadata": {},
   "source": [
    "#### 10 year"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19711c21-5fea-44d9-8798-45e4bdd7e242",
   "metadata": {},
   "source": [
    "Check Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b78edae-ee62-49f0-b213-8449a32f39e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📦 Checking data for AAPL...\n",
      "✅ AAPL 2014-01 data is already complete.\n",
      "✅ AAPL 2014-02 data is already complete.\n",
      "✅ AAPL 2014-03 data is already complete.\n",
      "✅ AAPL 2014-04 data is already complete.\n",
      "✅ AAPL 2014-05 data is already complete.\n",
      "✅ AAPL 2014-06 data is already complete.\n",
      "✅ AAPL 2014-07 data is already complete.\n",
      "✅ AAPL 2014-08 data is already complete.\n",
      "✅ AAPL 2014-09 data is already complete.\n",
      "✅ AAPL 2014-10 data is already complete.\n",
      "✅ AAPL 2014-11 data is already complete.\n",
      "✅ AAPL 2014-12 data is already complete.\n",
      "✅ AAPL 2015-01 data is already complete.\n",
      "✅ AAPL 2015-02 data is already complete.\n",
      "✅ AAPL 2015-03 data is already complete.\n",
      "✅ AAPL 2015-04 data is already complete.\n",
      "✅ AAPL 2015-05 data is already complete.\n",
      "✅ AAPL 2015-06 data is already complete.\n",
      "✅ AAPL 2015-07 data is already complete.\n",
      "✅ AAPL 2015-08 data is already complete.\n",
      "✅ AAPL 2015-09 data is already complete.\n",
      "✅ AAPL 2015-10 data is already complete.\n",
      "✅ AAPL 2015-11 data is already complete.\n",
      "✅ AAPL 2015-12 data is already complete.\n",
      "✅ AAPL 2016-01 data is already complete.\n",
      "✅ AAPL 2016-02 data is already complete.\n",
      "✅ AAPL 2016-03 data is already complete.\n",
      "✅ AAPL 2016-04 data is already complete.\n",
      "✅ AAPL 2016-05 data is already complete.\n",
      "✅ AAPL 2016-06 data is already complete.\n",
      "✅ AAPL 2016-07 data is already complete.\n",
      "✅ AAPL 2016-08 data is already complete.\n",
      "✅ AAPL 2016-09 data is already complete.\n",
      "✅ AAPL 2016-10 data is already complete.\n",
      "✅ AAPL 2016-11 data is already complete.\n",
      "✅ AAPL 2016-12 data is already complete.\n",
      "✅ AAPL 2017-01 data is already complete.\n",
      "✅ AAPL 2017-02 data is already complete.\n",
      "✅ AAPL 2017-03 data is already complete.\n",
      "✅ AAPL 2017-04 data is already complete.\n",
      "✅ AAPL 2017-05 data is already complete.\n",
      "✅ AAPL 2017-06 data is already complete.\n",
      "✅ AAPL 2017-07 data is already complete.\n",
      "✅ AAPL 2017-08 data is already complete.\n",
      "✅ AAPL 2017-09 data is already complete.\n",
      "✅ AAPL 2017-10 data is already complete.\n",
      "✅ AAPL 2017-11 data is already complete.\n",
      "✅ AAPL 2017-12 data is already complete.\n",
      "✅ AAPL 2018-01 data is already complete.\n",
      "✅ AAPL 2018-02 data is already complete.\n",
      "✅ AAPL 2018-03 data is already complete.\n",
      "✅ AAPL 2018-04 data is already complete.\n",
      "✅ AAPL 2018-05 data is already complete.\n",
      "✅ AAPL 2018-06 data is already complete.\n",
      "✅ AAPL 2018-07 data is already complete.\n",
      "✅ AAPL 2018-08 data is already complete.\n",
      "✅ AAPL 2018-09 data is already complete.\n",
      "✅ AAPL 2018-10 data is already complete.\n",
      "✅ AAPL 2018-11 data is already complete.\n",
      "✅ AAPL 2018-12 data is already complete.\n",
      "✅ AAPL 2019-01 data is already complete.\n",
      "✅ AAPL 2019-02 data is already complete.\n",
      "✅ AAPL 2019-03 data is already complete.\n",
      "✅ AAPL 2019-04 data is already complete.\n",
      "✅ AAPL 2019-05 data is already complete.\n",
      "✅ AAPL 2019-06 data is already complete.\n",
      "✅ AAPL 2019-07 data is already complete.\n",
      "✅ AAPL 2019-08 data is already complete.\n",
      "✅ AAPL 2019-09 data is already complete.\n",
      "✅ AAPL 2019-10 data is already complete.\n",
      "✅ AAPL 2019-11 data is already complete.\n",
      "✅ AAPL 2019-12 data is already complete.\n",
      "✅ AAPL 2020-01 data is already complete.\n",
      "✅ AAPL 2020-02 data is already complete.\n",
      "✅ AAPL 2020-03 data is already complete.\n",
      "✅ AAPL 2020-04 data is already complete.\n",
      "✅ AAPL 2020-05 data is already complete.\n",
      "✅ AAPL 2020-06 data is already complete.\n",
      "✅ AAPL 2020-07 data is already complete.\n",
      "✅ AAPL 2020-08 data is already complete.\n",
      "✅ AAPL 2020-09 data is already complete.\n",
      "✅ AAPL 2020-10 data is already complete.\n",
      "✅ AAPL 2020-11 data is already complete.\n",
      "✅ AAPL 2020-12 data is already complete.\n",
      "✅ AAPL 2021-01 data is already complete.\n",
      "✅ AAPL 2021-02 data is already complete.\n",
      "✅ AAPL 2021-03 data is already complete.\n",
      "✅ AAPL 2021-04 data is already complete.\n",
      "✅ AAPL 2021-05 data is already complete.\n",
      "✅ AAPL 2021-06 data is already complete.\n",
      "✅ AAPL 2021-07 data is already complete.\n",
      "✅ AAPL 2021-08 data is already complete.\n",
      "✅ AAPL 2021-09 data is already complete.\n",
      "✅ AAPL 2021-10 data is already complete.\n",
      "✅ AAPL 2021-11 data is already complete.\n",
      "✅ AAPL 2021-12 data is already complete.\n",
      "✅ AAPL 2022-01 data is already complete.\n",
      "✅ AAPL 2022-02 data is already complete.\n",
      "✅ AAPL 2022-03 data is already complete.\n",
      "✅ AAPL 2022-04 data is already complete.\n",
      "✅ AAPL 2022-05 data is already complete.\n",
      "✅ AAPL 2022-06 data is already complete.\n",
      "✅ AAPL 2022-07 data is already complete.\n",
      "✅ AAPL 2022-08 data is already complete.\n",
      "✅ AAPL 2022-09 data is already complete.\n",
      "✅ AAPL 2022-10 data is already complete.\n",
      "✅ AAPL 2022-11 data is already complete.\n",
      "✅ AAPL 2022-12 data is already complete.\n",
      "✅ AAPL 2023-01 data is already complete.\n",
      "✅ AAPL 2023-02 data is already complete.\n",
      "✅ AAPL 2023-03 data is already complete.\n",
      "✅ AAPL 2023-04 data is already complete.\n",
      "✅ AAPL 2023-05 data is already complete.\n",
      "✅ AAPL 2023-06 data is already complete.\n",
      "✅ AAPL 2023-07 data is already complete.\n",
      "✅ AAPL 2023-08 data is already complete.\n",
      "✅ AAPL 2023-09 data is already complete.\n",
      "✅ AAPL 2023-10 data is already complete.\n",
      "✅ AAPL 2023-11 data is already complete.\n",
      "✅ AAPL 2023-12 data is already complete.\n",
      "✅ AAPL 2024-01 data is already complete.\n",
      "✅ AAPL 2024-02 data is already complete.\n",
      "✅ AAPL 2024-03 data is already complete.\n",
      "✅ AAPL 2024-04 data is already complete.\n",
      "✅ AAPL 2024-05 data is already complete.\n",
      "✅ AAPL 2024-06 data is already complete.\n",
      "✅ AAPL 2024-07 data is already complete.\n",
      "✅ AAPL 2024-08 data is already complete.\n",
      "✅ AAPL 2024-09 data is already complete.\n",
      "✅ AAPL 2024-10 data is already complete.\n",
      "✅ AAPL 2024-11 data is already complete.\n",
      "✅ AAPL 2024-12 data is already complete.\n",
      "📊 AAPL months that need to be fetched: []\n",
      "📝 Missing months list saved in AAPL_30min_data\\missing_months_10yr.txt\n",
      "\n",
      "📦 Checking data for MSFT...\n",
      "✅ MSFT 2014-01 data is already complete.\n",
      "✅ MSFT 2014-02 data is already complete.\n",
      "✅ MSFT 2014-03 data is already complete.\n",
      "✅ MSFT 2014-04 data is already complete.\n",
      "✅ MSFT 2014-05 data is already complete.\n",
      "✅ MSFT 2014-06 data is already complete.\n",
      "✅ MSFT 2014-07 data is already complete.\n",
      "✅ MSFT 2014-08 data is already complete.\n",
      "✅ MSFT 2014-09 data is already complete.\n",
      "✅ MSFT 2014-10 data is already complete.\n",
      "✅ MSFT 2014-11 data is already complete.\n",
      "✅ MSFT 2014-12 data is already complete.\n",
      "✅ MSFT 2015-01 data is already complete.\n",
      "✅ MSFT 2015-02 data is already complete.\n",
      "✅ MSFT 2015-03 data is already complete.\n",
      "✅ MSFT 2015-04 data is already complete.\n",
      "✅ MSFT 2015-05 data is already complete.\n",
      "✅ MSFT 2015-06 data is already complete.\n",
      "✅ MSFT 2015-07 data is already complete.\n",
      "✅ MSFT 2015-08 data is already complete.\n",
      "✅ MSFT 2015-09 data is already complete.\n",
      "✅ MSFT 2015-10 data is already complete.\n",
      "✅ MSFT 2015-11 data is already complete.\n",
      "✅ MSFT 2015-12 data is already complete.\n",
      "✅ MSFT 2016-01 data is already complete.\n",
      "✅ MSFT 2016-02 data is already complete.\n",
      "✅ MSFT 2016-03 data is already complete.\n",
      "✅ MSFT 2016-04 data is already complete.\n",
      "✅ MSFT 2016-05 data is already complete.\n",
      "✅ MSFT 2016-06 data is already complete.\n",
      "✅ MSFT 2016-07 data is already complete.\n",
      "✅ MSFT 2016-08 data is already complete.\n",
      "✅ MSFT 2016-09 data is already complete.\n",
      "✅ MSFT 2016-10 data is already complete.\n",
      "✅ MSFT 2016-11 data is already complete.\n",
      "✅ MSFT 2016-12 data is already complete.\n",
      "✅ MSFT 2017-01 data is already complete.\n",
      "✅ MSFT 2017-02 data is already complete.\n",
      "✅ MSFT 2017-03 data is already complete.\n",
      "✅ MSFT 2017-04 data is already complete.\n",
      "✅ MSFT 2017-05 data is already complete.\n",
      "✅ MSFT 2017-06 data is already complete.\n",
      "✅ MSFT 2017-07 data is already complete.\n",
      "✅ MSFT 2017-08 data is already complete.\n",
      "✅ MSFT 2017-09 data is already complete.\n",
      "✅ MSFT 2017-10 data is already complete.\n",
      "✅ MSFT 2017-11 data is already complete.\n",
      "✅ MSFT 2017-12 data is already complete.\n",
      "❌ MSFT 2018-01 data is missing.\n",
      "❌ MSFT 2018-02 data is missing.\n",
      "❌ MSFT 2018-03 data is missing.\n",
      "❌ MSFT 2018-04 data is missing.\n",
      "❌ MSFT 2018-05 data is missing.\n",
      "❌ MSFT 2018-06 data is missing.\n",
      "❌ MSFT 2018-07 data is missing.\n",
      "❌ MSFT 2018-08 data is missing.\n",
      "❌ MSFT 2018-09 data is missing.\n",
      "❌ MSFT 2018-10 data is missing.\n",
      "❌ MSFT 2018-11 data is missing.\n",
      "❌ MSFT 2018-12 data is missing.\n",
      "❌ MSFT 2019-01 data is missing.\n",
      "❌ MSFT 2019-02 data is missing.\n",
      "❌ MSFT 2019-03 data is missing.\n",
      "❌ MSFT 2019-04 data is missing.\n",
      "❌ MSFT 2019-05 data is missing.\n",
      "❌ MSFT 2019-06 data is missing.\n",
      "❌ MSFT 2019-07 data is missing.\n",
      "❌ MSFT 2019-08 data is missing.\n",
      "❌ MSFT 2019-09 data is missing.\n",
      "❌ MSFT 2019-10 data is missing.\n",
      "❌ MSFT 2019-11 data is missing.\n",
      "❌ MSFT 2019-12 data is missing.\n",
      "❌ MSFT 2020-01 data is missing.\n",
      "❌ MSFT 2020-02 data is missing.\n",
      "❌ MSFT 2020-03 data is missing.\n",
      "❌ MSFT 2020-04 data is missing.\n",
      "❌ MSFT 2020-05 data is missing.\n",
      "❌ MSFT 2020-06 data is missing.\n",
      "❌ MSFT 2020-07 data is missing.\n",
      "❌ MSFT 2020-08 data is missing.\n",
      "❌ MSFT 2020-09 data is missing.\n",
      "❌ MSFT 2020-10 data is missing.\n",
      "❌ MSFT 2020-11 data is missing.\n",
      "❌ MSFT 2020-12 data is missing.\n",
      "❌ MSFT 2021-01 data is missing.\n",
      "❌ MSFT 2021-02 data is missing.\n",
      "❌ MSFT 2021-03 data is missing.\n",
      "❌ MSFT 2021-04 data is missing.\n",
      "❌ MSFT 2021-05 data is missing.\n",
      "❌ MSFT 2021-06 data is missing.\n",
      "❌ MSFT 2021-07 data is missing.\n",
      "❌ MSFT 2021-08 data is missing.\n",
      "❌ MSFT 2021-09 data is missing.\n",
      "❌ MSFT 2021-10 data is missing.\n",
      "❌ MSFT 2021-11 data is missing.\n",
      "❌ MSFT 2021-12 data is missing.\n",
      "❌ MSFT 2022-01 data is missing.\n",
      "❌ MSFT 2022-02 data is missing.\n",
      "❌ MSFT 2022-03 data is missing.\n",
      "❌ MSFT 2022-04 data is missing.\n",
      "❌ MSFT 2022-05 data is missing.\n",
      "❌ MSFT 2022-06 data is missing.\n",
      "❌ MSFT 2022-07 data is missing.\n",
      "❌ MSFT 2022-08 data is missing.\n",
      "❌ MSFT 2022-09 data is missing.\n",
      "❌ MSFT 2022-10 data is missing.\n",
      "❌ MSFT 2022-11 data is missing.\n",
      "❌ MSFT 2022-12 data is missing.\n",
      "❌ MSFT 2023-01 data is missing.\n",
      "❌ MSFT 2023-02 data is missing.\n",
      "❌ MSFT 2023-03 data is missing.\n",
      "❌ MSFT 2023-04 data is missing.\n",
      "❌ MSFT 2023-05 data is missing.\n",
      "❌ MSFT 2023-06 data is missing.\n",
      "❌ MSFT 2023-07 data is missing.\n",
      "❌ MSFT 2023-08 data is missing.\n",
      "❌ MSFT 2023-09 data is missing.\n",
      "❌ MSFT 2023-10 data is missing.\n",
      "❌ MSFT 2023-11 data is missing.\n",
      "❌ MSFT 2023-12 data is missing.\n",
      "❌ MSFT 2024-01 data is missing.\n",
      "❌ MSFT 2024-02 data is missing.\n",
      "❌ MSFT 2024-03 data is missing.\n",
      "❌ MSFT 2024-04 data is missing.\n",
      "❌ MSFT 2024-05 data is missing.\n",
      "❌ MSFT 2024-06 data is missing.\n",
      "❌ MSFT 2024-07 data is missing.\n",
      "❌ MSFT 2024-08 data is missing.\n",
      "❌ MSFT 2024-09 data is missing.\n",
      "❌ MSFT 2024-10 data is missing.\n",
      "❌ MSFT 2024-11 data is missing.\n",
      "❌ MSFT 2024-12 data is missing.\n",
      "📊 MSFT months that need to be fetched: ['2018-01', '2018-02', '2018-03', '2018-04', '2018-05', '2018-06', '2018-07', '2018-08', '2018-09', '2018-10', '2018-11', '2018-12', '2019-01', '2019-02', '2019-03', '2019-04', '2019-05', '2019-06', '2019-07', '2019-08', '2019-09', '2019-10', '2019-11', '2019-12', '2020-01', '2020-02', '2020-03', '2020-04', '2020-05', '2020-06', '2020-07', '2020-08', '2020-09', '2020-10', '2020-11', '2020-12', '2021-01', '2021-02', '2021-03', '2021-04', '2021-05', '2021-06', '2021-07', '2021-08', '2021-09', '2021-10', '2021-11', '2021-12', '2022-01', '2022-02', '2022-03', '2022-04', '2022-05', '2022-06', '2022-07', '2022-08', '2022-09', '2022-10', '2022-11', '2022-12', '2023-01', '2023-02', '2023-03', '2023-04', '2023-05', '2023-06', '2023-07', '2023-08', '2023-09', '2023-10', '2023-11', '2023-12', '2024-01', '2024-02', '2024-03', '2024-04', '2024-05', '2024-06', '2024-07', '2024-08', '2024-09', '2024-10', '2024-11', '2024-12']\n",
      "📝 Missing months list saved in MSFT_30min_data\\missing_months_10yr.txt\n",
      "\n",
      "📦 Checking data for NVDA...\n",
      "❌ NVDA 2014-01 data is missing.\n",
      "❌ NVDA 2014-02 data is missing.\n",
      "❌ NVDA 2014-03 data is missing.\n",
      "❌ NVDA 2014-04 data is missing.\n",
      "❌ NVDA 2014-05 data is missing.\n",
      "❌ NVDA 2014-06 data is missing.\n",
      "❌ NVDA 2014-07 data is missing.\n",
      "❌ NVDA 2014-08 data is missing.\n",
      "❌ NVDA 2014-09 data is missing.\n",
      "❌ NVDA 2014-10 data is missing.\n",
      "❌ NVDA 2014-11 data is missing.\n",
      "❌ NVDA 2014-12 data is missing.\n",
      "❌ NVDA 2015-01 data is missing.\n",
      "❌ NVDA 2015-02 data is missing.\n",
      "❌ NVDA 2015-03 data is missing.\n",
      "❌ NVDA 2015-04 data is missing.\n",
      "❌ NVDA 2015-05 data is missing.\n",
      "❌ NVDA 2015-06 data is missing.\n",
      "❌ NVDA 2015-07 data is missing.\n",
      "❌ NVDA 2015-08 data is missing.\n",
      "❌ NVDA 2015-09 data is missing.\n",
      "❌ NVDA 2015-10 data is missing.\n",
      "❌ NVDA 2015-11 data is missing.\n",
      "❌ NVDA 2015-12 data is missing.\n",
      "❌ NVDA 2016-01 data is missing.\n",
      "❌ NVDA 2016-02 data is missing.\n",
      "❌ NVDA 2016-03 data is missing.\n",
      "❌ NVDA 2016-04 data is missing.\n",
      "❌ NVDA 2016-05 data is missing.\n",
      "❌ NVDA 2016-06 data is missing.\n",
      "❌ NVDA 2016-07 data is missing.\n",
      "❌ NVDA 2016-08 data is missing.\n",
      "❌ NVDA 2016-09 data is missing.\n",
      "❌ NVDA 2016-10 data is missing.\n",
      "❌ NVDA 2016-11 data is missing.\n",
      "❌ NVDA 2016-12 data is missing.\n",
      "❌ NVDA 2017-01 data is missing.\n",
      "❌ NVDA 2017-02 data is missing.\n",
      "❌ NVDA 2017-03 data is missing.\n",
      "❌ NVDA 2017-04 data is missing.\n",
      "❌ NVDA 2017-05 data is missing.\n",
      "❌ NVDA 2017-06 data is missing.\n",
      "❌ NVDA 2017-07 data is missing.\n",
      "❌ NVDA 2017-08 data is missing.\n",
      "❌ NVDA 2017-09 data is missing.\n",
      "❌ NVDA 2017-10 data is missing.\n",
      "❌ NVDA 2017-11 data is missing.\n",
      "❌ NVDA 2017-12 data is missing.\n",
      "❌ NVDA 2018-01 data is missing.\n",
      "❌ NVDA 2018-02 data is missing.\n",
      "❌ NVDA 2018-03 data is missing.\n",
      "❌ NVDA 2018-04 data is missing.\n",
      "❌ NVDA 2018-05 data is missing.\n",
      "❌ NVDA 2018-06 data is missing.\n",
      "❌ NVDA 2018-07 data is missing.\n",
      "❌ NVDA 2018-08 data is missing.\n",
      "❌ NVDA 2018-09 data is missing.\n",
      "❌ NVDA 2018-10 data is missing.\n",
      "❌ NVDA 2018-11 data is missing.\n",
      "❌ NVDA 2018-12 data is missing.\n",
      "❌ NVDA 2019-01 data is missing.\n",
      "❌ NVDA 2019-02 data is missing.\n",
      "❌ NVDA 2019-03 data is missing.\n",
      "❌ NVDA 2019-04 data is missing.\n",
      "❌ NVDA 2019-05 data is missing.\n",
      "❌ NVDA 2019-06 data is missing.\n",
      "❌ NVDA 2019-07 data is missing.\n",
      "❌ NVDA 2019-08 data is missing.\n",
      "❌ NVDA 2019-09 data is missing.\n",
      "❌ NVDA 2019-10 data is missing.\n",
      "❌ NVDA 2019-11 data is missing.\n",
      "❌ NVDA 2019-12 data is missing.\n",
      "❌ NVDA 2020-01 data is missing.\n",
      "❌ NVDA 2020-02 data is missing.\n",
      "❌ NVDA 2020-03 data is missing.\n",
      "❌ NVDA 2020-04 data is missing.\n",
      "❌ NVDA 2020-05 data is missing.\n",
      "❌ NVDA 2020-06 data is missing.\n",
      "❌ NVDA 2020-07 data is missing.\n",
      "❌ NVDA 2020-08 data is missing.\n",
      "❌ NVDA 2020-09 data is missing.\n",
      "❌ NVDA 2020-10 data is missing.\n",
      "❌ NVDA 2020-11 data is missing.\n",
      "❌ NVDA 2020-12 data is missing.\n",
      "❌ NVDA 2021-01 data is missing.\n",
      "❌ NVDA 2021-02 data is missing.\n",
      "❌ NVDA 2021-03 data is missing.\n",
      "❌ NVDA 2021-04 data is missing.\n",
      "❌ NVDA 2021-05 data is missing.\n",
      "❌ NVDA 2021-06 data is missing.\n",
      "❌ NVDA 2021-07 data is missing.\n",
      "❌ NVDA 2021-08 data is missing.\n",
      "❌ NVDA 2021-09 data is missing.\n",
      "❌ NVDA 2021-10 data is missing.\n",
      "❌ NVDA 2021-11 data is missing.\n",
      "❌ NVDA 2021-12 data is missing.\n",
      "❌ NVDA 2022-01 data is missing.\n",
      "❌ NVDA 2022-02 data is missing.\n",
      "❌ NVDA 2022-03 data is missing.\n",
      "❌ NVDA 2022-04 data is missing.\n",
      "❌ NVDA 2022-05 data is missing.\n",
      "❌ NVDA 2022-06 data is missing.\n",
      "❌ NVDA 2022-07 data is missing.\n",
      "❌ NVDA 2022-08 data is missing.\n",
      "❌ NVDA 2022-09 data is missing.\n",
      "❌ NVDA 2022-10 data is missing.\n",
      "❌ NVDA 2022-11 data is missing.\n",
      "❌ NVDA 2022-12 data is missing.\n",
      "❌ NVDA 2023-01 data is missing.\n",
      "❌ NVDA 2023-02 data is missing.\n",
      "❌ NVDA 2023-03 data is missing.\n",
      "❌ NVDA 2023-04 data is missing.\n",
      "❌ NVDA 2023-05 data is missing.\n",
      "❌ NVDA 2023-06 data is missing.\n",
      "❌ NVDA 2023-07 data is missing.\n",
      "❌ NVDA 2023-08 data is missing.\n",
      "❌ NVDA 2023-09 data is missing.\n",
      "❌ NVDA 2023-10 data is missing.\n",
      "❌ NVDA 2023-11 data is missing.\n",
      "❌ NVDA 2023-12 data is missing.\n",
      "❌ NVDA 2024-01 data is missing.\n",
      "❌ NVDA 2024-02 data is missing.\n",
      "❌ NVDA 2024-03 data is missing.\n",
      "❌ NVDA 2024-04 data is missing.\n",
      "❌ NVDA 2024-05 data is missing.\n",
      "❌ NVDA 2024-06 data is missing.\n",
      "❌ NVDA 2024-07 data is missing.\n",
      "❌ NVDA 2024-08 data is missing.\n",
      "❌ NVDA 2024-09 data is missing.\n",
      "❌ NVDA 2024-10 data is missing.\n",
      "❌ NVDA 2024-11 data is missing.\n",
      "❌ NVDA 2024-12 data is missing.\n",
      "📊 NVDA months that need to be fetched: ['2014-01', '2014-02', '2014-03', '2014-04', '2014-05', '2014-06', '2014-07', '2014-08', '2014-09', '2014-10', '2014-11', '2014-12', '2015-01', '2015-02', '2015-03', '2015-04', '2015-05', '2015-06', '2015-07', '2015-08', '2015-09', '2015-10', '2015-11', '2015-12', '2016-01', '2016-02', '2016-03', '2016-04', '2016-05', '2016-06', '2016-07', '2016-08', '2016-09', '2016-10', '2016-11', '2016-12', '2017-01', '2017-02', '2017-03', '2017-04', '2017-05', '2017-06', '2017-07', '2017-08', '2017-09', '2017-10', '2017-11', '2017-12', '2018-01', '2018-02', '2018-03', '2018-04', '2018-05', '2018-06', '2018-07', '2018-08', '2018-09', '2018-10', '2018-11', '2018-12', '2019-01', '2019-02', '2019-03', '2019-04', '2019-05', '2019-06', '2019-07', '2019-08', '2019-09', '2019-10', '2019-11', '2019-12', '2020-01', '2020-02', '2020-03', '2020-04', '2020-05', '2020-06', '2020-07', '2020-08', '2020-09', '2020-10', '2020-11', '2020-12', '2021-01', '2021-02', '2021-03', '2021-04', '2021-05', '2021-06', '2021-07', '2021-08', '2021-09', '2021-10', '2021-11', '2021-12', '2022-01', '2022-02', '2022-03', '2022-04', '2022-05', '2022-06', '2022-07', '2022-08', '2022-09', '2022-10', '2022-11', '2022-12', '2023-01', '2023-02', '2023-03', '2023-04', '2023-05', '2023-06', '2023-07', '2023-08', '2023-09', '2023-10', '2023-11', '2023-12', '2024-01', '2024-02', '2024-03', '2024-04', '2024-05', '2024-06', '2024-07', '2024-08', '2024-09', '2024-10', '2024-11', '2024-12']\n",
      "📝 Missing months list saved in NVDA_30min_data\\missing_months_10yr.txt\n",
      "\n",
      "📦 Checking data for AMZN...\n",
      "❌ AMZN 2014-01 data is missing.\n",
      "❌ AMZN 2014-02 data is missing.\n",
      "❌ AMZN 2014-03 data is missing.\n",
      "❌ AMZN 2014-04 data is missing.\n",
      "❌ AMZN 2014-05 data is missing.\n",
      "❌ AMZN 2014-06 data is missing.\n",
      "❌ AMZN 2014-07 data is missing.\n",
      "❌ AMZN 2014-08 data is missing.\n",
      "❌ AMZN 2014-09 data is missing.\n",
      "❌ AMZN 2014-10 data is missing.\n",
      "❌ AMZN 2014-11 data is missing.\n",
      "❌ AMZN 2014-12 data is missing.\n",
      "❌ AMZN 2015-01 data is missing.\n",
      "❌ AMZN 2015-02 data is missing.\n",
      "❌ AMZN 2015-03 data is missing.\n",
      "❌ AMZN 2015-04 data is missing.\n",
      "❌ AMZN 2015-05 data is missing.\n",
      "❌ AMZN 2015-06 data is missing.\n",
      "❌ AMZN 2015-07 data is missing.\n",
      "❌ AMZN 2015-08 data is missing.\n",
      "❌ AMZN 2015-09 data is missing.\n",
      "❌ AMZN 2015-10 data is missing.\n",
      "❌ AMZN 2015-11 data is missing.\n",
      "❌ AMZN 2015-12 data is missing.\n",
      "❌ AMZN 2016-01 data is missing.\n",
      "❌ AMZN 2016-02 data is missing.\n",
      "❌ AMZN 2016-03 data is missing.\n",
      "❌ AMZN 2016-04 data is missing.\n",
      "❌ AMZN 2016-05 data is missing.\n",
      "❌ AMZN 2016-06 data is missing.\n",
      "❌ AMZN 2016-07 data is missing.\n",
      "❌ AMZN 2016-08 data is missing.\n",
      "❌ AMZN 2016-09 data is missing.\n",
      "❌ AMZN 2016-10 data is missing.\n",
      "❌ AMZN 2016-11 data is missing.\n",
      "❌ AMZN 2016-12 data is missing.\n",
      "❌ AMZN 2017-01 data is missing.\n",
      "❌ AMZN 2017-02 data is missing.\n",
      "❌ AMZN 2017-03 data is missing.\n",
      "❌ AMZN 2017-04 data is missing.\n",
      "❌ AMZN 2017-05 data is missing.\n",
      "❌ AMZN 2017-06 data is missing.\n",
      "❌ AMZN 2017-07 data is missing.\n",
      "❌ AMZN 2017-08 data is missing.\n",
      "❌ AMZN 2017-09 data is missing.\n",
      "❌ AMZN 2017-10 data is missing.\n",
      "❌ AMZN 2017-11 data is missing.\n",
      "❌ AMZN 2017-12 data is missing.\n",
      "❌ AMZN 2018-01 data is missing.\n",
      "❌ AMZN 2018-02 data is missing.\n",
      "❌ AMZN 2018-03 data is missing.\n",
      "❌ AMZN 2018-04 data is missing.\n",
      "❌ AMZN 2018-05 data is missing.\n",
      "❌ AMZN 2018-06 data is missing.\n",
      "❌ AMZN 2018-07 data is missing.\n",
      "❌ AMZN 2018-08 data is missing.\n",
      "❌ AMZN 2018-09 data is missing.\n",
      "❌ AMZN 2018-10 data is missing.\n",
      "❌ AMZN 2018-11 data is missing.\n",
      "❌ AMZN 2018-12 data is missing.\n",
      "❌ AMZN 2019-01 data is missing.\n",
      "❌ AMZN 2019-02 data is missing.\n",
      "❌ AMZN 2019-03 data is missing.\n",
      "❌ AMZN 2019-04 data is missing.\n",
      "❌ AMZN 2019-05 data is missing.\n",
      "❌ AMZN 2019-06 data is missing.\n",
      "❌ AMZN 2019-07 data is missing.\n",
      "❌ AMZN 2019-08 data is missing.\n",
      "❌ AMZN 2019-09 data is missing.\n",
      "❌ AMZN 2019-10 data is missing.\n",
      "❌ AMZN 2019-11 data is missing.\n",
      "❌ AMZN 2019-12 data is missing.\n",
      "❌ AMZN 2020-01 data is missing.\n",
      "❌ AMZN 2020-02 data is missing.\n",
      "❌ AMZN 2020-03 data is missing.\n",
      "❌ AMZN 2020-04 data is missing.\n",
      "❌ AMZN 2020-05 data is missing.\n",
      "❌ AMZN 2020-06 data is missing.\n",
      "❌ AMZN 2020-07 data is missing.\n",
      "❌ AMZN 2020-08 data is missing.\n",
      "❌ AMZN 2020-09 data is missing.\n",
      "❌ AMZN 2020-10 data is missing.\n",
      "❌ AMZN 2020-11 data is missing.\n",
      "❌ AMZN 2020-12 data is missing.\n",
      "❌ AMZN 2021-01 data is missing.\n",
      "❌ AMZN 2021-02 data is missing.\n",
      "❌ AMZN 2021-03 data is missing.\n",
      "❌ AMZN 2021-04 data is missing.\n",
      "❌ AMZN 2021-05 data is missing.\n",
      "❌ AMZN 2021-06 data is missing.\n",
      "❌ AMZN 2021-07 data is missing.\n",
      "❌ AMZN 2021-08 data is missing.\n",
      "❌ AMZN 2021-09 data is missing.\n",
      "❌ AMZN 2021-10 data is missing.\n",
      "❌ AMZN 2021-11 data is missing.\n",
      "❌ AMZN 2021-12 data is missing.\n",
      "❌ AMZN 2022-01 data is missing.\n",
      "❌ AMZN 2022-02 data is missing.\n",
      "❌ AMZN 2022-03 data is missing.\n",
      "❌ AMZN 2022-04 data is missing.\n",
      "❌ AMZN 2022-05 data is missing.\n",
      "❌ AMZN 2022-06 data is missing.\n",
      "❌ AMZN 2022-07 data is missing.\n",
      "❌ AMZN 2022-08 data is missing.\n",
      "❌ AMZN 2022-09 data is missing.\n",
      "❌ AMZN 2022-10 data is missing.\n",
      "❌ AMZN 2022-11 data is missing.\n",
      "❌ AMZN 2022-12 data is missing.\n",
      "❌ AMZN 2023-01 data is missing.\n",
      "❌ AMZN 2023-02 data is missing.\n",
      "❌ AMZN 2023-03 data is missing.\n",
      "❌ AMZN 2023-04 data is missing.\n",
      "❌ AMZN 2023-05 data is missing.\n",
      "❌ AMZN 2023-06 data is missing.\n",
      "❌ AMZN 2023-07 data is missing.\n",
      "❌ AMZN 2023-08 data is missing.\n",
      "❌ AMZN 2023-09 data is missing.\n",
      "❌ AMZN 2023-10 data is missing.\n",
      "❌ AMZN 2023-11 data is missing.\n",
      "❌ AMZN 2023-12 data is missing.\n",
      "❌ AMZN 2024-01 data is missing.\n",
      "❌ AMZN 2024-02 data is missing.\n",
      "❌ AMZN 2024-03 data is missing.\n",
      "❌ AMZN 2024-04 data is missing.\n",
      "❌ AMZN 2024-05 data is missing.\n",
      "❌ AMZN 2024-06 data is missing.\n",
      "❌ AMZN 2024-07 data is missing.\n",
      "❌ AMZN 2024-08 data is missing.\n",
      "❌ AMZN 2024-09 data is missing.\n",
      "❌ AMZN 2024-10 data is missing.\n",
      "❌ AMZN 2024-11 data is missing.\n",
      "❌ AMZN 2024-12 data is missing.\n",
      "📊 AMZN months that need to be fetched: ['2014-01', '2014-02', '2014-03', '2014-04', '2014-05', '2014-06', '2014-07', '2014-08', '2014-09', '2014-10', '2014-11', '2014-12', '2015-01', '2015-02', '2015-03', '2015-04', '2015-05', '2015-06', '2015-07', '2015-08', '2015-09', '2015-10', '2015-11', '2015-12', '2016-01', '2016-02', '2016-03', '2016-04', '2016-05', '2016-06', '2016-07', '2016-08', '2016-09', '2016-10', '2016-11', '2016-12', '2017-01', '2017-02', '2017-03', '2017-04', '2017-05', '2017-06', '2017-07', '2017-08', '2017-09', '2017-10', '2017-11', '2017-12', '2018-01', '2018-02', '2018-03', '2018-04', '2018-05', '2018-06', '2018-07', '2018-08', '2018-09', '2018-10', '2018-11', '2018-12', '2019-01', '2019-02', '2019-03', '2019-04', '2019-05', '2019-06', '2019-07', '2019-08', '2019-09', '2019-10', '2019-11', '2019-12', '2020-01', '2020-02', '2020-03', '2020-04', '2020-05', '2020-06', '2020-07', '2020-08', '2020-09', '2020-10', '2020-11', '2020-12', '2021-01', '2021-02', '2021-03', '2021-04', '2021-05', '2021-06', '2021-07', '2021-08', '2021-09', '2021-10', '2021-11', '2021-12', '2022-01', '2022-02', '2022-03', '2022-04', '2022-05', '2022-06', '2022-07', '2022-08', '2022-09', '2022-10', '2022-11', '2022-12', '2023-01', '2023-02', '2023-03', '2023-04', '2023-05', '2023-06', '2023-07', '2023-08', '2023-09', '2023-10', '2023-11', '2023-12', '2024-01', '2024-02', '2024-03', '2024-04', '2024-05', '2024-06', '2024-07', '2024-08', '2024-09', '2024-10', '2024-11', '2024-12']\n",
      "📝 Missing months list saved in AMZN_30min_data\\missing_months_10yr.txt\n",
      "\n",
      "📦 Checking data for GOOGL...\n",
      "❌ GOOGL 2014-01 data is missing.\n",
      "❌ GOOGL 2014-02 data is missing.\n",
      "❌ GOOGL 2014-03 data is missing.\n",
      "❌ GOOGL 2014-04 data is missing.\n",
      "❌ GOOGL 2014-05 data is missing.\n",
      "❌ GOOGL 2014-06 data is missing.\n",
      "❌ GOOGL 2014-07 data is missing.\n",
      "❌ GOOGL 2014-08 data is missing.\n",
      "❌ GOOGL 2014-09 data is missing.\n",
      "❌ GOOGL 2014-10 data is missing.\n",
      "❌ GOOGL 2014-11 data is missing.\n",
      "❌ GOOGL 2014-12 data is missing.\n",
      "❌ GOOGL 2015-01 data is missing.\n",
      "❌ GOOGL 2015-02 data is missing.\n",
      "❌ GOOGL 2015-03 data is missing.\n",
      "❌ GOOGL 2015-04 data is missing.\n",
      "❌ GOOGL 2015-05 data is missing.\n",
      "❌ GOOGL 2015-06 data is missing.\n",
      "❌ GOOGL 2015-07 data is missing.\n",
      "❌ GOOGL 2015-08 data is missing.\n",
      "❌ GOOGL 2015-09 data is missing.\n",
      "❌ GOOGL 2015-10 data is missing.\n",
      "❌ GOOGL 2015-11 data is missing.\n",
      "❌ GOOGL 2015-12 data is missing.\n",
      "❌ GOOGL 2016-01 data is missing.\n",
      "❌ GOOGL 2016-02 data is missing.\n",
      "❌ GOOGL 2016-03 data is missing.\n",
      "❌ GOOGL 2016-04 data is missing.\n",
      "❌ GOOGL 2016-05 data is missing.\n",
      "❌ GOOGL 2016-06 data is missing.\n",
      "❌ GOOGL 2016-07 data is missing.\n",
      "❌ GOOGL 2016-08 data is missing.\n",
      "❌ GOOGL 2016-09 data is missing.\n",
      "❌ GOOGL 2016-10 data is missing.\n",
      "❌ GOOGL 2016-11 data is missing.\n",
      "❌ GOOGL 2016-12 data is missing.\n",
      "❌ GOOGL 2017-01 data is missing.\n",
      "❌ GOOGL 2017-02 data is missing.\n",
      "❌ GOOGL 2017-03 data is missing.\n",
      "❌ GOOGL 2017-04 data is missing.\n",
      "❌ GOOGL 2017-05 data is missing.\n",
      "❌ GOOGL 2017-06 data is missing.\n",
      "❌ GOOGL 2017-07 data is missing.\n",
      "❌ GOOGL 2017-08 data is missing.\n",
      "❌ GOOGL 2017-09 data is missing.\n",
      "❌ GOOGL 2017-10 data is missing.\n",
      "❌ GOOGL 2017-11 data is missing.\n",
      "❌ GOOGL 2017-12 data is missing.\n",
      "❌ GOOGL 2018-01 data is missing.\n",
      "❌ GOOGL 2018-02 data is missing.\n",
      "❌ GOOGL 2018-03 data is missing.\n",
      "❌ GOOGL 2018-04 data is missing.\n",
      "❌ GOOGL 2018-05 data is missing.\n",
      "❌ GOOGL 2018-06 data is missing.\n",
      "❌ GOOGL 2018-07 data is missing.\n",
      "❌ GOOGL 2018-08 data is missing.\n",
      "❌ GOOGL 2018-09 data is missing.\n",
      "❌ GOOGL 2018-10 data is missing.\n",
      "❌ GOOGL 2018-11 data is missing.\n",
      "❌ GOOGL 2018-12 data is missing.\n",
      "❌ GOOGL 2019-01 data is missing.\n",
      "❌ GOOGL 2019-02 data is missing.\n",
      "❌ GOOGL 2019-03 data is missing.\n",
      "❌ GOOGL 2019-04 data is missing.\n",
      "❌ GOOGL 2019-05 data is missing.\n",
      "❌ GOOGL 2019-06 data is missing.\n",
      "❌ GOOGL 2019-07 data is missing.\n",
      "❌ GOOGL 2019-08 data is missing.\n",
      "❌ GOOGL 2019-09 data is missing.\n",
      "❌ GOOGL 2019-10 data is missing.\n",
      "❌ GOOGL 2019-11 data is missing.\n",
      "❌ GOOGL 2019-12 data is missing.\n",
      "❌ GOOGL 2020-01 data is missing.\n",
      "❌ GOOGL 2020-02 data is missing.\n",
      "❌ GOOGL 2020-03 data is missing.\n",
      "❌ GOOGL 2020-04 data is missing.\n",
      "❌ GOOGL 2020-05 data is missing.\n",
      "❌ GOOGL 2020-06 data is missing.\n",
      "❌ GOOGL 2020-07 data is missing.\n",
      "❌ GOOGL 2020-08 data is missing.\n",
      "❌ GOOGL 2020-09 data is missing.\n",
      "❌ GOOGL 2020-10 data is missing.\n",
      "❌ GOOGL 2020-11 data is missing.\n",
      "❌ GOOGL 2020-12 data is missing.\n",
      "❌ GOOGL 2021-01 data is missing.\n",
      "❌ GOOGL 2021-02 data is missing.\n",
      "❌ GOOGL 2021-03 data is missing.\n",
      "❌ GOOGL 2021-04 data is missing.\n",
      "❌ GOOGL 2021-05 data is missing.\n",
      "❌ GOOGL 2021-06 data is missing.\n",
      "❌ GOOGL 2021-07 data is missing.\n",
      "❌ GOOGL 2021-08 data is missing.\n",
      "❌ GOOGL 2021-09 data is missing.\n",
      "❌ GOOGL 2021-10 data is missing.\n",
      "❌ GOOGL 2021-11 data is missing.\n",
      "❌ GOOGL 2021-12 data is missing.\n",
      "❌ GOOGL 2022-01 data is missing.\n",
      "❌ GOOGL 2022-02 data is missing.\n",
      "❌ GOOGL 2022-03 data is missing.\n",
      "❌ GOOGL 2022-04 data is missing.\n",
      "❌ GOOGL 2022-05 data is missing.\n",
      "❌ GOOGL 2022-06 data is missing.\n",
      "❌ GOOGL 2022-07 data is missing.\n",
      "❌ GOOGL 2022-08 data is missing.\n",
      "❌ GOOGL 2022-09 data is missing.\n",
      "❌ GOOGL 2022-10 data is missing.\n",
      "❌ GOOGL 2022-11 data is missing.\n",
      "❌ GOOGL 2022-12 data is missing.\n",
      "❌ GOOGL 2023-01 data is missing.\n",
      "❌ GOOGL 2023-02 data is missing.\n",
      "❌ GOOGL 2023-03 data is missing.\n",
      "❌ GOOGL 2023-04 data is missing.\n",
      "❌ GOOGL 2023-05 data is missing.\n",
      "❌ GOOGL 2023-06 data is missing.\n",
      "❌ GOOGL 2023-07 data is missing.\n",
      "❌ GOOGL 2023-08 data is missing.\n",
      "❌ GOOGL 2023-09 data is missing.\n",
      "❌ GOOGL 2023-10 data is missing.\n",
      "❌ GOOGL 2023-11 data is missing.\n",
      "❌ GOOGL 2023-12 data is missing.\n",
      "❌ GOOGL 2024-01 data is missing.\n",
      "❌ GOOGL 2024-02 data is missing.\n",
      "❌ GOOGL 2024-03 data is missing.\n",
      "❌ GOOGL 2024-04 data is missing.\n",
      "❌ GOOGL 2024-05 data is missing.\n",
      "❌ GOOGL 2024-06 data is missing.\n",
      "❌ GOOGL 2024-07 data is missing.\n",
      "❌ GOOGL 2024-08 data is missing.\n",
      "❌ GOOGL 2024-09 data is missing.\n",
      "❌ GOOGL 2024-10 data is missing.\n",
      "❌ GOOGL 2024-11 data is missing.\n",
      "❌ GOOGL 2024-12 data is missing.\n",
      "📊 GOOGL months that need to be fetched: ['2014-01', '2014-02', '2014-03', '2014-04', '2014-05', '2014-06', '2014-07', '2014-08', '2014-09', '2014-10', '2014-11', '2014-12', '2015-01', '2015-02', '2015-03', '2015-04', '2015-05', '2015-06', '2015-07', '2015-08', '2015-09', '2015-10', '2015-11', '2015-12', '2016-01', '2016-02', '2016-03', '2016-04', '2016-05', '2016-06', '2016-07', '2016-08', '2016-09', '2016-10', '2016-11', '2016-12', '2017-01', '2017-02', '2017-03', '2017-04', '2017-05', '2017-06', '2017-07', '2017-08', '2017-09', '2017-10', '2017-11', '2017-12', '2018-01', '2018-02', '2018-03', '2018-04', '2018-05', '2018-06', '2018-07', '2018-08', '2018-09', '2018-10', '2018-11', '2018-12', '2019-01', '2019-02', '2019-03', '2019-04', '2019-05', '2019-06', '2019-07', '2019-08', '2019-09', '2019-10', '2019-11', '2019-12', '2020-01', '2020-02', '2020-03', '2020-04', '2020-05', '2020-06', '2020-07', '2020-08', '2020-09', '2020-10', '2020-11', '2020-12', '2021-01', '2021-02', '2021-03', '2021-04', '2021-05', '2021-06', '2021-07', '2021-08', '2021-09', '2021-10', '2021-11', '2021-12', '2022-01', '2022-02', '2022-03', '2022-04', '2022-05', '2022-06', '2022-07', '2022-08', '2022-09', '2022-10', '2022-11', '2022-12', '2023-01', '2023-02', '2023-03', '2023-04', '2023-05', '2023-06', '2023-07', '2023-08', '2023-09', '2023-10', '2023-11', '2023-12', '2024-01', '2024-02', '2024-03', '2024-04', '2024-05', '2024-06', '2024-07', '2024-08', '2024-09', '2024-10', '2024-11', '2024-12']\n",
      "📝 Missing months list saved in GOOGL_30min_data\\missing_months_10yr.txt\n",
      "\n",
      "📦 Checking data for META...\n",
      "❌ META 2014-01 data is missing.\n",
      "❌ META 2014-02 data is missing.\n",
      "❌ META 2014-03 data is missing.\n",
      "❌ META 2014-04 data is missing.\n",
      "❌ META 2014-05 data is missing.\n",
      "❌ META 2014-06 data is missing.\n",
      "❌ META 2014-07 data is missing.\n",
      "❌ META 2014-08 data is missing.\n",
      "❌ META 2014-09 data is missing.\n",
      "❌ META 2014-10 data is missing.\n",
      "❌ META 2014-11 data is missing.\n",
      "❌ META 2014-12 data is missing.\n",
      "❌ META 2015-01 data is missing.\n",
      "❌ META 2015-02 data is missing.\n",
      "❌ META 2015-03 data is missing.\n",
      "❌ META 2015-04 data is missing.\n",
      "❌ META 2015-05 data is missing.\n",
      "❌ META 2015-06 data is missing.\n",
      "❌ META 2015-07 data is missing.\n",
      "❌ META 2015-08 data is missing.\n",
      "❌ META 2015-09 data is missing.\n",
      "❌ META 2015-10 data is missing.\n",
      "❌ META 2015-11 data is missing.\n",
      "❌ META 2015-12 data is missing.\n",
      "❌ META 2016-01 data is missing.\n",
      "❌ META 2016-02 data is missing.\n",
      "❌ META 2016-03 data is missing.\n",
      "❌ META 2016-04 data is missing.\n",
      "❌ META 2016-05 data is missing.\n",
      "❌ META 2016-06 data is missing.\n",
      "❌ META 2016-07 data is missing.\n",
      "❌ META 2016-08 data is missing.\n",
      "❌ META 2016-09 data is missing.\n",
      "❌ META 2016-10 data is missing.\n",
      "❌ META 2016-11 data is missing.\n",
      "❌ META 2016-12 data is missing.\n",
      "❌ META 2017-01 data is missing.\n",
      "❌ META 2017-02 data is missing.\n",
      "❌ META 2017-03 data is missing.\n",
      "❌ META 2017-04 data is missing.\n",
      "❌ META 2017-05 data is missing.\n",
      "❌ META 2017-06 data is missing.\n",
      "❌ META 2017-07 data is missing.\n",
      "❌ META 2017-08 data is missing.\n",
      "❌ META 2017-09 data is missing.\n",
      "❌ META 2017-10 data is missing.\n",
      "❌ META 2017-11 data is missing.\n",
      "❌ META 2017-12 data is missing.\n",
      "❌ META 2018-01 data is missing.\n",
      "❌ META 2018-02 data is missing.\n",
      "❌ META 2018-03 data is missing.\n",
      "❌ META 2018-04 data is missing.\n",
      "❌ META 2018-05 data is missing.\n",
      "❌ META 2018-06 data is missing.\n",
      "❌ META 2018-07 data is missing.\n",
      "❌ META 2018-08 data is missing.\n",
      "❌ META 2018-09 data is missing.\n",
      "❌ META 2018-10 data is missing.\n",
      "❌ META 2018-11 data is missing.\n",
      "❌ META 2018-12 data is missing.\n",
      "❌ META 2019-01 data is missing.\n",
      "❌ META 2019-02 data is missing.\n",
      "❌ META 2019-03 data is missing.\n",
      "❌ META 2019-04 data is missing.\n",
      "❌ META 2019-05 data is missing.\n",
      "❌ META 2019-06 data is missing.\n",
      "❌ META 2019-07 data is missing.\n",
      "❌ META 2019-08 data is missing.\n",
      "❌ META 2019-09 data is missing.\n",
      "❌ META 2019-10 data is missing.\n",
      "❌ META 2019-11 data is missing.\n",
      "❌ META 2019-12 data is missing.\n",
      "❌ META 2020-01 data is missing.\n",
      "❌ META 2020-02 data is missing.\n",
      "❌ META 2020-03 data is missing.\n",
      "❌ META 2020-04 data is missing.\n",
      "❌ META 2020-05 data is missing.\n",
      "❌ META 2020-06 data is missing.\n",
      "❌ META 2020-07 data is missing.\n",
      "❌ META 2020-08 data is missing.\n",
      "❌ META 2020-09 data is missing.\n",
      "❌ META 2020-10 data is missing.\n",
      "❌ META 2020-11 data is missing.\n",
      "❌ META 2020-12 data is missing.\n",
      "❌ META 2021-01 data is missing.\n",
      "❌ META 2021-02 data is missing.\n",
      "❌ META 2021-03 data is missing.\n",
      "❌ META 2021-04 data is missing.\n",
      "❌ META 2021-05 data is missing.\n",
      "❌ META 2021-06 data is missing.\n",
      "❌ META 2021-07 data is missing.\n",
      "❌ META 2021-08 data is missing.\n",
      "❌ META 2021-09 data is missing.\n",
      "❌ META 2021-10 data is missing.\n",
      "❌ META 2021-11 data is missing.\n",
      "❌ META 2021-12 data is missing.\n",
      "❌ META 2022-01 data is missing.\n",
      "❌ META 2022-02 data is missing.\n",
      "❌ META 2022-03 data is missing.\n",
      "❌ META 2022-04 data is missing.\n",
      "❌ META 2022-05 data is missing.\n",
      "❌ META 2022-06 data is missing.\n",
      "❌ META 2022-07 data is missing.\n",
      "❌ META 2022-08 data is missing.\n",
      "❌ META 2022-09 data is missing.\n",
      "❌ META 2022-10 data is missing.\n",
      "❌ META 2022-11 data is missing.\n",
      "❌ META 2022-12 data is missing.\n",
      "❌ META 2023-01 data is missing.\n",
      "❌ META 2023-02 data is missing.\n",
      "❌ META 2023-03 data is missing.\n",
      "❌ META 2023-04 data is missing.\n",
      "❌ META 2023-05 data is missing.\n",
      "❌ META 2023-06 data is missing.\n",
      "❌ META 2023-07 data is missing.\n",
      "❌ META 2023-08 data is missing.\n",
      "❌ META 2023-09 data is missing.\n",
      "❌ META 2023-10 data is missing.\n",
      "❌ META 2023-11 data is missing.\n",
      "❌ META 2023-12 data is missing.\n",
      "❌ META 2024-01 data is missing.\n",
      "❌ META 2024-02 data is missing.\n",
      "❌ META 2024-03 data is missing.\n",
      "❌ META 2024-04 data is missing.\n",
      "❌ META 2024-05 data is missing.\n",
      "❌ META 2024-06 data is missing.\n",
      "❌ META 2024-07 data is missing.\n",
      "❌ META 2024-08 data is missing.\n",
      "❌ META 2024-09 data is missing.\n",
      "❌ META 2024-10 data is missing.\n",
      "❌ META 2024-11 data is missing.\n",
      "❌ META 2024-12 data is missing.\n",
      "📊 META months that need to be fetched: ['2014-01', '2014-02', '2014-03', '2014-04', '2014-05', '2014-06', '2014-07', '2014-08', '2014-09', '2014-10', '2014-11', '2014-12', '2015-01', '2015-02', '2015-03', '2015-04', '2015-05', '2015-06', '2015-07', '2015-08', '2015-09', '2015-10', '2015-11', '2015-12', '2016-01', '2016-02', '2016-03', '2016-04', '2016-05', '2016-06', '2016-07', '2016-08', '2016-09', '2016-10', '2016-11', '2016-12', '2017-01', '2017-02', '2017-03', '2017-04', '2017-05', '2017-06', '2017-07', '2017-08', '2017-09', '2017-10', '2017-11', '2017-12', '2018-01', '2018-02', '2018-03', '2018-04', '2018-05', '2018-06', '2018-07', '2018-08', '2018-09', '2018-10', '2018-11', '2018-12', '2019-01', '2019-02', '2019-03', '2019-04', '2019-05', '2019-06', '2019-07', '2019-08', '2019-09', '2019-10', '2019-11', '2019-12', '2020-01', '2020-02', '2020-03', '2020-04', '2020-05', '2020-06', '2020-07', '2020-08', '2020-09', '2020-10', '2020-11', '2020-12', '2021-01', '2021-02', '2021-03', '2021-04', '2021-05', '2021-06', '2021-07', '2021-08', '2021-09', '2021-10', '2021-11', '2021-12', '2022-01', '2022-02', '2022-03', '2022-04', '2022-05', '2022-06', '2022-07', '2022-08', '2022-09', '2022-10', '2022-11', '2022-12', '2023-01', '2023-02', '2023-03', '2023-04', '2023-05', '2023-06', '2023-07', '2023-08', '2023-09', '2023-10', '2023-11', '2023-12', '2024-01', '2024-02', '2024-03', '2024-04', '2024-05', '2024-06', '2024-07', '2024-08', '2024-09', '2024-10', '2024-11', '2024-12']\n",
      "📝 Missing months list saved in META_30min_data\\missing_months_10yr.txt\n",
      "\n",
      "📦 Checking data for TSLA...\n",
      "❌ TSLA 2014-01 data is missing.\n",
      "❌ TSLA 2014-02 data is missing.\n",
      "❌ TSLA 2014-03 data is missing.\n",
      "❌ TSLA 2014-04 data is missing.\n",
      "❌ TSLA 2014-05 data is missing.\n",
      "❌ TSLA 2014-06 data is missing.\n",
      "❌ TSLA 2014-07 data is missing.\n",
      "❌ TSLA 2014-08 data is missing.\n",
      "❌ TSLA 2014-09 data is missing.\n",
      "❌ TSLA 2014-10 data is missing.\n",
      "❌ TSLA 2014-11 data is missing.\n",
      "❌ TSLA 2014-12 data is missing.\n",
      "❌ TSLA 2015-01 data is missing.\n",
      "❌ TSLA 2015-02 data is missing.\n",
      "❌ TSLA 2015-03 data is missing.\n",
      "❌ TSLA 2015-04 data is missing.\n",
      "❌ TSLA 2015-05 data is missing.\n",
      "❌ TSLA 2015-06 data is missing.\n",
      "❌ TSLA 2015-07 data is missing.\n",
      "❌ TSLA 2015-08 data is missing.\n",
      "❌ TSLA 2015-09 data is missing.\n",
      "❌ TSLA 2015-10 data is missing.\n",
      "❌ TSLA 2015-11 data is missing.\n",
      "❌ TSLA 2015-12 data is missing.\n",
      "❌ TSLA 2016-01 data is missing.\n",
      "❌ TSLA 2016-02 data is missing.\n",
      "❌ TSLA 2016-03 data is missing.\n",
      "❌ TSLA 2016-04 data is missing.\n",
      "❌ TSLA 2016-05 data is missing.\n",
      "❌ TSLA 2016-06 data is missing.\n",
      "❌ TSLA 2016-07 data is missing.\n",
      "❌ TSLA 2016-08 data is missing.\n",
      "❌ TSLA 2016-09 data is missing.\n",
      "❌ TSLA 2016-10 data is missing.\n",
      "❌ TSLA 2016-11 data is missing.\n",
      "❌ TSLA 2016-12 data is missing.\n",
      "❌ TSLA 2017-01 data is missing.\n",
      "❌ TSLA 2017-02 data is missing.\n",
      "❌ TSLA 2017-03 data is missing.\n",
      "❌ TSLA 2017-04 data is missing.\n",
      "❌ TSLA 2017-05 data is missing.\n",
      "❌ TSLA 2017-06 data is missing.\n",
      "❌ TSLA 2017-07 data is missing.\n",
      "❌ TSLA 2017-08 data is missing.\n",
      "❌ TSLA 2017-09 data is missing.\n",
      "❌ TSLA 2017-10 data is missing.\n",
      "❌ TSLA 2017-11 data is missing.\n",
      "❌ TSLA 2017-12 data is missing.\n",
      "❌ TSLA 2018-01 data is missing.\n",
      "❌ TSLA 2018-02 data is missing.\n",
      "❌ TSLA 2018-03 data is missing.\n",
      "❌ TSLA 2018-04 data is missing.\n",
      "❌ TSLA 2018-05 data is missing.\n",
      "❌ TSLA 2018-06 data is missing.\n",
      "❌ TSLA 2018-07 data is missing.\n",
      "❌ TSLA 2018-08 data is missing.\n",
      "❌ TSLA 2018-09 data is missing.\n",
      "❌ TSLA 2018-10 data is missing.\n",
      "❌ TSLA 2018-11 data is missing.\n",
      "❌ TSLA 2018-12 data is missing.\n",
      "❌ TSLA 2019-01 data is missing.\n",
      "❌ TSLA 2019-02 data is missing.\n",
      "❌ TSLA 2019-03 data is missing.\n",
      "❌ TSLA 2019-04 data is missing.\n",
      "❌ TSLA 2019-05 data is missing.\n",
      "❌ TSLA 2019-06 data is missing.\n",
      "❌ TSLA 2019-07 data is missing.\n",
      "❌ TSLA 2019-08 data is missing.\n",
      "❌ TSLA 2019-09 data is missing.\n",
      "❌ TSLA 2019-10 data is missing.\n",
      "❌ TSLA 2019-11 data is missing.\n",
      "❌ TSLA 2019-12 data is missing.\n",
      "❌ TSLA 2020-01 data is missing.\n",
      "❌ TSLA 2020-02 data is missing.\n",
      "❌ TSLA 2020-03 data is missing.\n",
      "❌ TSLA 2020-04 data is missing.\n",
      "❌ TSLA 2020-05 data is missing.\n",
      "❌ TSLA 2020-06 data is missing.\n",
      "❌ TSLA 2020-07 data is missing.\n",
      "❌ TSLA 2020-08 data is missing.\n",
      "❌ TSLA 2020-09 data is missing.\n",
      "❌ TSLA 2020-10 data is missing.\n",
      "❌ TSLA 2020-11 data is missing.\n",
      "❌ TSLA 2020-12 data is missing.\n",
      "❌ TSLA 2021-01 data is missing.\n",
      "❌ TSLA 2021-02 data is missing.\n",
      "❌ TSLA 2021-03 data is missing.\n",
      "❌ TSLA 2021-04 data is missing.\n",
      "❌ TSLA 2021-05 data is missing.\n",
      "❌ TSLA 2021-06 data is missing.\n",
      "❌ TSLA 2021-07 data is missing.\n",
      "❌ TSLA 2021-08 data is missing.\n",
      "❌ TSLA 2021-09 data is missing.\n",
      "❌ TSLA 2021-10 data is missing.\n",
      "❌ TSLA 2021-11 data is missing.\n",
      "❌ TSLA 2021-12 data is missing.\n",
      "❌ TSLA 2022-01 data is missing.\n",
      "❌ TSLA 2022-02 data is missing.\n",
      "❌ TSLA 2022-03 data is missing.\n",
      "❌ TSLA 2022-04 data is missing.\n",
      "❌ TSLA 2022-05 data is missing.\n",
      "❌ TSLA 2022-06 data is missing.\n",
      "❌ TSLA 2022-07 data is missing.\n",
      "❌ TSLA 2022-08 data is missing.\n",
      "❌ TSLA 2022-09 data is missing.\n",
      "❌ TSLA 2022-10 data is missing.\n",
      "❌ TSLA 2022-11 data is missing.\n",
      "❌ TSLA 2022-12 data is missing.\n",
      "❌ TSLA 2023-01 data is missing.\n",
      "❌ TSLA 2023-02 data is missing.\n",
      "❌ TSLA 2023-03 data is missing.\n",
      "❌ TSLA 2023-04 data is missing.\n",
      "❌ TSLA 2023-05 data is missing.\n",
      "❌ TSLA 2023-06 data is missing.\n",
      "❌ TSLA 2023-07 data is missing.\n",
      "❌ TSLA 2023-08 data is missing.\n",
      "❌ TSLA 2023-09 data is missing.\n",
      "❌ TSLA 2023-10 data is missing.\n",
      "❌ TSLA 2023-11 data is missing.\n",
      "❌ TSLA 2023-12 data is missing.\n",
      "❌ TSLA 2024-01 data is missing.\n",
      "❌ TSLA 2024-02 data is missing.\n",
      "❌ TSLA 2024-03 data is missing.\n",
      "❌ TSLA 2024-04 data is missing.\n",
      "❌ TSLA 2024-05 data is missing.\n",
      "❌ TSLA 2024-06 data is missing.\n",
      "❌ TSLA 2024-07 data is missing.\n",
      "❌ TSLA 2024-08 data is missing.\n",
      "❌ TSLA 2024-09 data is missing.\n",
      "❌ TSLA 2024-10 data is missing.\n",
      "❌ TSLA 2024-11 data is missing.\n",
      "❌ TSLA 2024-12 data is missing.\n",
      "📊 TSLA months that need to be fetched: ['2014-01', '2014-02', '2014-03', '2014-04', '2014-05', '2014-06', '2014-07', '2014-08', '2014-09', '2014-10', '2014-11', '2014-12', '2015-01', '2015-02', '2015-03', '2015-04', '2015-05', '2015-06', '2015-07', '2015-08', '2015-09', '2015-10', '2015-11', '2015-12', '2016-01', '2016-02', '2016-03', '2016-04', '2016-05', '2016-06', '2016-07', '2016-08', '2016-09', '2016-10', '2016-11', '2016-12', '2017-01', '2017-02', '2017-03', '2017-04', '2017-05', '2017-06', '2017-07', '2017-08', '2017-09', '2017-10', '2017-11', '2017-12', '2018-01', '2018-02', '2018-03', '2018-04', '2018-05', '2018-06', '2018-07', '2018-08', '2018-09', '2018-10', '2018-11', '2018-12', '2019-01', '2019-02', '2019-03', '2019-04', '2019-05', '2019-06', '2019-07', '2019-08', '2019-09', '2019-10', '2019-11', '2019-12', '2020-01', '2020-02', '2020-03', '2020-04', '2020-05', '2020-06', '2020-07', '2020-08', '2020-09', '2020-10', '2020-11', '2020-12', '2021-01', '2021-02', '2021-03', '2021-04', '2021-05', '2021-06', '2021-07', '2021-08', '2021-09', '2021-10', '2021-11', '2021-12', '2022-01', '2022-02', '2022-03', '2022-04', '2022-05', '2022-06', '2022-07', '2022-08', '2022-09', '2022-10', '2022-11', '2022-12', '2023-01', '2023-02', '2023-03', '2023-04', '2023-05', '2023-06', '2023-07', '2023-08', '2023-09', '2023-10', '2023-11', '2023-12', '2024-01', '2024-02', '2024-03', '2024-04', '2024-05', '2024-06', '2024-07', '2024-08', '2024-09', '2024-10', '2024-11', '2024-12']\n",
      "📝 Missing months list saved in TSLA_30min_data\\missing_months_10yr.txt\n",
      "\n",
      "📦 Checking data for AMD...\n",
      "✅ AMD 2014-01 data is already complete.\n",
      "✅ AMD 2014-02 data is already complete.\n",
      "✅ AMD 2014-03 data is already complete.\n",
      "✅ AMD 2014-04 data is already complete.\n",
      "✅ AMD 2014-05 data is already complete.\n",
      "✅ AMD 2014-06 data is already complete.\n",
      "✅ AMD 2014-07 data is already complete.\n",
      "✅ AMD 2014-08 data is already complete.\n",
      "✅ AMD 2014-09 data is already complete.\n",
      "✅ AMD 2014-10 data is already complete.\n",
      "✅ AMD 2014-11 data is already complete.\n",
      "✅ AMD 2014-12 data is already complete.\n",
      "✅ AMD 2015-01 data is already complete.\n",
      "✅ AMD 2015-02 data is already complete.\n",
      "✅ AMD 2015-03 data is already complete.\n",
      "✅ AMD 2015-04 data is already complete.\n",
      "✅ AMD 2015-05 data is already complete.\n",
      "✅ AMD 2015-06 data is already complete.\n",
      "✅ AMD 2015-07 data is already complete.\n",
      "✅ AMD 2015-08 data is already complete.\n",
      "✅ AMD 2015-09 data is already complete.\n",
      "✅ AMD 2015-10 data is already complete.\n",
      "✅ AMD 2015-11 data is already complete.\n",
      "✅ AMD 2015-12 data is already complete.\n",
      "✅ AMD 2016-01 data is already complete.\n",
      "✅ AMD 2016-02 data is already complete.\n",
      "✅ AMD 2016-03 data is already complete.\n",
      "✅ AMD 2016-04 data is already complete.\n",
      "✅ AMD 2016-05 data is already complete.\n",
      "✅ AMD 2016-06 data is already complete.\n",
      "✅ AMD 2016-07 data is already complete.\n",
      "✅ AMD 2016-08 data is already complete.\n",
      "✅ AMD 2016-09 data is already complete.\n",
      "✅ AMD 2016-10 data is already complete.\n",
      "✅ AMD 2016-11 data is already complete.\n",
      "✅ AMD 2016-12 data is already complete.\n",
      "✅ AMD 2017-01 data is already complete.\n",
      "✅ AMD 2017-02 data is already complete.\n",
      "✅ AMD 2017-03 data is already complete.\n",
      "✅ AMD 2017-04 data is already complete.\n",
      "✅ AMD 2017-05 data is already complete.\n",
      "✅ AMD 2017-06 data is already complete.\n",
      "✅ AMD 2017-07 data is already complete.\n",
      "✅ AMD 2017-08 data is already complete.\n",
      "✅ AMD 2017-09 data is already complete.\n",
      "✅ AMD 2017-10 data is already complete.\n",
      "✅ AMD 2017-11 data is already complete.\n",
      "✅ AMD 2017-12 data is already complete.\n",
      "✅ AMD 2018-01 data is already complete.\n",
      "✅ AMD 2018-02 data is already complete.\n",
      "✅ AMD 2018-03 data is already complete.\n",
      "✅ AMD 2018-04 data is already complete.\n",
      "✅ AMD 2018-05 data is already complete.\n",
      "✅ AMD 2018-06 data is already complete.\n",
      "✅ AMD 2018-07 data is already complete.\n",
      "✅ AMD 2018-08 data is already complete.\n",
      "✅ AMD 2018-09 data is already complete.\n",
      "✅ AMD 2018-10 data is already complete.\n",
      "✅ AMD 2018-11 data is already complete.\n",
      "✅ AMD 2018-12 data is already complete.\n",
      "✅ AMD 2019-01 data is already complete.\n",
      "✅ AMD 2019-02 data is already complete.\n",
      "✅ AMD 2019-03 data is already complete.\n",
      "✅ AMD 2019-04 data is already complete.\n",
      "✅ AMD 2019-05 data is already complete.\n",
      "✅ AMD 2019-06 data is already complete.\n",
      "✅ AMD 2019-07 data is already complete.\n",
      "✅ AMD 2019-08 data is already complete.\n",
      "✅ AMD 2019-09 data is already complete.\n",
      "✅ AMD 2019-10 data is already complete.\n",
      "✅ AMD 2019-11 data is already complete.\n",
      "✅ AMD 2019-12 data is already complete.\n",
      "✅ AMD 2020-01 data is already complete.\n",
      "✅ AMD 2020-02 data is already complete.\n",
      "✅ AMD 2020-03 data is already complete.\n",
      "✅ AMD 2020-04 data is already complete.\n",
      "✅ AMD 2020-05 data is already complete.\n",
      "✅ AMD 2020-06 data is already complete.\n",
      "✅ AMD 2020-07 data is already complete.\n",
      "✅ AMD 2020-08 data is already complete.\n",
      "✅ AMD 2020-09 data is already complete.\n",
      "✅ AMD 2020-10 data is already complete.\n",
      "✅ AMD 2020-11 data is already complete.\n",
      "✅ AMD 2020-12 data is already complete.\n",
      "✅ AMD 2021-01 data is already complete.\n",
      "✅ AMD 2021-02 data is already complete.\n",
      "✅ AMD 2021-03 data is already complete.\n",
      "✅ AMD 2021-04 data is already complete.\n",
      "✅ AMD 2021-05 data is already complete.\n",
      "✅ AMD 2021-06 data is already complete.\n",
      "✅ AMD 2021-07 data is already complete.\n",
      "✅ AMD 2021-08 data is already complete.\n",
      "✅ AMD 2021-09 data is already complete.\n",
      "✅ AMD 2021-10 data is already complete.\n",
      "✅ AMD 2021-11 data is already complete.\n",
      "✅ AMD 2021-12 data is already complete.\n",
      "✅ AMD 2022-01 data is already complete.\n",
      "✅ AMD 2022-02 data is already complete.\n",
      "✅ AMD 2022-03 data is already complete.\n",
      "✅ AMD 2022-04 data is already complete.\n",
      "✅ AMD 2022-05 data is already complete.\n",
      "✅ AMD 2022-06 data is already complete.\n",
      "✅ AMD 2022-07 data is already complete.\n",
      "✅ AMD 2022-08 data is already complete.\n",
      "✅ AMD 2022-09 data is already complete.\n",
      "✅ AMD 2022-10 data is already complete.\n",
      "✅ AMD 2022-11 data is already complete.\n",
      "✅ AMD 2022-12 data is already complete.\n",
      "✅ AMD 2023-01 data is already complete.\n",
      "✅ AMD 2023-02 data is already complete.\n",
      "✅ AMD 2023-03 data is already complete.\n",
      "✅ AMD 2023-04 data is already complete.\n",
      "✅ AMD 2023-05 data is already complete.\n",
      "✅ AMD 2023-06 data is already complete.\n",
      "✅ AMD 2023-07 data is already complete.\n",
      "✅ AMD 2023-08 data is already complete.\n",
      "✅ AMD 2023-09 data is already complete.\n",
      "✅ AMD 2023-10 data is already complete.\n",
      "✅ AMD 2023-11 data is already complete.\n",
      "✅ AMD 2023-12 data is already complete.\n",
      "✅ AMD 2024-01 data is already complete.\n",
      "✅ AMD 2024-02 data is already complete.\n",
      "✅ AMD 2024-03 data is already complete.\n",
      "✅ AMD 2024-04 data is already complete.\n",
      "✅ AMD 2024-05 data is already complete.\n",
      "✅ AMD 2024-06 data is already complete.\n",
      "✅ AMD 2024-07 data is already complete.\n",
      "✅ AMD 2024-08 data is already complete.\n",
      "✅ AMD 2024-09 data is already complete.\n",
      "✅ AMD 2024-10 data is already complete.\n",
      "✅ AMD 2024-11 data is already complete.\n",
      "✅ AMD 2024-12 data is already complete.\n",
      "📊 AMD months that need to be fetched: []\n",
      "📝 Missing months list saved in AMD_30min_data\\missing_months_10yr.txt\n",
      "\n",
      "📦 Checking data for NFLX...\n",
      "❌ NFLX 2014-01 data is missing.\n",
      "❌ NFLX 2014-02 data is missing.\n",
      "❌ NFLX 2014-03 data is missing.\n",
      "❌ NFLX 2014-04 data is missing.\n",
      "❌ NFLX 2014-05 data is missing.\n",
      "❌ NFLX 2014-06 data is missing.\n",
      "❌ NFLX 2014-07 data is missing.\n",
      "❌ NFLX 2014-08 data is missing.\n",
      "❌ NFLX 2014-09 data is missing.\n",
      "❌ NFLX 2014-10 data is missing.\n",
      "❌ NFLX 2014-11 data is missing.\n",
      "❌ NFLX 2014-12 data is missing.\n",
      "❌ NFLX 2015-01 data is missing.\n",
      "❌ NFLX 2015-02 data is missing.\n",
      "❌ NFLX 2015-03 data is missing.\n",
      "❌ NFLX 2015-04 data is missing.\n",
      "❌ NFLX 2015-05 data is missing.\n",
      "❌ NFLX 2015-06 data is missing.\n",
      "❌ NFLX 2015-07 data is missing.\n",
      "❌ NFLX 2015-08 data is missing.\n",
      "❌ NFLX 2015-09 data is missing.\n",
      "❌ NFLX 2015-10 data is missing.\n",
      "❌ NFLX 2015-11 data is missing.\n",
      "❌ NFLX 2015-12 data is missing.\n",
      "❌ NFLX 2016-01 data is missing.\n",
      "❌ NFLX 2016-02 data is missing.\n",
      "❌ NFLX 2016-03 data is missing.\n",
      "❌ NFLX 2016-04 data is missing.\n",
      "❌ NFLX 2016-05 data is missing.\n",
      "❌ NFLX 2016-06 data is missing.\n",
      "❌ NFLX 2016-07 data is missing.\n",
      "❌ NFLX 2016-08 data is missing.\n",
      "❌ NFLX 2016-09 data is missing.\n",
      "❌ NFLX 2016-10 data is missing.\n",
      "❌ NFLX 2016-11 data is missing.\n",
      "❌ NFLX 2016-12 data is missing.\n",
      "❌ NFLX 2017-01 data is missing.\n",
      "❌ NFLX 2017-02 data is missing.\n",
      "❌ NFLX 2017-03 data is missing.\n",
      "❌ NFLX 2017-04 data is missing.\n",
      "❌ NFLX 2017-05 data is missing.\n",
      "❌ NFLX 2017-06 data is missing.\n",
      "❌ NFLX 2017-07 data is missing.\n",
      "❌ NFLX 2017-08 data is missing.\n",
      "❌ NFLX 2017-09 data is missing.\n",
      "❌ NFLX 2017-10 data is missing.\n",
      "❌ NFLX 2017-11 data is missing.\n",
      "❌ NFLX 2017-12 data is missing.\n",
      "❌ NFLX 2018-01 data is missing.\n",
      "❌ NFLX 2018-02 data is missing.\n",
      "❌ NFLX 2018-03 data is missing.\n",
      "❌ NFLX 2018-04 data is missing.\n",
      "❌ NFLX 2018-05 data is missing.\n",
      "❌ NFLX 2018-06 data is missing.\n",
      "❌ NFLX 2018-07 data is missing.\n",
      "❌ NFLX 2018-08 data is missing.\n",
      "❌ NFLX 2018-09 data is missing.\n",
      "❌ NFLX 2018-10 data is missing.\n",
      "❌ NFLX 2018-11 data is missing.\n",
      "❌ NFLX 2018-12 data is missing.\n",
      "❌ NFLX 2019-01 data is missing.\n",
      "❌ NFLX 2019-02 data is missing.\n",
      "❌ NFLX 2019-03 data is missing.\n",
      "❌ NFLX 2019-04 data is missing.\n",
      "❌ NFLX 2019-05 data is missing.\n",
      "❌ NFLX 2019-06 data is missing.\n",
      "❌ NFLX 2019-07 data is missing.\n",
      "❌ NFLX 2019-08 data is missing.\n",
      "❌ NFLX 2019-09 data is missing.\n",
      "❌ NFLX 2019-10 data is missing.\n",
      "❌ NFLX 2019-11 data is missing.\n",
      "❌ NFLX 2019-12 data is missing.\n",
      "❌ NFLX 2020-01 data is missing.\n",
      "❌ NFLX 2020-02 data is missing.\n",
      "❌ NFLX 2020-03 data is missing.\n",
      "❌ NFLX 2020-04 data is missing.\n",
      "❌ NFLX 2020-05 data is missing.\n",
      "❌ NFLX 2020-06 data is missing.\n",
      "❌ NFLX 2020-07 data is missing.\n",
      "❌ NFLX 2020-08 data is missing.\n",
      "❌ NFLX 2020-09 data is missing.\n",
      "❌ NFLX 2020-10 data is missing.\n",
      "❌ NFLX 2020-11 data is missing.\n",
      "❌ NFLX 2020-12 data is missing.\n",
      "❌ NFLX 2021-01 data is missing.\n",
      "❌ NFLX 2021-02 data is missing.\n",
      "❌ NFLX 2021-03 data is missing.\n",
      "❌ NFLX 2021-04 data is missing.\n",
      "❌ NFLX 2021-05 data is missing.\n",
      "❌ NFLX 2021-06 data is missing.\n",
      "❌ NFLX 2021-07 data is missing.\n",
      "❌ NFLX 2021-08 data is missing.\n",
      "❌ NFLX 2021-09 data is missing.\n",
      "❌ NFLX 2021-10 data is missing.\n",
      "❌ NFLX 2021-11 data is missing.\n",
      "❌ NFLX 2021-12 data is missing.\n",
      "❌ NFLX 2022-01 data is missing.\n",
      "❌ NFLX 2022-02 data is missing.\n",
      "❌ NFLX 2022-03 data is missing.\n",
      "❌ NFLX 2022-04 data is missing.\n",
      "❌ NFLX 2022-05 data is missing.\n",
      "❌ NFLX 2022-06 data is missing.\n",
      "❌ NFLX 2022-07 data is missing.\n",
      "❌ NFLX 2022-08 data is missing.\n",
      "❌ NFLX 2022-09 data is missing.\n",
      "❌ NFLX 2022-10 data is missing.\n",
      "❌ NFLX 2022-11 data is missing.\n",
      "❌ NFLX 2022-12 data is missing.\n",
      "❌ NFLX 2023-01 data is missing.\n",
      "❌ NFLX 2023-02 data is missing.\n",
      "❌ NFLX 2023-03 data is missing.\n",
      "❌ NFLX 2023-04 data is missing.\n",
      "❌ NFLX 2023-05 data is missing.\n",
      "❌ NFLX 2023-06 data is missing.\n",
      "❌ NFLX 2023-07 data is missing.\n",
      "❌ NFLX 2023-08 data is missing.\n",
      "❌ NFLX 2023-09 data is missing.\n",
      "❌ NFLX 2023-10 data is missing.\n",
      "❌ NFLX 2023-11 data is missing.\n",
      "❌ NFLX 2023-12 data is missing.\n",
      "❌ NFLX 2024-01 data is missing.\n",
      "❌ NFLX 2024-02 data is missing.\n",
      "❌ NFLX 2024-03 data is missing.\n",
      "❌ NFLX 2024-04 data is missing.\n",
      "❌ NFLX 2024-05 data is missing.\n",
      "❌ NFLX 2024-06 data is missing.\n",
      "❌ NFLX 2024-07 data is missing.\n",
      "❌ NFLX 2024-08 data is missing.\n",
      "❌ NFLX 2024-09 data is missing.\n",
      "❌ NFLX 2024-10 data is missing.\n",
      "❌ NFLX 2024-11 data is missing.\n",
      "❌ NFLX 2024-12 data is missing.\n",
      "📊 NFLX months that need to be fetched: ['2014-01', '2014-02', '2014-03', '2014-04', '2014-05', '2014-06', '2014-07', '2014-08', '2014-09', '2014-10', '2014-11', '2014-12', '2015-01', '2015-02', '2015-03', '2015-04', '2015-05', '2015-06', '2015-07', '2015-08', '2015-09', '2015-10', '2015-11', '2015-12', '2016-01', '2016-02', '2016-03', '2016-04', '2016-05', '2016-06', '2016-07', '2016-08', '2016-09', '2016-10', '2016-11', '2016-12', '2017-01', '2017-02', '2017-03', '2017-04', '2017-05', '2017-06', '2017-07', '2017-08', '2017-09', '2017-10', '2017-11', '2017-12', '2018-01', '2018-02', '2018-03', '2018-04', '2018-05', '2018-06', '2018-07', '2018-08', '2018-09', '2018-10', '2018-11', '2018-12', '2019-01', '2019-02', '2019-03', '2019-04', '2019-05', '2019-06', '2019-07', '2019-08', '2019-09', '2019-10', '2019-11', '2019-12', '2020-01', '2020-02', '2020-03', '2020-04', '2020-05', '2020-06', '2020-07', '2020-08', '2020-09', '2020-10', '2020-11', '2020-12', '2021-01', '2021-02', '2021-03', '2021-04', '2021-05', '2021-06', '2021-07', '2021-08', '2021-09', '2021-10', '2021-11', '2021-12', '2022-01', '2022-02', '2022-03', '2022-04', '2022-05', '2022-06', '2022-07', '2022-08', '2022-09', '2022-10', '2022-11', '2022-12', '2023-01', '2023-02', '2023-03', '2023-04', '2023-05', '2023-06', '2023-07', '2023-08', '2023-09', '2023-10', '2023-11', '2023-12', '2024-01', '2024-02', '2024-03', '2024-04', '2024-05', '2024-06', '2024-07', '2024-08', '2024-09', '2024-10', '2024-11', '2024-12']\n",
      "📝 Missing months list saved in NFLX_30min_data\\missing_months_10yr.txt\n",
      "\n",
      "📦 Checking data for AVGO...\n",
      "❌ AVGO 2014-01 data is missing.\n",
      "❌ AVGO 2014-02 data is missing.\n",
      "❌ AVGO 2014-03 data is missing.\n",
      "❌ AVGO 2014-04 data is missing.\n",
      "❌ AVGO 2014-05 data is missing.\n",
      "❌ AVGO 2014-06 data is missing.\n",
      "❌ AVGO 2014-07 data is missing.\n",
      "❌ AVGO 2014-08 data is missing.\n",
      "❌ AVGO 2014-09 data is missing.\n",
      "❌ AVGO 2014-10 data is missing.\n",
      "❌ AVGO 2014-11 data is missing.\n",
      "❌ AVGO 2014-12 data is missing.\n",
      "❌ AVGO 2015-01 data is missing.\n",
      "❌ AVGO 2015-02 data is missing.\n",
      "❌ AVGO 2015-03 data is missing.\n",
      "❌ AVGO 2015-04 data is missing.\n",
      "❌ AVGO 2015-05 data is missing.\n",
      "❌ AVGO 2015-06 data is missing.\n",
      "❌ AVGO 2015-07 data is missing.\n",
      "❌ AVGO 2015-08 data is missing.\n",
      "❌ AVGO 2015-09 data is missing.\n",
      "❌ AVGO 2015-10 data is missing.\n",
      "❌ AVGO 2015-11 data is missing.\n",
      "❌ AVGO 2015-12 data is missing.\n",
      "❌ AVGO 2016-01 data is missing.\n",
      "❌ AVGO 2016-02 data is missing.\n",
      "❌ AVGO 2016-03 data is missing.\n",
      "❌ AVGO 2016-04 data is missing.\n",
      "❌ AVGO 2016-05 data is missing.\n",
      "❌ AVGO 2016-06 data is missing.\n",
      "❌ AVGO 2016-07 data is missing.\n",
      "❌ AVGO 2016-08 data is missing.\n",
      "❌ AVGO 2016-09 data is missing.\n",
      "❌ AVGO 2016-10 data is missing.\n",
      "❌ AVGO 2016-11 data is missing.\n",
      "❌ AVGO 2016-12 data is missing.\n",
      "❌ AVGO 2017-01 data is missing.\n",
      "❌ AVGO 2017-02 data is missing.\n",
      "❌ AVGO 2017-03 data is missing.\n",
      "❌ AVGO 2017-04 data is missing.\n",
      "❌ AVGO 2017-05 data is missing.\n",
      "❌ AVGO 2017-06 data is missing.\n",
      "❌ AVGO 2017-07 data is missing.\n",
      "❌ AVGO 2017-08 data is missing.\n",
      "❌ AVGO 2017-09 data is missing.\n",
      "❌ AVGO 2017-10 data is missing.\n",
      "❌ AVGO 2017-11 data is missing.\n",
      "❌ AVGO 2017-12 data is missing.\n",
      "❌ AVGO 2018-01 data is missing.\n",
      "❌ AVGO 2018-02 data is missing.\n",
      "❌ AVGO 2018-03 data is missing.\n",
      "❌ AVGO 2018-04 data is missing.\n",
      "❌ AVGO 2018-05 data is missing.\n",
      "❌ AVGO 2018-06 data is missing.\n",
      "❌ AVGO 2018-07 data is missing.\n",
      "❌ AVGO 2018-08 data is missing.\n",
      "❌ AVGO 2018-09 data is missing.\n",
      "❌ AVGO 2018-10 data is missing.\n",
      "❌ AVGO 2018-11 data is missing.\n",
      "❌ AVGO 2018-12 data is missing.\n",
      "❌ AVGO 2019-01 data is missing.\n",
      "❌ AVGO 2019-02 data is missing.\n",
      "❌ AVGO 2019-03 data is missing.\n",
      "❌ AVGO 2019-04 data is missing.\n",
      "❌ AVGO 2019-05 data is missing.\n",
      "❌ AVGO 2019-06 data is missing.\n",
      "❌ AVGO 2019-07 data is missing.\n",
      "❌ AVGO 2019-08 data is missing.\n",
      "❌ AVGO 2019-09 data is missing.\n",
      "❌ AVGO 2019-10 data is missing.\n",
      "❌ AVGO 2019-11 data is missing.\n",
      "❌ AVGO 2019-12 data is missing.\n",
      "❌ AVGO 2020-01 data is missing.\n",
      "❌ AVGO 2020-02 data is missing.\n",
      "❌ AVGO 2020-03 data is missing.\n",
      "❌ AVGO 2020-04 data is missing.\n",
      "❌ AVGO 2020-05 data is missing.\n",
      "❌ AVGO 2020-06 data is missing.\n",
      "❌ AVGO 2020-07 data is missing.\n",
      "❌ AVGO 2020-08 data is missing.\n",
      "❌ AVGO 2020-09 data is missing.\n",
      "❌ AVGO 2020-10 data is missing.\n",
      "❌ AVGO 2020-11 data is missing.\n",
      "❌ AVGO 2020-12 data is missing.\n",
      "❌ AVGO 2021-01 data is missing.\n",
      "❌ AVGO 2021-02 data is missing.\n",
      "❌ AVGO 2021-03 data is missing.\n",
      "❌ AVGO 2021-04 data is missing.\n",
      "❌ AVGO 2021-05 data is missing.\n",
      "❌ AVGO 2021-06 data is missing.\n",
      "❌ AVGO 2021-07 data is missing.\n",
      "❌ AVGO 2021-08 data is missing.\n",
      "❌ AVGO 2021-09 data is missing.\n",
      "❌ AVGO 2021-10 data is missing.\n",
      "❌ AVGO 2021-11 data is missing.\n",
      "❌ AVGO 2021-12 data is missing.\n",
      "❌ AVGO 2022-01 data is missing.\n",
      "❌ AVGO 2022-02 data is missing.\n",
      "❌ AVGO 2022-03 data is missing.\n",
      "❌ AVGO 2022-04 data is missing.\n",
      "❌ AVGO 2022-05 data is missing.\n",
      "❌ AVGO 2022-06 data is missing.\n",
      "❌ AVGO 2022-07 data is missing.\n",
      "❌ AVGO 2022-08 data is missing.\n",
      "❌ AVGO 2022-09 data is missing.\n",
      "❌ AVGO 2022-10 data is missing.\n",
      "❌ AVGO 2022-11 data is missing.\n",
      "❌ AVGO 2022-12 data is missing.\n",
      "❌ AVGO 2023-01 data is missing.\n",
      "❌ AVGO 2023-02 data is missing.\n",
      "❌ AVGO 2023-03 data is missing.\n",
      "❌ AVGO 2023-04 data is missing.\n",
      "❌ AVGO 2023-05 data is missing.\n",
      "❌ AVGO 2023-06 data is missing.\n",
      "❌ AVGO 2023-07 data is missing.\n",
      "❌ AVGO 2023-08 data is missing.\n",
      "❌ AVGO 2023-09 data is missing.\n",
      "❌ AVGO 2023-10 data is missing.\n",
      "❌ AVGO 2023-11 data is missing.\n",
      "❌ AVGO 2023-12 data is missing.\n",
      "❌ AVGO 2024-01 data is missing.\n",
      "❌ AVGO 2024-02 data is missing.\n",
      "❌ AVGO 2024-03 data is missing.\n",
      "❌ AVGO 2024-04 data is missing.\n",
      "❌ AVGO 2024-05 data is missing.\n",
      "❌ AVGO 2024-06 data is missing.\n",
      "❌ AVGO 2024-07 data is missing.\n",
      "❌ AVGO 2024-08 data is missing.\n",
      "❌ AVGO 2024-09 data is missing.\n",
      "❌ AVGO 2024-10 data is missing.\n",
      "❌ AVGO 2024-11 data is missing.\n",
      "❌ AVGO 2024-12 data is missing.\n",
      "📊 AVGO months that need to be fetched: ['2014-01', '2014-02', '2014-03', '2014-04', '2014-05', '2014-06', '2014-07', '2014-08', '2014-09', '2014-10', '2014-11', '2014-12', '2015-01', '2015-02', '2015-03', '2015-04', '2015-05', '2015-06', '2015-07', '2015-08', '2015-09', '2015-10', '2015-11', '2015-12', '2016-01', '2016-02', '2016-03', '2016-04', '2016-05', '2016-06', '2016-07', '2016-08', '2016-09', '2016-10', '2016-11', '2016-12', '2017-01', '2017-02', '2017-03', '2017-04', '2017-05', '2017-06', '2017-07', '2017-08', '2017-09', '2017-10', '2017-11', '2017-12', '2018-01', '2018-02', '2018-03', '2018-04', '2018-05', '2018-06', '2018-07', '2018-08', '2018-09', '2018-10', '2018-11', '2018-12', '2019-01', '2019-02', '2019-03', '2019-04', '2019-05', '2019-06', '2019-07', '2019-08', '2019-09', '2019-10', '2019-11', '2019-12', '2020-01', '2020-02', '2020-03', '2020-04', '2020-05', '2020-06', '2020-07', '2020-08', '2020-09', '2020-10', '2020-11', '2020-12', '2021-01', '2021-02', '2021-03', '2021-04', '2021-05', '2021-06', '2021-07', '2021-08', '2021-09', '2021-10', '2021-11', '2021-12', '2022-01', '2022-02', '2022-03', '2022-04', '2022-05', '2022-06', '2022-07', '2022-08', '2022-09', '2022-10', '2022-11', '2022-12', '2023-01', '2023-02', '2023-03', '2023-04', '2023-05', '2023-06', '2023-07', '2023-08', '2023-09', '2023-10', '2023-11', '2023-12', '2024-01', '2024-02', '2024-03', '2024-04', '2024-05', '2024-06', '2024-07', '2024-08', '2024-09', '2024-10', '2024-11', '2024-12']\n",
      "📝 Missing months list saved in AVGO_30min_data\\missing_months_10yr.txt\n"
     ]
    }
   ],
   "source": [
    "# List of stock symbols to process\n",
    "stock_list = [\"AAPL\", \"MSFT\", \"NVDA\", \"AMZN\", \"GOOGL\", \"META\", \"TSLA\", \"AMD\", \"NFLX\", \"AVGO\"]  # Add more if needed\n",
    "\n",
    "# List of years (2014-2024) and months\n",
    "years = list(range(2014, 2025))\n",
    "months_10yr = [f\"{y}-{str(m).zfill(2)}\" for y in years for m in range(1, 13)]\n",
    "\n",
    "# Stock market holidays (2014–2024)\n",
    "stock_market_holidays = [\n",
    "    \"2024-01-01\", \"2024-01-15\", \"2024-02-19\", \"2024-03-29\", \"2024-05-27\", \"2024-06-19\",\n",
    "    \"2024-07-04\", \"2024-09-02\", \"2024-11-28\", \"2024-12-25\", \"2023-01-02\", \"2023-01-16\",\n",
    "    \"2023-02-20\", \"2023-04-07\", \"2023-05-29\", \"2023-06-19\", \"2023-07-04\", \"2023-09-04\", \n",
    "    \"2023-11-23\", \"2023-12-25\", \"2022-01-01\", \"2022-01-17\", \"2022-02-21\", \"2022-04-15\", \n",
    "    \"2022-05-30\", \"2022-06-20\", \"2022-07-04\", \"2022-09-05\", \"2022-11-24\", \"2022-12-26\", \n",
    "    \"2021-01-01\", \"2021-01-18\", \"2021-02-15\", \"2021-04-02\", \"2021-05-31\", \"2021-07-05\", \n",
    "    \"2021-09-06\", \"2021-11-25\", \"2021-12-24\", \"2020-01-01\", \"2020-01-20\", \"2020-02-17\", \n",
    "    \"2020-04-10\", \"2020-05-25\", \"2020-07-03\", \"2020-09-07\", \"2020-11-26\", \"2020-12-25\", \n",
    "    \"2019-01-01\", \"2019-01-21\", \"2019-02-18\", \"2019-04-19\", \"2019-05-27\", \"2019-07-04\", \n",
    "    \"2019-09-02\", \"2019-11-28\", \"2019-12-25\", \"2018-01-01\", \"2018-01-15\", \"2018-02-19\",\n",
    "    \"2018-03-30\", \"2018-05-28\", \"2018-07-04\", \"2018-09-03\", \"2018-11-22\", \"2018-12-05\",\n",
    "    \"2018-12-25\", \"2017-01-02\", \"2017-01-16\", \"2017-02-20\", \"2017-04-14\", \"2017-05-29\",\n",
    "    \"2017-07-04\", \"2017-09-04\", \"2017-11-23\", \"2017-12-25\", \"2016-01-01\", \"2016-01-18\",\n",
    "    \"2016-02-15\", \"2016-03-25\", \"2016-05-30\", \"2016-07-04\", \"2016-09-05\", \"2016-11-24\",\n",
    "    \"2016-12-26\", \"2015-01-01\", \"2015-01-19\", \"2015-02-16\", \"2015-04-03\", \"2015-05-25\",\n",
    "    \"2015-07-03\", \"2015-09-07\", \"2015-11-26\", \"2015-12-25\", \"2014-01-01\", \"2014-01-20\", \n",
    "    \"2014-02-17\", \"2014-04-18\", \"2014-05-26\", \"2014-07-04\", \"2014-09-01\", \"2014-11-27\", \n",
    "    \"2014-12-25\"\n",
    "]\n",
    "stock_market_holidays = [pd.to_datetime(date).date() for date in stock_market_holidays]\n",
    "\n",
    "# Function to check if a month's data is complete\n",
    "def check_existing_data(symbol, month, output_dir):\n",
    "    file_path = os.path.join(output_dir, f\"{symbol}_30min_{month}.csv\")\n",
    "\n",
    "    if os.path.exists(file_path):\n",
    "        df = pd.read_csv(file_path, parse_dates=[\"date\"], index_col=\"date\")\n",
    "\n",
    "        # Generate expected business days (Mon–Fri)\n",
    "        expected_days = pd.date_range(start=f\"{month}-01\", end=f\"{month}-28\", freq=\"B\")\n",
    "\n",
    "        # Find missing weekdays (excluding holidays)\n",
    "        missing_days = [d.date() for d in expected_days if d.date() not in df.index.date and d.date() not in stock_market_holidays]\n",
    "\n",
    "        if missing_days:\n",
    "            print(f\"⚠️ WARNING: {symbol} {month} is missing these weekdays: {missing_days}\")\n",
    "            return False\n",
    "        else:\n",
    "            print(f\"✅ {symbol} {month} data is already complete.\")\n",
    "            return True\n",
    "    else:\n",
    "        print(f\"❌ {symbol} {month} data is missing.\")\n",
    "        return False\n",
    "\n",
    "# Loop through each stock\n",
    "for symbol in stock_list:\n",
    "    print(f\"\\n📦 Checking data for {symbol}...\")\n",
    "\n",
    "    output_dir = f\"{symbol}_30min_data\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Check for missing months\n",
    "    months_to_fetch = [month for month in months_10yr if not check_existing_data(symbol, month, output_dir)]\n",
    "\n",
    "    # Save to file\n",
    "    missing_months_file = os.path.join(output_dir, \"missing_months_10yr.txt\")\n",
    "    with open(missing_months_file, \"w\") as f:\n",
    "        for month in months_to_fetch:\n",
    "            f.write(month + \"\\n\")\n",
    "\n",
    "    print(f\"📊 {symbol} months that need to be fetched: {months_to_fetch}\")\n",
    "    print(f\"📝 Missing months list saved in {missing_months_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c392adf-a674-418e-bd02-da512edc070c",
   "metadata": {},
   "source": [
    "Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fcf463cf-421e-4aa2-9570-7c89b0a57664",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🚀 Starting data collection for AAPL\n",
      "\n",
      "🚀 Starting data collection for MSFT\n",
      "📊 Fetching MSFT data for 2015-11...\n",
      "✅ Saved MSFT data for 2015-11\n",
      "📊 Fetching MSFT data for 2015-12...\n",
      "✅ Saved MSFT data for 2015-12\n",
      "📊 Fetching MSFT data for 2016-01...\n",
      "✅ Saved MSFT data for 2016-01\n",
      "📊 Fetching MSFT data for 2016-02...\n",
      "✅ Saved MSFT data for 2016-02\n",
      "📊 Fetching MSFT data for 2016-03...\n",
      "✅ Saved MSFT data for 2016-03\n",
      "📊 Fetching MSFT data for 2016-04...\n",
      "✅ Saved MSFT data for 2016-04\n",
      "📊 Fetching MSFT data for 2016-05...\n",
      "✅ Saved MSFT data for 2016-05\n",
      "📊 Fetching MSFT data for 2016-06...\n",
      "✅ Saved MSFT data for 2016-06\n",
      "📊 Fetching MSFT data for 2016-07...\n",
      "✅ Saved MSFT data for 2016-07\n",
      "📊 Fetching MSFT data for 2016-08...\n",
      "✅ Saved MSFT data for 2016-08\n",
      "📊 Fetching MSFT data for 2016-09...\n",
      "✅ Saved MSFT data for 2016-09\n",
      "📊 Fetching MSFT data for 2016-10...\n",
      "✅ Saved MSFT data for 2016-10\n",
      "📊 Fetching MSFT data for 2016-11...\n",
      "✅ Saved MSFT data for 2016-11\n",
      "📊 Fetching MSFT data for 2016-12...\n",
      "✅ Saved MSFT data for 2016-12\n",
      "📊 Fetching MSFT data for 2017-01...\n",
      "✅ Saved MSFT data for 2017-01\n",
      "📊 Fetching MSFT data for 2017-02...\n",
      "✅ Saved MSFT data for 2017-02\n",
      "📊 Fetching MSFT data for 2017-03...\n",
      "✅ Saved MSFT data for 2017-03\n",
      "📊 Fetching MSFT data for 2017-04...\n",
      "✅ Saved MSFT data for 2017-04\n",
      "📊 Fetching MSFT data for 2017-05...\n",
      "✅ Saved MSFT data for 2017-05\n",
      "📊 Fetching MSFT data for 2017-06...\n",
      "✅ Saved MSFT data for 2017-06\n",
      "📊 Fetching MSFT data for 2017-07...\n",
      "✅ Saved MSFT data for 2017-07\n",
      "📊 Fetching MSFT data for 2017-08...\n",
      "✅ Saved MSFT data for 2017-08\n",
      "📊 Fetching MSFT data for 2017-09...\n",
      "✅ Saved MSFT data for 2017-09\n",
      "📊 Fetching MSFT data for 2017-10...\n",
      "✅ Saved MSFT data for 2017-10\n",
      "📊 Fetching MSFT data for 2017-11...\n",
      "✅ Saved MSFT data for 2017-11\n",
      "📊 Fetching MSFT data for 2017-12...\n",
      "✅ Saved MSFT data for 2017-12\n",
      "📊 Fetching MSFT data for 2018-01...\n",
      "❌ Error fetching MSFT data for 2018-01: We have detected your API key as SRKSUHDAW2DL6Y3B and our standard API rate limit is 25 requests per day. Please subscribe to any of the premium plans at https://www.alphavantage.co/premium/ to instantly remove all daily rate limits.\n",
      "⚠️ Stopping process. Rerun to continue from last successful month.\n",
      "\n",
      "🚀 Starting data collection for NVDA\n",
      "📊 Fetching NVDA data for 2014-01...\n",
      "❌ Error fetching NVDA data for 2014-01: We have detected your API key as SRKSUHDAW2DL6Y3B and our standard API rate limit is 25 requests per day. Please subscribe to any of the premium plans at https://www.alphavantage.co/premium/ to instantly remove all daily rate limits.\n",
      "⚠️ Stopping process. Rerun to continue from last successful month.\n",
      "\n",
      "🚀 Starting data collection for AMZN\n",
      "📊 Fetching AMZN data for 2014-01...\n",
      "❌ Error fetching AMZN data for 2014-01: We have detected your API key as SRKSUHDAW2DL6Y3B and our standard API rate limit is 25 requests per day. Please subscribe to any of the premium plans at https://www.alphavantage.co/premium/ to instantly remove all daily rate limits.\n",
      "⚠️ Stopping process. Rerun to continue from last successful month.\n",
      "\n",
      "🚀 Starting data collection for GOOGL\n",
      "📊 Fetching GOOGL data for 2014-01...\n",
      "❌ Error fetching GOOGL data for 2014-01: We have detected your API key as SRKSUHDAW2DL6Y3B and our standard API rate limit is 25 requests per day. Please subscribe to any of the premium plans at https://www.alphavantage.co/premium/ to instantly remove all daily rate limits.\n",
      "⚠️ Stopping process. Rerun to continue from last successful month.\n",
      "\n",
      "🚀 Starting data collection for META\n",
      "📊 Fetching META data for 2014-01...\n",
      "❌ Error fetching META data for 2014-01: We have detected your API key as SRKSUHDAW2DL6Y3B and our standard API rate limit is 25 requests per day. Please subscribe to any of the premium plans at https://www.alphavantage.co/premium/ to instantly remove all daily rate limits.\n",
      "⚠️ Stopping process. Rerun to continue from last successful month.\n",
      "\n",
      "🚀 Starting data collection for TSLA\n",
      "📊 Fetching TSLA data for 2014-01...\n",
      "❌ Error fetching TSLA data for 2014-01: We have detected your API key as SRKSUHDAW2DL6Y3B and our standard API rate limit is 25 requests per day. Please subscribe to any of the premium plans at https://www.alphavantage.co/premium/ to instantly remove all daily rate limits.\n",
      "⚠️ Stopping process. Rerun to continue from last successful month.\n",
      "\n",
      "🚀 Starting data collection for AMD\n",
      "\n",
      "🚀 Starting data collection for NFLX\n",
      "📊 Fetching NFLX data for 2014-01...\n",
      "❌ Error fetching NFLX data for 2014-01: We have detected your API key as SRKSUHDAW2DL6Y3B and our standard API rate limit is 25 requests per day. Please subscribe to any of the premium plans at https://www.alphavantage.co/premium/ to instantly remove all daily rate limits.\n",
      "⚠️ Stopping process. Rerun to continue from last successful month.\n",
      "\n",
      "🚀 Starting data collection for AVGO\n",
      "📊 Fetching AVGO data for 2014-01...\n",
      "❌ Error fetching AVGO data for 2014-01: We have detected your API key as SRKSUHDAW2DL6Y3B and our standard API rate limit is 25 requests per day. Please subscribe to any of the premium plans at https://www.alphavantage.co/premium/ to instantly remove all daily rate limits.\n",
      "⚠️ Stopping process. Rerun to continue from last successful month.\n",
      "✅ All stock data fetching processes completed.\n"
     ]
    }
   ],
   "source": [
    "# Alpha Vantage API Key\n",
    "api_key = \"SRKSUHDAW2DL6Y3B\"\n",
    "ts = TimeSeries(key=api_key, output_format=\"pandas\")\n",
    "\n",
    "# List of stocks\n",
    "stock_list = [\"AAPL\", \"MSFT\", \"NVDA\", \"AMZN\", \"GOOGL\", \"META\", \"TSLA\", \"AMD\", \"NFLX\", \"AVGO\"]  # Add more as needed\n",
    "\n",
    "# Loop through each stock\n",
    "for symbol in stock_list:\n",
    "    print(f\"\\n🚀 Starting data collection for {symbol}\")\n",
    "\n",
    "    output_dir = f\"{symbol}_30min_data\"\n",
    "    missing_months_file = os.path.join(output_dir, \"missing_months_10yr.txt\")\n",
    "\n",
    "    # Check if missing months file exists\n",
    "    try:\n",
    "        with open(missing_months_file, \"r\") as f:\n",
    "            months_to_fetch = f.read().splitlines()\n",
    "    except FileNotFoundError:\n",
    "        print(f\"✅ No missing months found for {symbol}. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    # Fetch data month-by-month\n",
    "    for month in months_to_fetch:\n",
    "        output_file = os.path.join(output_dir, f\"{symbol}_30min_{month}.csv\")\n",
    "\n",
    "        try:\n",
    "            print(f\"📊 Fetching {symbol} data for {month}...\")\n",
    "\n",
    "            # Fetch data from Alpha Vantage\n",
    "            data, _ = ts.get_intraday(\n",
    "                symbol=symbol,\n",
    "                interval=\"30min\",\n",
    "                month=month,\n",
    "                adjusted=True,\n",
    "                extended_hours=False,\n",
    "                outputsize=\"full\"\n",
    "            )\n",
    "\n",
    "            # Convert index to datetime\n",
    "            data.index = pd.to_datetime(data.index)\n",
    "            data.columns = [\"Open\", \"High\", \"Low\", \"Close\", \"Volume\"]\n",
    "\n",
    "            # Save to CSV\n",
    "            data.to_csv(output_file)\n",
    "            print(f\"✅ Saved {symbol} data for {month}\")\n",
    "            time.sleep(12)  # Respect API rate limit\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error fetching {symbol} data for {month}: {e}\")\n",
    "            print(\"⚠️ Stopping process. Rerun to continue from last successful month.\")\n",
    "            break  # Break the month loop if error occurs\n",
    "\n",
    "print(\"✅ All stock data fetching processes completed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d2573bf-a699-46f0-bfbf-e3a88bdef2a4",
   "metadata": {},
   "source": [
    "### Merge All Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff477a26-b77c-4a85-8a2c-b1fb68aa0569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔄 Merging 30-minute data for AAPL...\n",
      "✅ Merged AAPL data saved to 30min_data\\AAPL.csv\n",
      "\n",
      "🔄 Merging 30-minute data for MSFT...\n",
      "✅ Merged MSFT data saved to 30min_data\\MSFT.csv\n",
      "\n",
      "🔄 Merging 30-minute data for NVDA...\n",
      "✅ Merged NVDA data saved to 30min_data\\NVDA.csv\n",
      "\n",
      "🔄 Merging 30-minute data for AMZN...\n",
      "✅ Merged AMZN data saved to 30min_data\\AMZN.csv\n",
      "\n",
      "🔄 Merging 30-minute data for GOOGL...\n",
      "✅ Merged GOOGL data saved to 30min_data\\GOOGL.csv\n",
      "\n",
      "🔄 Merging 30-minute data for META...\n",
      "✅ Merged META data saved to 30min_data\\META.csv\n",
      "\n",
      "🔄 Merging 30-minute data for TSLA...\n",
      "✅ Merged TSLA data saved to 30min_data\\TSLA.csv\n",
      "\n",
      "🔄 Merging 30-minute data for AMD...\n",
      "✅ Merged AMD data saved to 30min_data\\AMD.csv\n",
      "\n",
      "🔄 Merging 30-minute data for NFLX...\n",
      "✅ Merged NFLX data saved to 30min_data\\NFLX.csv\n",
      "\n",
      "🔄 Merging 30-minute data for AVGO...\n",
      "✅ Merged AVGO data saved to 30min_data\\AVGO.csv\n"
     ]
    }
   ],
   "source": [
    "# === List of all stock symbols you want to merge ===\n",
    "stock_list = [\"AAPL\", \"MSFT\", \"NVDA\", \"AMZN\", \"GOOGL\", \"META\", \"TSLA\", \"AMD\", \"NFLX\", \"AVGO\"]  # Add/remove symbols as needed\n",
    "\n",
    "# Create output directory for merged data\n",
    "output_dir = \"30min_data\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Loop through each stock symbol\n",
    "for symbol in stock_list:\n",
    "    print(f\"\\n🔄 Merging 30-minute data for {symbol}...\")\n",
    "\n",
    "    # Input directory for this stock\n",
    "    data_dir = f\"{symbol}_30min_data\"\n",
    "\n",
    "    # Find monthly CSV files\n",
    "    csv_files = [f for f in os.listdir(data_dir) if f.endswith(\".csv\") and f.startswith(f\"{symbol}_30min_\")]\n",
    "    csv_files.sort()  # Ensure chronological order\n",
    "\n",
    "    merged_df = pd.DataFrame()\n",
    "\n",
    "    # Load and concatenate each file\n",
    "    for file in csv_files:\n",
    "        file_path = os.path.join(data_dir, file)\n",
    "        df = pd.read_csv(file_path, parse_dates=[\"date\"], index_col=\"date\")\n",
    "        merged_df = pd.concat([merged_df, df])\n",
    "\n",
    "    # Sort the merged data\n",
    "    merged_df.sort_index(inplace=True)\n",
    "\n",
    "    # Save to final CSV\n",
    "    output_file = os.path.join(output_dir, f\"{symbol}.csv\")\n",
    "    merged_df.to_csv(output_file)\n",
    "\n",
    "    print(f\"✅ Merged {symbol} data saved to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3989aac2-6451-4bba-99b1-aa839f26ebf6",
   "metadata": {},
   "source": [
    "### yfinance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a86b0b-17d9-4989-9ca5-c441986e2918",
   "metadata": {},
   "source": [
    "#### Collect Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30cf5db-7f2a-4ea8-bcf9-66cf1fc934b3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define stock symbols (Choose tech stocks or other relevant ones)\n",
    "stock_symbols = [\"AAPL\", \"MSFT\", \"NVDA\", \"AMZN\", \"GOOGL\", \"META\", \"TSLA\", \"AMD\", \"NFLX\", \"AVGO\"]\n",
    "\n",
    "# Define output directory\n",
    "output_dir = \"yfinance\"\n",
    "os.makedirs(output_dir, exist_ok=True)  # Create directory if it doesn't exist\n",
    "\n",
    "# Function to fetch full historical stock data\n",
    "def fetch_full_stock_data(stock_symbol):\n",
    "    print(f\"📊 Fetching full historical data for {stock_symbol}...\")\n",
    "\n",
    "    df = yf.download(stock_symbol, start=\"1900-01-01\", interval=\"1d\")  # Fetch from the first available date\n",
    "\n",
    "    if df.empty:\n",
    "        print(f\"⚠️ No data found for {stock_symbol}!\")\n",
    "        return\n",
    "\n",
    "    # Save to CSV inside the yfinance directory\n",
    "    file_name = os.path.join(output_dir, f\"{stock_symbol}_full_history.csv\")\n",
    "    df.to_csv(file_name)\n",
    "\n",
    "    print(f\"✅ {stock_symbol} full history saved as {file_name}\")\n",
    "\n",
    "# Fetch data for all selected stocks\n",
    "for stock in stock_symbols:\n",
    "    fetch_full_stock_data(stock)\n",
    "\n",
    "print(\"📊 All stock historical data has been collected and saved in /yfinance/.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07001218-f02a-4e45-a906-527f4a9d74ae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define input and output directories\n",
    "input_dir = \"yfinance\"\n",
    "output_dir = \"cleaned_data\"\n",
    "os.makedirs(output_dir, exist_ok=True)  # Create output directory if it doesn't exist\n",
    "\n",
    "# List all CSV files in the yfinance folder\n",
    "csv_files = [f for f in os.listdir(input_dir) if f.endswith(\".csv\")]\n",
    "\n",
    "# Function to check stock data for issues\n",
    "def check_stock_data(file_path):\n",
    "    df = pd.read_csv(file_path, skiprows=2)  # Skip first two header rows\n",
    "\n",
    "    # Rename columns properly\n",
    "    df.columns = [\"Date\", \"Close\", \"High\", \"Low\", \"Open\", \"Volume\"]\n",
    "\n",
    "    # Convert Date column to datetime format\n",
    "    df[\"Date\"] = pd.to_datetime(df[\"Date\"], errors='coerce')\n",
    "\n",
    "    # Convert numeric columns to float\n",
    "    numeric_cols = [\"Close\", \"High\", \"Low\", \"Open\", \"Volume\"]\n",
    "    df[numeric_cols] = df[numeric_cols].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "    # Check for duplicates\n",
    "    duplicate_count = df.duplicated(subset=[\"Date\"]).sum()\n",
    "\n",
    "    # Check for missing values\n",
    "    missing_values = df.isnull().sum()\n",
    "\n",
    "    print(f\"\\n📊 Checking {file_path}...\")\n",
    "    print(f\"📅 Date Range: {df['Date'].min()} to {df['Date'].max()}\")\n",
    "    print(f\"🔄 Duplicate Dates: {duplicate_count}\")\n",
    "    print(\"❗ Missing Values Per Column:\\n\", missing_values)\n",
    "\n",
    "    return df, duplicate_count, missing_values\n",
    "\n",
    "# Function to clean and save stock data\n",
    "def clean_stock_data(df, output_path):\n",
    "    # Sort by date\n",
    "    df.sort_values(by=\"Date\", ascending=True, inplace=True)\n",
    "\n",
    "    # Save the cleaned file without dropping duplicates/missing values\n",
    "    df.to_csv(output_path, index=False)\n",
    "    print(f\"✅ Cleaned data saved as: {output_path}\")\n",
    "\n",
    "# Process all CSV files in yfinance directory\n",
    "for file in csv_files:\n",
    "    input_file_path = os.path.join(input_dir, file)\n",
    "    output_file_path = os.path.join(output_dir, file.replace(\".csv\", \"_cleaned.csv\"))\n",
    "    \n",
    "    df, duplicate_count, missing_values = check_stock_data(input_file_path)\n",
    "    \n",
    "    # Only save the cleaned file (without dropping data)\n",
    "    clean_stock_data(df, output_file_path)\n",
    "\n",
    "print(\"\\n✅ All stock data has been checked and saved in the 'cleaned_data/' folder.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d6d1ac-c3bf-4364-b169-d73d331b4822",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b26d9ac-8039-4532-8898-32cd4968a16b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d001b954-7f6b-449f-b1cc-2e4ada7b9071",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "124c7652-3b4c-417e-9557-63db46968e11",
   "metadata": {},
   "source": [
    "#### Avoid this first Check Missing Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d92dab2d-d813-48f1-a2e9-8dfdc0d21a7b",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'AAPL_historical_data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAAPL_historical_data.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# Replace with any stock CSV file\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(df\u001b[38;5;241m.\u001b[39minfo())  \u001b[38;5;66;03m# Check data types and missing values\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(df\u001b[38;5;241m.\u001b[39mhead())\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\FYP\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\FYP\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\FYP\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\FYP\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1881\u001b[0m     f,\n\u001b[0;32m   1882\u001b[0m     mode,\n\u001b[0;32m   1883\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1884\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1885\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m   1886\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[0;32m   1887\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1888\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1889\u001b[0m )\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\FYP\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    874\u001b[0m             handle,\n\u001b[0;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    876\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    877\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    879\u001b[0m         )\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'AAPL_historical_data.csv'"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"AAPL_historical_data.csv\")  # Replace with any stock CSV file\n",
    "print(df.info())  # Check data types and missing values\n",
    "print(df.head())  # Preview first few rows\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "330a2118-505f-4d74-98ca-74a61ab73595",
   "metadata": {},
   "source": [
    "## News Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86c110e9-5b50-41ad-858d-66a9290ab827",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "News data collected and saved to 'tech_stock_news.csv'.\n"
     ]
    }
   ],
   "source": [
    "# Your NewsAPI Key\n",
    "api_key = \"31dbe344e851496e950dc899ab1d0e93\"\n",
    "\n",
    "# List of tech stocks to search for\n",
    "tech_stocks = [\"Apple\", \"Microsoft\", \"Nvidia\", \"Amazon\", \"Google\", \"Meta\", \"Tesla\", \"AMD\", \"Netflix\", \"Broadcom\"]\n",
    "\n",
    "# Date range for news (last 7 days)\n",
    "end_date = datetime.today().strftime('%Y-%m-%d')\n",
    "start_date = (datetime.today() - timedelta(days=7)).strftime('%Y-%m-%d')\n",
    "\n",
    "# Function to fetch news for each stock\n",
    "def fetch_news(stock):\n",
    "    url = f\"https://newsapi.org/v2/everything?q={stock}&language=en&from={start_date}&to={end_date}&sortBy=publishedAt&apiKey={api_key}\"\n",
    "    response = requests.get(url)\n",
    "    return response.json()\n",
    "\n",
    "# Collect news for all stocks\n",
    "news_data = []\n",
    "for stock in tech_stocks:\n",
    "    data = fetch_news(stock)\n",
    "    if \"articles\" in data:\n",
    "        for article in data[\"articles\"]:\n",
    "            news_data.append({\n",
    "                \"Stock\": stock,\n",
    "                \"Title\": article[\"title\"],\n",
    "                \"content\": article[\"content\"],\n",
    "                \"Source\": article[\"source\"][\"name\"],\n",
    "                \"Published At\": article[\"publishedAt\"],\n",
    "                \"URL\": article[\"url\"]\n",
    "            })\n",
    "\n",
    "# Convert to DataFrame\n",
    "df_news = pd.DataFrame(news_data)\n",
    "\n",
    "# Save to CSV\n",
    "df_news.to_csv(\"tech_stock_news.csv\", index=False)\n",
    "\n",
    "print(\"News data collected and saved to 'tech_stock_news.csv'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9691011a-fe2f-4147-b2ff-b971f9bd5c2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Stock                                              Title  \\\n",
      "0  Apple        Veronica Mars Season 1-4 $4.99 via Apple TV   \n",
      "1  Apple  Protecting your iCloud data after Apple’s Adva...   \n",
      "2  Apple  Praying through Weaknesses as a Couple - Cross...   \n",
      "3  Apple  This hybrid smartwatch finally convinced me to...   \n",
      "4  Apple  Apple's New Passwords App Left Users Exposed T...   \n",
      "\n",
      "                                             content             Source  \\\n",
      "0  This collaborative space allows users to contr...     Slickdeals.net   \n",
      "1  Advanced Data Protection (ADP) secures iCloud ...  Help Net Security   \n",
      "2  Praying through Weaknesses as a CoupleBy Lynet...      Crosswalk.com   \n",
      "3  I used dozens of Wear OS smartwatches over the...    Android Central   \n",
      "4  Security researchers found that the Passwords ...         Biztoc.com   \n",
      "\n",
      "           Published At                                                URL  \n",
      "0  2025-03-19T05:01:02Z  https://slickdeals.net/f/18188056-veronica-mar...  \n",
      "1  2025-03-19T05:00:37Z  https://www.helpnetsecurity.com/2025/03/19/pro...  \n",
      "2  2025-03-19T05:00:00Z  https://www.crosswalk.com/devotionals/crosswal...  \n",
      "3  2025-03-19T04:48:02Z  https://www.androidcentral.com/wearables/withi...  \n",
      "4  2025-03-19T04:47:36Z              https://biztoc.com/x/257dd0a34ee8f6de  \n"
     ]
    }
   ],
   "source": [
    "# Load the collected news data\n",
    "df_news = pd.read_csv(\"tech_stock_news.csv\")\n",
    "\n",
    "# Display first few rows\n",
    "print(df_news.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91525d5b-37da-426d-9be9-7e3037522475",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "34f9bbc3-2532-4dc1-93b5-f2148c1a4bb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data cleaned and saved.\n"
     ]
    }
   ],
   "source": [
    "def clean_text(text):\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    text = re.sub(r'\\s+', ' ', text)  # Remove extra spaces\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n",
    "    text = text.strip()  # Remove leading/trailing spaces\n",
    "    return text\n",
    "\n",
    "# Apply cleaning\n",
    "df_news[\"Cleaned_Title\"] = df_news[\"Title\"].apply(clean_text)\n",
    "\n",
    "# Save cleaned data\n",
    "df_news.to_csv(\"cleaned_tech_stock_news1.csv\", index=False)\n",
    "\n",
    "print(\"Data cleaned and saved.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca1e3900-361b-408d-b701-123485429416",
   "metadata": {},
   "source": [
    "# Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ef9982-21a0-4f33-be86-0fb25f5067cf",
   "metadata": {},
   "source": [
    "## FinBERT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0f1c7325-9cd2-42aa-9dc9-cd634997ee4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load FinBERT tokenizer & model\n",
    "tokenizer = BertTokenizer.from_pretrained(\"yiyanghkust/finbert-tone\")\n",
    "model = BertForSequenceClassification.from_pretrained(\"yiyanghkust/finbert-tone\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0105c8e7-83e2-4c46-b1d9-2430b70ae25d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment: Neutral\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def predict_sentiment(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=512)\n",
    "    outputs = model(**inputs)\n",
    "    probs = F.softmax(outputs.logits, dim=-1)\n",
    "\n",
    "    # Labels: 0 = Negative, 1 = Neutral, 2 = Positive\n",
    "    labels = [\"Negative\", \"Neutral\", \"Positive\"]\n",
    "    sentiment = labels[torch.argmax(probs).item()]\n",
    "    \n",
    "    return sentiment\n",
    "\n",
    "# Test on an example headline\n",
    "example_headline = \"Apple stock soars as earnings beat expectations\"\n",
    "print(f\"Sentiment: {predict_sentiment(example_headline)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b7d7e2fe-9262-4495-b15b-b81424125fe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Removed invalid rows. Remaining data: 986 rows.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load dataset\n",
    "df_news = pd.read_csv(\"cleaned_tech_stock_news1.csv\")\n",
    "\n",
    "# Remove rows where \"Cleaned_Title\" is NaN or not a string\n",
    "df_news = df_news.dropna(subset=[\"Cleaned_Title\"])  # Drop missing values\n",
    "df_news = df_news[df_news[\"Cleaned_Title\"].apply(lambda x: isinstance(x, str))]  # Keep only string values\n",
    "\n",
    "# Save cleaned dataset\n",
    "df_news.to_csv(\"cleaned_tech_stock_news_filtered.csv\", index=False)\n",
    "\n",
    "print(f\"✅ Removed invalid rows. Remaining data: {len(df_news)} rows.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d430b25c-e584-4256-ba41-cf46bcc255ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Removed non-English titles. Remaining rows: 894\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from langdetect import detect\n",
    "\n",
    "# Load dataset\n",
    "df_news = pd.read_csv(\"cleaned_tech_stock_news1.csv\")\n",
    "\n",
    "# Function to detect language\n",
    "def is_english(text):\n",
    "    try:\n",
    "        return detect(text) == \"en\"  # Keep only English text\n",
    "    except:\n",
    "        return False  # If detection fails, remove the row\n",
    "\n",
    "# Apply language filter\n",
    "df_news = df_news[df_news[\"Cleaned_Title\"].apply(is_english)]\n",
    "\n",
    "# Save cleaned dataset\n",
    "df_news.to_csv(\"cleaned_tech_stock_news_english.csv\", index=False)\n",
    "\n",
    "print(f\"✅ Removed non-English titles. Remaining rows: {len(df_news)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cb9455d7-6c7f-49a6-a38b-8110bca72520",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment analysis complete. Results saved.\n"
     ]
    }
   ],
   "source": [
    "df_news = pd.read_csv(\"cleaned_tech_stock_news_filtered.csv\")\n",
    "\n",
    "# Apply sentiment analysis to each headline\n",
    "df_news[\"Sentiment\"] = df_news[\"Cleaned_Title\"].apply(predict_sentiment)\n",
    "\n",
    "# Save results\n",
    "df_news.to_csv(\"news_sentiment_analysis1.csv\", index=False)\n",
    "\n",
    "print(\"Sentiment analysis complete. Results saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4b666c7b-d058-4274-b5b9-43620e3a0cc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment\n",
      "Negative    723\n",
      "Neutral     150\n",
      "Positive    113\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset with sentiment analysis results\n",
    "df_news = pd.read_csv(\"news_sentiment_analysis1.csv\")\n",
    "\n",
    "# Count the occurrences of each sentiment category\n",
    "sentiment_counts = df_news[\"Sentiment\"].value_counts()\n",
    "\n",
    "# Display results\n",
    "print(sentiment_counts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f54411f-100c-4b2b-9633-7cd5bf7eb9b9",
   "metadata": {},
   "source": [
    "# Chart Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ce870af-fdc3-4db8-8314-7bef5fc84835",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'AAPL_30min_data_test/AAPL_30min_2024-01.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Load collected AAPL data\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAAPL_30min_data_test/AAPL_30min_2024-01.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, parse_dates\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m\"\u001b[39m], index_col\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Select a specific period to visualize (e.g., 1 week in 2024)\u001b[39;00m\n\u001b[0;32m      5\u001b[0m df_sample \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mloc[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2024-01-02\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2024-01-10\u001b[39m\u001b[38;5;124m\"\u001b[39m]  \u001b[38;5;66;03m# Change dates as needed\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\FYP\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\FYP\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\FYP\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\FYP\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1881\u001b[0m     f,\n\u001b[0;32m   1882\u001b[0m     mode,\n\u001b[0;32m   1883\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1884\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1885\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m   1886\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[0;32m   1887\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1888\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1889\u001b[0m )\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\FYP\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    874\u001b[0m             handle,\n\u001b[0;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    876\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    877\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    879\u001b[0m         )\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'AAPL_30min_data_test/AAPL_30min_2024-01.csv'"
     ]
    }
   ],
   "source": [
    "# Load collected AAPL data\n",
    "df = pd.read_csv(\"AAPL_30min_data_test/AAPL_30min_2024-01.csv\", parse_dates=[\"date\"], index_col=\"date\")\n",
    "\n",
    "# Select a specific period to visualize (e.g., 1 week in 2024)\n",
    "df_sample = df.loc[\"2024-01-02\":\"2024-01-10\"]  # Change dates as needed\n",
    "\n",
    "# Ensure the DataFrame has the correct columns\n",
    "df_sample = df_sample[[\"Open\", \"High\", \"Low\", \"Close\", \"Volume\"]]\n",
    "\n",
    "# Plot candlestick chart\n",
    "mpf.plot(\n",
    "    df_sample,\n",
    "    type=\"candle\",\n",
    "    style=\"yahoo\",\n",
    "    title=\"AAPL Candlestick Chart (1 Week)\",\n",
    "    ylabel=\"Price (USD)\",\n",
    "    volume=True,\n",
    "    figratio=(12,6),  # Adjust figure size\n",
    "    #mav=(5, 10),  # Add moving averages (5-day & 10-day)\n",
    "    tight_layout=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58a8d5b-50e6-4988-89a3-bda7b1983f8d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

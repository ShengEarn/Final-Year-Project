{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b09e7e71-4bd0-4b10-a5f0-6db3f76fc269",
   "metadata": {},
   "source": [
    "# Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8105b0e-f5fc-420e-8890-65b29f0ba1bb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install alpha_vantage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d28813-f656-4b20-ba0e-08fffef6cae8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install mplfinance pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2276bc0f-371b-4e4a-b017-7355d6448b04",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install fastapi uvicorn pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7335ede-2176-4fe6-8d12-e4c6b6466007",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langdetect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "979e31c2-72ca-4caf-8fca-38a02ada5d76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ta\n",
      "  Downloading ta-0.11.0.tar.gz (25 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: numpy in c:\\users\\sheng\\anaconda3\\envs\\fyp\\lib\\site-packages (from ta) (2.0.2)\n",
      "Requirement already satisfied: pandas in c:\\users\\sheng\\anaconda3\\envs\\fyp\\lib\\site-packages (from ta) (2.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\sheng\\anaconda3\\envs\\fyp\\lib\\site-packages (from pandas->ta) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\sheng\\anaconda3\\envs\\fyp\\lib\\site-packages (from pandas->ta) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\sheng\\anaconda3\\envs\\fyp\\lib\\site-packages (from pandas->ta) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\sheng\\anaconda3\\envs\\fyp\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->ta) (1.16.0)\n",
      "Building wheels for collected packages: ta\n",
      "  Building wheel for ta (setup.py): started\n",
      "  Building wheel for ta (setup.py): finished with status 'done'\n",
      "  Created wheel for ta: filename=ta-0.11.0-py3-none-any.whl size=29423 sha256=4122e65eb6db0ffb57fd205c8128e91972fa2c7ea940223848e37132a512ece2\n",
      "  Stored in directory: c:\\users\\sheng\\appdata\\local\\pip\\cache\\wheels\\5c\\a1\\5f\\c6b85a7d9452057be4ce68a8e45d77ba34234a6d46581777c6\n",
      "Successfully built ta\n",
      "Installing collected packages: ta\n",
      "Successfully installed ta-0.11.0\n"
     ]
    }
   ],
   "source": [
    "!pip install ta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ff189dc0-f938-4f75-a08f-103108c1da9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\sheng\\anaconda3\\envs\\fyp\\lib\\site-packages (2.18.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.18.0 in c:\\users\\sheng\\anaconda3\\envs\\fyp\\lib\\site-packages (from tensorflow) (2.18.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\sheng\\anaconda3\\envs\\fyp\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\sheng\\anaconda3\\envs\\fyp\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\sheng\\anaconda3\\envs\\fyp\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\sheng\\anaconda3\\envs\\fyp\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\sheng\\anaconda3\\envs\\fyp\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\sheng\\anaconda3\\envs\\fyp\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\sheng\\anaconda3\\envs\\fyp\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\sheng\\anaconda3\\envs\\fyp\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (24.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\sheng\\anaconda3\\envs\\fyp\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (5.29.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\sheng\\anaconda3\\envs\\fyp\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\sheng\\anaconda3\\envs\\fyp\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (72.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\sheng\\anaconda3\\envs\\fyp\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\sheng\\anaconda3\\envs\\fyp\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\sheng\\anaconda3\\envs\\fyp\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\sheng\\anaconda3\\envs\\fyp\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.17.2)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\sheng\\anaconda3\\envs\\fyp\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.70.0)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in c:\\users\\sheng\\anaconda3\\envs\\fyp\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in c:\\users\\sheng\\anaconda3\\envs\\fyp\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.8.0)\n",
      "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in c:\\users\\sheng\\anaconda3\\envs\\fyp\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.0.2)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\sheng\\anaconda3\\envs\\fyp\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.13.0)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in c:\\users\\sheng\\anaconda3\\envs\\fyp\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.4.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\sheng\\anaconda3\\envs\\fyp\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.18.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: rich in c:\\users\\sheng\\anaconda3\\envs\\fyp\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (13.9.4)\n",
      "Requirement already satisfied: namex in c:\\users\\sheng\\anaconda3\\envs\\fyp\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\sheng\\anaconda3\\envs\\fyp\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.14.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\sheng\\anaconda3\\envs\\fyp\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sheng\\anaconda3\\envs\\fyp\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\sheng\\anaconda3\\envs\\fyp\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sheng\\anaconda3\\envs\\fyp\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2025.1.31)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\sheng\\anaconda3\\envs\\fyp\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\sheng\\anaconda3\\envs\\fyp\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\sheng\\anaconda3\\envs\\fyp\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\sheng\\anaconda3\\envs\\fyp\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\sheng\\anaconda3\\envs\\fyp\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\sheng\\anaconda3\\envs\\fyp\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\sheng\\anaconda3\\envs\\fyp\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c2a09800-9073-4bc6-a11a-a39b492dc553",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import requests\n",
    "from datetime import datetime, timedelta\n",
    "import re\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "import torch\n",
    "import os\n",
    "from alpha_vantage.timeseries import TimeSeries\n",
    "import time\n",
    "import mplfinance as mpf\n",
    "import ta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c99692c-1981-46d0-ac93-65f348b7a02c",
   "metadata": {},
   "source": [
    "# Data Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc4db003-6bff-4ea4-b04d-6a959e35c323",
   "metadata": {},
   "source": [
    "## Stock Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d053816-e892-4c45-8182-eb85ab2d5484",
   "metadata": {},
   "source": [
    "### Alpha Vantage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46573ca0-d0a3-4e46-9815-24ff46f63862",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Api Key\n",
    "api = X29K76EJP70V2JGP\n",
    "FOD3B9ESO9W0Y9UE\n",
    "SRKSUHDAW2DL6Y3B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca69f212-5610-45e1-a3a3-35de3385de1a",
   "metadata": {},
   "source": [
    "#### 10 year"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19711c21-5fea-44d9-8798-45e4bdd7e242",
   "metadata": {},
   "source": [
    "Check Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b78edae-ee62-49f0-b213-8449a32f39e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📦 Checking data for AAPL...\n",
      "✅ AAPL already marked as complete. Skipping.\n",
      "\n",
      "📦 Checking data for MSFT...\n",
      "✅ MSFT 2014-01 data is already complete.\n",
      "✅ MSFT 2014-02 data is already complete.\n",
      "✅ MSFT 2014-03 data is already complete.\n",
      "✅ MSFT 2014-04 data is already complete.\n",
      "✅ MSFT 2014-05 data is already complete.\n",
      "✅ MSFT 2014-06 data is already complete.\n",
      "✅ MSFT 2014-07 data is already complete.\n",
      "✅ MSFT 2014-08 data is already complete.\n",
      "✅ MSFT 2014-09 data is already complete.\n",
      "✅ MSFT 2014-10 data is already complete.\n",
      "✅ MSFT 2014-11 data is already complete.\n",
      "✅ MSFT 2014-12 data is already complete.\n",
      "✅ MSFT 2015-01 data is already complete.\n",
      "✅ MSFT 2015-02 data is already complete.\n",
      "✅ MSFT 2015-03 data is already complete.\n",
      "✅ MSFT 2015-04 data is already complete.\n",
      "✅ MSFT 2015-05 data is already complete.\n",
      "✅ MSFT 2015-06 data is already complete.\n",
      "✅ MSFT 2015-07 data is already complete.\n",
      "✅ MSFT 2015-08 data is already complete.\n",
      "✅ MSFT 2015-09 data is already complete.\n",
      "✅ MSFT 2015-10 data is already complete.\n",
      "✅ MSFT 2015-11 data is already complete.\n",
      "✅ MSFT 2015-12 data is already complete.\n",
      "✅ MSFT 2016-01 data is already complete.\n",
      "✅ MSFT 2016-02 data is already complete.\n",
      "✅ MSFT 2016-03 data is already complete.\n",
      "✅ MSFT 2016-04 data is already complete.\n",
      "✅ MSFT 2016-05 data is already complete.\n",
      "✅ MSFT 2016-06 data is already complete.\n",
      "✅ MSFT 2016-07 data is already complete.\n",
      "✅ MSFT 2016-08 data is already complete.\n",
      "✅ MSFT 2016-09 data is already complete.\n",
      "✅ MSFT 2016-10 data is already complete.\n",
      "✅ MSFT 2016-11 data is already complete.\n",
      "✅ MSFT 2016-12 data is already complete.\n",
      "✅ MSFT 2017-01 data is already complete.\n",
      "✅ MSFT 2017-02 data is already complete.\n",
      "✅ MSFT 2017-03 data is already complete.\n",
      "✅ MSFT 2017-04 data is already complete.\n",
      "✅ MSFT 2017-05 data is already complete.\n",
      "✅ MSFT 2017-06 data is already complete.\n",
      "✅ MSFT 2017-07 data is already complete.\n",
      "✅ MSFT 2017-08 data is already complete.\n",
      "✅ MSFT 2017-09 data is already complete.\n",
      "✅ MSFT 2017-10 data is already complete.\n",
      "✅ MSFT 2017-11 data is already complete.\n",
      "✅ MSFT 2017-12 data is already complete.\n",
      "✅ MSFT 2018-01 data is already complete.\n",
      "✅ MSFT 2018-02 data is already complete.\n",
      "✅ MSFT 2018-03 data is already complete.\n",
      "✅ MSFT 2018-04 data is already complete.\n",
      "✅ MSFT 2018-05 data is already complete.\n",
      "✅ MSFT 2018-06 data is already complete.\n",
      "✅ MSFT 2018-07 data is already complete.\n",
      "✅ MSFT 2018-08 data is already complete.\n",
      "✅ MSFT 2018-09 data is already complete.\n",
      "✅ MSFT 2018-10 data is already complete.\n",
      "✅ MSFT 2018-11 data is already complete.\n",
      "✅ MSFT 2018-12 data is already complete.\n",
      "✅ MSFT 2019-01 data is already complete.\n",
      "✅ MSFT 2019-02 data is already complete.\n",
      "✅ MSFT 2019-03 data is already complete.\n",
      "✅ MSFT 2019-04 data is already complete.\n",
      "✅ MSFT 2019-05 data is already complete.\n",
      "✅ MSFT 2019-06 data is already complete.\n",
      "✅ MSFT 2019-07 data is already complete.\n",
      "✅ MSFT 2019-08 data is already complete.\n",
      "✅ MSFT 2019-09 data is already complete.\n",
      "✅ MSFT 2019-10 data is already complete.\n",
      "✅ MSFT 2019-11 data is already complete.\n",
      "✅ MSFT 2019-12 data is already complete.\n",
      "✅ MSFT 2020-01 data is already complete.\n",
      "✅ MSFT 2020-02 data is already complete.\n",
      "❌ MSFT 2020-03 data is missing.\n",
      "❌ MSFT 2020-04 data is missing.\n",
      "❌ MSFT 2020-05 data is missing.\n",
      "❌ MSFT 2020-06 data is missing.\n",
      "❌ MSFT 2020-07 data is missing.\n",
      "❌ MSFT 2020-08 data is missing.\n",
      "❌ MSFT 2020-09 data is missing.\n",
      "❌ MSFT 2020-10 data is missing.\n",
      "❌ MSFT 2020-11 data is missing.\n",
      "❌ MSFT 2020-12 data is missing.\n",
      "❌ MSFT 2021-01 data is missing.\n",
      "❌ MSFT 2021-02 data is missing.\n",
      "❌ MSFT 2021-03 data is missing.\n",
      "❌ MSFT 2021-04 data is missing.\n",
      "❌ MSFT 2021-05 data is missing.\n",
      "❌ MSFT 2021-06 data is missing.\n",
      "❌ MSFT 2021-07 data is missing.\n",
      "❌ MSFT 2021-08 data is missing.\n",
      "❌ MSFT 2021-09 data is missing.\n",
      "❌ MSFT 2021-10 data is missing.\n",
      "❌ MSFT 2021-11 data is missing.\n",
      "❌ MSFT 2021-12 data is missing.\n",
      "❌ MSFT 2022-01 data is missing.\n",
      "❌ MSFT 2022-02 data is missing.\n",
      "❌ MSFT 2022-03 data is missing.\n",
      "❌ MSFT 2022-04 data is missing.\n",
      "❌ MSFT 2022-05 data is missing.\n",
      "❌ MSFT 2022-06 data is missing.\n",
      "❌ MSFT 2022-07 data is missing.\n",
      "❌ MSFT 2022-08 data is missing.\n",
      "❌ MSFT 2022-09 data is missing.\n",
      "❌ MSFT 2022-10 data is missing.\n",
      "❌ MSFT 2022-11 data is missing.\n",
      "❌ MSFT 2022-12 data is missing.\n",
      "❌ MSFT 2023-01 data is missing.\n",
      "❌ MSFT 2023-02 data is missing.\n",
      "❌ MSFT 2023-03 data is missing.\n",
      "❌ MSFT 2023-04 data is missing.\n",
      "❌ MSFT 2023-05 data is missing.\n",
      "❌ MSFT 2023-06 data is missing.\n",
      "❌ MSFT 2023-07 data is missing.\n",
      "❌ MSFT 2023-08 data is missing.\n",
      "❌ MSFT 2023-09 data is missing.\n",
      "❌ MSFT 2023-10 data is missing.\n",
      "❌ MSFT 2023-11 data is missing.\n",
      "❌ MSFT 2023-12 data is missing.\n",
      "❌ MSFT 2024-01 data is missing.\n",
      "❌ MSFT 2024-02 data is missing.\n",
      "❌ MSFT 2024-03 data is missing.\n",
      "❌ MSFT 2024-04 data is missing.\n",
      "❌ MSFT 2024-05 data is missing.\n",
      "❌ MSFT 2024-06 data is missing.\n",
      "❌ MSFT 2024-07 data is missing.\n",
      "❌ MSFT 2024-08 data is missing.\n",
      "❌ MSFT 2024-09 data is missing.\n",
      "❌ MSFT 2024-10 data is missing.\n",
      "❌ MSFT 2024-11 data is missing.\n",
      "❌ MSFT 2024-12 data is missing.\n",
      "📊 MSFT months that need to be fetched: ['2020-03', '2020-04', '2020-05', '2020-06', '2020-07', '2020-08', '2020-09', '2020-10', '2020-11', '2020-12', '2021-01', '2021-02', '2021-03', '2021-04', '2021-05', '2021-06', '2021-07', '2021-08', '2021-09', '2021-10', '2021-11', '2021-12', '2022-01', '2022-02', '2022-03', '2022-04', '2022-05', '2022-06', '2022-07', '2022-08', '2022-09', '2022-10', '2022-11', '2022-12', '2023-01', '2023-02', '2023-03', '2023-04', '2023-05', '2023-06', '2023-07', '2023-08', '2023-09', '2023-10', '2023-11', '2023-12', '2024-01', '2024-02', '2024-03', '2024-04', '2024-05', '2024-06', '2024-07', '2024-08', '2024-09', '2024-10', '2024-11', '2024-12']\n",
      "📝 Missing months list saved in MSFT_30min_data\\missing_months_10yr.txt\n",
      "\n",
      "📦 Checking data for NVDA...\n",
      "❌ NVDA 2014-01 data is missing.\n",
      "❌ NVDA 2014-02 data is missing.\n",
      "❌ NVDA 2014-03 data is missing.\n",
      "❌ NVDA 2014-04 data is missing.\n",
      "❌ NVDA 2014-05 data is missing.\n",
      "❌ NVDA 2014-06 data is missing.\n",
      "❌ NVDA 2014-07 data is missing.\n",
      "❌ NVDA 2014-08 data is missing.\n",
      "❌ NVDA 2014-09 data is missing.\n",
      "❌ NVDA 2014-10 data is missing.\n",
      "❌ NVDA 2014-11 data is missing.\n",
      "❌ NVDA 2014-12 data is missing.\n",
      "❌ NVDA 2015-01 data is missing.\n",
      "❌ NVDA 2015-02 data is missing.\n",
      "❌ NVDA 2015-03 data is missing.\n",
      "❌ NVDA 2015-04 data is missing.\n",
      "❌ NVDA 2015-05 data is missing.\n",
      "❌ NVDA 2015-06 data is missing.\n",
      "❌ NVDA 2015-07 data is missing.\n",
      "❌ NVDA 2015-08 data is missing.\n",
      "❌ NVDA 2015-09 data is missing.\n",
      "❌ NVDA 2015-10 data is missing.\n",
      "❌ NVDA 2015-11 data is missing.\n",
      "❌ NVDA 2015-12 data is missing.\n",
      "❌ NVDA 2016-01 data is missing.\n",
      "❌ NVDA 2016-02 data is missing.\n",
      "❌ NVDA 2016-03 data is missing.\n",
      "❌ NVDA 2016-04 data is missing.\n",
      "❌ NVDA 2016-05 data is missing.\n",
      "❌ NVDA 2016-06 data is missing.\n",
      "❌ NVDA 2016-07 data is missing.\n",
      "❌ NVDA 2016-08 data is missing.\n",
      "❌ NVDA 2016-09 data is missing.\n",
      "❌ NVDA 2016-10 data is missing.\n",
      "❌ NVDA 2016-11 data is missing.\n",
      "❌ NVDA 2016-12 data is missing.\n",
      "❌ NVDA 2017-01 data is missing.\n",
      "❌ NVDA 2017-02 data is missing.\n",
      "❌ NVDA 2017-03 data is missing.\n",
      "❌ NVDA 2017-04 data is missing.\n",
      "❌ NVDA 2017-05 data is missing.\n",
      "❌ NVDA 2017-06 data is missing.\n",
      "❌ NVDA 2017-07 data is missing.\n",
      "❌ NVDA 2017-08 data is missing.\n",
      "❌ NVDA 2017-09 data is missing.\n",
      "❌ NVDA 2017-10 data is missing.\n",
      "❌ NVDA 2017-11 data is missing.\n",
      "❌ NVDA 2017-12 data is missing.\n",
      "❌ NVDA 2018-01 data is missing.\n",
      "❌ NVDA 2018-02 data is missing.\n",
      "❌ NVDA 2018-03 data is missing.\n",
      "❌ NVDA 2018-04 data is missing.\n",
      "❌ NVDA 2018-05 data is missing.\n",
      "❌ NVDA 2018-06 data is missing.\n",
      "❌ NVDA 2018-07 data is missing.\n",
      "❌ NVDA 2018-08 data is missing.\n",
      "❌ NVDA 2018-09 data is missing.\n",
      "❌ NVDA 2018-10 data is missing.\n",
      "❌ NVDA 2018-11 data is missing.\n",
      "❌ NVDA 2018-12 data is missing.\n",
      "❌ NVDA 2019-01 data is missing.\n",
      "❌ NVDA 2019-02 data is missing.\n",
      "❌ NVDA 2019-03 data is missing.\n",
      "❌ NVDA 2019-04 data is missing.\n",
      "❌ NVDA 2019-05 data is missing.\n",
      "❌ NVDA 2019-06 data is missing.\n",
      "❌ NVDA 2019-07 data is missing.\n",
      "❌ NVDA 2019-08 data is missing.\n",
      "❌ NVDA 2019-09 data is missing.\n",
      "❌ NVDA 2019-10 data is missing.\n",
      "❌ NVDA 2019-11 data is missing.\n",
      "❌ NVDA 2019-12 data is missing.\n",
      "❌ NVDA 2020-01 data is missing.\n",
      "❌ NVDA 2020-02 data is missing.\n",
      "❌ NVDA 2020-03 data is missing.\n",
      "❌ NVDA 2020-04 data is missing.\n",
      "❌ NVDA 2020-05 data is missing.\n",
      "❌ NVDA 2020-06 data is missing.\n",
      "❌ NVDA 2020-07 data is missing.\n",
      "❌ NVDA 2020-08 data is missing.\n",
      "❌ NVDA 2020-09 data is missing.\n",
      "❌ NVDA 2020-10 data is missing.\n",
      "❌ NVDA 2020-11 data is missing.\n",
      "❌ NVDA 2020-12 data is missing.\n",
      "❌ NVDA 2021-01 data is missing.\n",
      "❌ NVDA 2021-02 data is missing.\n",
      "❌ NVDA 2021-03 data is missing.\n",
      "❌ NVDA 2021-04 data is missing.\n",
      "❌ NVDA 2021-05 data is missing.\n",
      "❌ NVDA 2021-06 data is missing.\n",
      "❌ NVDA 2021-07 data is missing.\n",
      "❌ NVDA 2021-08 data is missing.\n",
      "❌ NVDA 2021-09 data is missing.\n",
      "❌ NVDA 2021-10 data is missing.\n",
      "❌ NVDA 2021-11 data is missing.\n",
      "❌ NVDA 2021-12 data is missing.\n",
      "❌ NVDA 2022-01 data is missing.\n",
      "❌ NVDA 2022-02 data is missing.\n",
      "❌ NVDA 2022-03 data is missing.\n",
      "❌ NVDA 2022-04 data is missing.\n",
      "❌ NVDA 2022-05 data is missing.\n",
      "❌ NVDA 2022-06 data is missing.\n",
      "❌ NVDA 2022-07 data is missing.\n",
      "❌ NVDA 2022-08 data is missing.\n",
      "❌ NVDA 2022-09 data is missing.\n",
      "❌ NVDA 2022-10 data is missing.\n",
      "❌ NVDA 2022-11 data is missing.\n",
      "❌ NVDA 2022-12 data is missing.\n",
      "❌ NVDA 2023-01 data is missing.\n",
      "❌ NVDA 2023-02 data is missing.\n",
      "❌ NVDA 2023-03 data is missing.\n",
      "❌ NVDA 2023-04 data is missing.\n",
      "❌ NVDA 2023-05 data is missing.\n",
      "❌ NVDA 2023-06 data is missing.\n",
      "❌ NVDA 2023-07 data is missing.\n",
      "❌ NVDA 2023-08 data is missing.\n",
      "❌ NVDA 2023-09 data is missing.\n",
      "❌ NVDA 2023-10 data is missing.\n",
      "❌ NVDA 2023-11 data is missing.\n",
      "❌ NVDA 2023-12 data is missing.\n",
      "❌ NVDA 2024-01 data is missing.\n",
      "❌ NVDA 2024-02 data is missing.\n",
      "❌ NVDA 2024-03 data is missing.\n",
      "❌ NVDA 2024-04 data is missing.\n",
      "❌ NVDA 2024-05 data is missing.\n",
      "❌ NVDA 2024-06 data is missing.\n",
      "❌ NVDA 2024-07 data is missing.\n",
      "❌ NVDA 2024-08 data is missing.\n",
      "❌ NVDA 2024-09 data is missing.\n",
      "❌ NVDA 2024-10 data is missing.\n",
      "❌ NVDA 2024-11 data is missing.\n",
      "❌ NVDA 2024-12 data is missing.\n",
      "📊 NVDA months that need to be fetched: ['2014-01', '2014-02', '2014-03', '2014-04', '2014-05', '2014-06', '2014-07', '2014-08', '2014-09', '2014-10', '2014-11', '2014-12', '2015-01', '2015-02', '2015-03', '2015-04', '2015-05', '2015-06', '2015-07', '2015-08', '2015-09', '2015-10', '2015-11', '2015-12', '2016-01', '2016-02', '2016-03', '2016-04', '2016-05', '2016-06', '2016-07', '2016-08', '2016-09', '2016-10', '2016-11', '2016-12', '2017-01', '2017-02', '2017-03', '2017-04', '2017-05', '2017-06', '2017-07', '2017-08', '2017-09', '2017-10', '2017-11', '2017-12', '2018-01', '2018-02', '2018-03', '2018-04', '2018-05', '2018-06', '2018-07', '2018-08', '2018-09', '2018-10', '2018-11', '2018-12', '2019-01', '2019-02', '2019-03', '2019-04', '2019-05', '2019-06', '2019-07', '2019-08', '2019-09', '2019-10', '2019-11', '2019-12', '2020-01', '2020-02', '2020-03', '2020-04', '2020-05', '2020-06', '2020-07', '2020-08', '2020-09', '2020-10', '2020-11', '2020-12', '2021-01', '2021-02', '2021-03', '2021-04', '2021-05', '2021-06', '2021-07', '2021-08', '2021-09', '2021-10', '2021-11', '2021-12', '2022-01', '2022-02', '2022-03', '2022-04', '2022-05', '2022-06', '2022-07', '2022-08', '2022-09', '2022-10', '2022-11', '2022-12', '2023-01', '2023-02', '2023-03', '2023-04', '2023-05', '2023-06', '2023-07', '2023-08', '2023-09', '2023-10', '2023-11', '2023-12', '2024-01', '2024-02', '2024-03', '2024-04', '2024-05', '2024-06', '2024-07', '2024-08', '2024-09', '2024-10', '2024-11', '2024-12']\n",
      "📝 Missing months list saved in NVDA_30min_data\\missing_months_10yr.txt\n",
      "\n",
      "📦 Checking data for AMZN...\n",
      "❌ AMZN 2014-01 data is missing.\n",
      "❌ AMZN 2014-02 data is missing.\n",
      "❌ AMZN 2014-03 data is missing.\n",
      "❌ AMZN 2014-04 data is missing.\n",
      "❌ AMZN 2014-05 data is missing.\n",
      "❌ AMZN 2014-06 data is missing.\n",
      "❌ AMZN 2014-07 data is missing.\n",
      "❌ AMZN 2014-08 data is missing.\n",
      "❌ AMZN 2014-09 data is missing.\n",
      "❌ AMZN 2014-10 data is missing.\n",
      "❌ AMZN 2014-11 data is missing.\n",
      "❌ AMZN 2014-12 data is missing.\n",
      "❌ AMZN 2015-01 data is missing.\n",
      "❌ AMZN 2015-02 data is missing.\n",
      "❌ AMZN 2015-03 data is missing.\n",
      "❌ AMZN 2015-04 data is missing.\n",
      "❌ AMZN 2015-05 data is missing.\n",
      "❌ AMZN 2015-06 data is missing.\n",
      "❌ AMZN 2015-07 data is missing.\n",
      "❌ AMZN 2015-08 data is missing.\n",
      "❌ AMZN 2015-09 data is missing.\n",
      "❌ AMZN 2015-10 data is missing.\n",
      "❌ AMZN 2015-11 data is missing.\n",
      "❌ AMZN 2015-12 data is missing.\n",
      "❌ AMZN 2016-01 data is missing.\n",
      "❌ AMZN 2016-02 data is missing.\n",
      "❌ AMZN 2016-03 data is missing.\n",
      "❌ AMZN 2016-04 data is missing.\n",
      "❌ AMZN 2016-05 data is missing.\n",
      "❌ AMZN 2016-06 data is missing.\n",
      "❌ AMZN 2016-07 data is missing.\n",
      "❌ AMZN 2016-08 data is missing.\n",
      "❌ AMZN 2016-09 data is missing.\n",
      "❌ AMZN 2016-10 data is missing.\n",
      "❌ AMZN 2016-11 data is missing.\n",
      "❌ AMZN 2016-12 data is missing.\n",
      "❌ AMZN 2017-01 data is missing.\n",
      "❌ AMZN 2017-02 data is missing.\n",
      "❌ AMZN 2017-03 data is missing.\n",
      "❌ AMZN 2017-04 data is missing.\n",
      "❌ AMZN 2017-05 data is missing.\n",
      "❌ AMZN 2017-06 data is missing.\n",
      "❌ AMZN 2017-07 data is missing.\n",
      "❌ AMZN 2017-08 data is missing.\n",
      "❌ AMZN 2017-09 data is missing.\n",
      "❌ AMZN 2017-10 data is missing.\n",
      "❌ AMZN 2017-11 data is missing.\n",
      "❌ AMZN 2017-12 data is missing.\n",
      "❌ AMZN 2018-01 data is missing.\n",
      "❌ AMZN 2018-02 data is missing.\n",
      "❌ AMZN 2018-03 data is missing.\n",
      "❌ AMZN 2018-04 data is missing.\n",
      "❌ AMZN 2018-05 data is missing.\n",
      "❌ AMZN 2018-06 data is missing.\n",
      "❌ AMZN 2018-07 data is missing.\n",
      "❌ AMZN 2018-08 data is missing.\n",
      "❌ AMZN 2018-09 data is missing.\n",
      "❌ AMZN 2018-10 data is missing.\n",
      "❌ AMZN 2018-11 data is missing.\n",
      "❌ AMZN 2018-12 data is missing.\n",
      "❌ AMZN 2019-01 data is missing.\n",
      "❌ AMZN 2019-02 data is missing.\n",
      "❌ AMZN 2019-03 data is missing.\n",
      "❌ AMZN 2019-04 data is missing.\n",
      "❌ AMZN 2019-05 data is missing.\n",
      "❌ AMZN 2019-06 data is missing.\n",
      "❌ AMZN 2019-07 data is missing.\n",
      "❌ AMZN 2019-08 data is missing.\n",
      "❌ AMZN 2019-09 data is missing.\n",
      "❌ AMZN 2019-10 data is missing.\n",
      "❌ AMZN 2019-11 data is missing.\n",
      "❌ AMZN 2019-12 data is missing.\n",
      "❌ AMZN 2020-01 data is missing.\n",
      "❌ AMZN 2020-02 data is missing.\n",
      "❌ AMZN 2020-03 data is missing.\n",
      "❌ AMZN 2020-04 data is missing.\n",
      "❌ AMZN 2020-05 data is missing.\n",
      "❌ AMZN 2020-06 data is missing.\n",
      "❌ AMZN 2020-07 data is missing.\n",
      "❌ AMZN 2020-08 data is missing.\n",
      "❌ AMZN 2020-09 data is missing.\n",
      "❌ AMZN 2020-10 data is missing.\n",
      "❌ AMZN 2020-11 data is missing.\n",
      "❌ AMZN 2020-12 data is missing.\n",
      "❌ AMZN 2021-01 data is missing.\n",
      "❌ AMZN 2021-02 data is missing.\n",
      "❌ AMZN 2021-03 data is missing.\n",
      "❌ AMZN 2021-04 data is missing.\n",
      "❌ AMZN 2021-05 data is missing.\n",
      "❌ AMZN 2021-06 data is missing.\n",
      "❌ AMZN 2021-07 data is missing.\n",
      "❌ AMZN 2021-08 data is missing.\n",
      "❌ AMZN 2021-09 data is missing.\n",
      "❌ AMZN 2021-10 data is missing.\n",
      "❌ AMZN 2021-11 data is missing.\n",
      "❌ AMZN 2021-12 data is missing.\n",
      "❌ AMZN 2022-01 data is missing.\n",
      "❌ AMZN 2022-02 data is missing.\n",
      "❌ AMZN 2022-03 data is missing.\n",
      "❌ AMZN 2022-04 data is missing.\n",
      "❌ AMZN 2022-05 data is missing.\n",
      "❌ AMZN 2022-06 data is missing.\n",
      "❌ AMZN 2022-07 data is missing.\n",
      "❌ AMZN 2022-08 data is missing.\n",
      "❌ AMZN 2022-09 data is missing.\n",
      "❌ AMZN 2022-10 data is missing.\n",
      "❌ AMZN 2022-11 data is missing.\n",
      "❌ AMZN 2022-12 data is missing.\n",
      "❌ AMZN 2023-01 data is missing.\n",
      "❌ AMZN 2023-02 data is missing.\n",
      "❌ AMZN 2023-03 data is missing.\n",
      "❌ AMZN 2023-04 data is missing.\n",
      "❌ AMZN 2023-05 data is missing.\n",
      "❌ AMZN 2023-06 data is missing.\n",
      "❌ AMZN 2023-07 data is missing.\n",
      "❌ AMZN 2023-08 data is missing.\n",
      "❌ AMZN 2023-09 data is missing.\n",
      "❌ AMZN 2023-10 data is missing.\n",
      "❌ AMZN 2023-11 data is missing.\n",
      "❌ AMZN 2023-12 data is missing.\n",
      "❌ AMZN 2024-01 data is missing.\n",
      "❌ AMZN 2024-02 data is missing.\n",
      "❌ AMZN 2024-03 data is missing.\n",
      "❌ AMZN 2024-04 data is missing.\n",
      "❌ AMZN 2024-05 data is missing.\n",
      "❌ AMZN 2024-06 data is missing.\n",
      "❌ AMZN 2024-07 data is missing.\n",
      "❌ AMZN 2024-08 data is missing.\n",
      "❌ AMZN 2024-09 data is missing.\n",
      "❌ AMZN 2024-10 data is missing.\n",
      "❌ AMZN 2024-11 data is missing.\n",
      "❌ AMZN 2024-12 data is missing.\n",
      "📊 AMZN months that need to be fetched: ['2014-01', '2014-02', '2014-03', '2014-04', '2014-05', '2014-06', '2014-07', '2014-08', '2014-09', '2014-10', '2014-11', '2014-12', '2015-01', '2015-02', '2015-03', '2015-04', '2015-05', '2015-06', '2015-07', '2015-08', '2015-09', '2015-10', '2015-11', '2015-12', '2016-01', '2016-02', '2016-03', '2016-04', '2016-05', '2016-06', '2016-07', '2016-08', '2016-09', '2016-10', '2016-11', '2016-12', '2017-01', '2017-02', '2017-03', '2017-04', '2017-05', '2017-06', '2017-07', '2017-08', '2017-09', '2017-10', '2017-11', '2017-12', '2018-01', '2018-02', '2018-03', '2018-04', '2018-05', '2018-06', '2018-07', '2018-08', '2018-09', '2018-10', '2018-11', '2018-12', '2019-01', '2019-02', '2019-03', '2019-04', '2019-05', '2019-06', '2019-07', '2019-08', '2019-09', '2019-10', '2019-11', '2019-12', '2020-01', '2020-02', '2020-03', '2020-04', '2020-05', '2020-06', '2020-07', '2020-08', '2020-09', '2020-10', '2020-11', '2020-12', '2021-01', '2021-02', '2021-03', '2021-04', '2021-05', '2021-06', '2021-07', '2021-08', '2021-09', '2021-10', '2021-11', '2021-12', '2022-01', '2022-02', '2022-03', '2022-04', '2022-05', '2022-06', '2022-07', '2022-08', '2022-09', '2022-10', '2022-11', '2022-12', '2023-01', '2023-02', '2023-03', '2023-04', '2023-05', '2023-06', '2023-07', '2023-08', '2023-09', '2023-10', '2023-11', '2023-12', '2024-01', '2024-02', '2024-03', '2024-04', '2024-05', '2024-06', '2024-07', '2024-08', '2024-09', '2024-10', '2024-11', '2024-12']\n",
      "📝 Missing months list saved in AMZN_30min_data\\missing_months_10yr.txt\n",
      "\n",
      "📦 Checking data for GOOGL...\n",
      "❌ GOOGL 2014-01 data is missing.\n",
      "❌ GOOGL 2014-02 data is missing.\n",
      "❌ GOOGL 2014-03 data is missing.\n",
      "❌ GOOGL 2014-04 data is missing.\n",
      "❌ GOOGL 2014-05 data is missing.\n",
      "❌ GOOGL 2014-06 data is missing.\n",
      "❌ GOOGL 2014-07 data is missing.\n",
      "❌ GOOGL 2014-08 data is missing.\n",
      "❌ GOOGL 2014-09 data is missing.\n",
      "❌ GOOGL 2014-10 data is missing.\n",
      "❌ GOOGL 2014-11 data is missing.\n",
      "❌ GOOGL 2014-12 data is missing.\n",
      "❌ GOOGL 2015-01 data is missing.\n",
      "❌ GOOGL 2015-02 data is missing.\n",
      "❌ GOOGL 2015-03 data is missing.\n",
      "❌ GOOGL 2015-04 data is missing.\n",
      "❌ GOOGL 2015-05 data is missing.\n",
      "❌ GOOGL 2015-06 data is missing.\n",
      "❌ GOOGL 2015-07 data is missing.\n",
      "❌ GOOGL 2015-08 data is missing.\n",
      "❌ GOOGL 2015-09 data is missing.\n",
      "❌ GOOGL 2015-10 data is missing.\n",
      "❌ GOOGL 2015-11 data is missing.\n",
      "❌ GOOGL 2015-12 data is missing.\n",
      "❌ GOOGL 2016-01 data is missing.\n",
      "❌ GOOGL 2016-02 data is missing.\n",
      "❌ GOOGL 2016-03 data is missing.\n",
      "❌ GOOGL 2016-04 data is missing.\n",
      "❌ GOOGL 2016-05 data is missing.\n",
      "❌ GOOGL 2016-06 data is missing.\n",
      "❌ GOOGL 2016-07 data is missing.\n",
      "❌ GOOGL 2016-08 data is missing.\n",
      "❌ GOOGL 2016-09 data is missing.\n",
      "❌ GOOGL 2016-10 data is missing.\n",
      "❌ GOOGL 2016-11 data is missing.\n",
      "❌ GOOGL 2016-12 data is missing.\n",
      "❌ GOOGL 2017-01 data is missing.\n",
      "❌ GOOGL 2017-02 data is missing.\n",
      "❌ GOOGL 2017-03 data is missing.\n",
      "❌ GOOGL 2017-04 data is missing.\n",
      "❌ GOOGL 2017-05 data is missing.\n",
      "❌ GOOGL 2017-06 data is missing.\n",
      "❌ GOOGL 2017-07 data is missing.\n",
      "❌ GOOGL 2017-08 data is missing.\n",
      "❌ GOOGL 2017-09 data is missing.\n",
      "❌ GOOGL 2017-10 data is missing.\n",
      "❌ GOOGL 2017-11 data is missing.\n",
      "❌ GOOGL 2017-12 data is missing.\n",
      "❌ GOOGL 2018-01 data is missing.\n",
      "❌ GOOGL 2018-02 data is missing.\n",
      "❌ GOOGL 2018-03 data is missing.\n",
      "❌ GOOGL 2018-04 data is missing.\n",
      "❌ GOOGL 2018-05 data is missing.\n",
      "❌ GOOGL 2018-06 data is missing.\n",
      "❌ GOOGL 2018-07 data is missing.\n",
      "❌ GOOGL 2018-08 data is missing.\n",
      "❌ GOOGL 2018-09 data is missing.\n",
      "❌ GOOGL 2018-10 data is missing.\n",
      "❌ GOOGL 2018-11 data is missing.\n",
      "❌ GOOGL 2018-12 data is missing.\n",
      "❌ GOOGL 2019-01 data is missing.\n",
      "❌ GOOGL 2019-02 data is missing.\n",
      "❌ GOOGL 2019-03 data is missing.\n",
      "❌ GOOGL 2019-04 data is missing.\n",
      "❌ GOOGL 2019-05 data is missing.\n",
      "❌ GOOGL 2019-06 data is missing.\n",
      "❌ GOOGL 2019-07 data is missing.\n",
      "❌ GOOGL 2019-08 data is missing.\n",
      "❌ GOOGL 2019-09 data is missing.\n",
      "❌ GOOGL 2019-10 data is missing.\n",
      "❌ GOOGL 2019-11 data is missing.\n",
      "❌ GOOGL 2019-12 data is missing.\n",
      "❌ GOOGL 2020-01 data is missing.\n",
      "❌ GOOGL 2020-02 data is missing.\n",
      "❌ GOOGL 2020-03 data is missing.\n",
      "❌ GOOGL 2020-04 data is missing.\n",
      "❌ GOOGL 2020-05 data is missing.\n",
      "❌ GOOGL 2020-06 data is missing.\n",
      "❌ GOOGL 2020-07 data is missing.\n",
      "❌ GOOGL 2020-08 data is missing.\n",
      "❌ GOOGL 2020-09 data is missing.\n",
      "❌ GOOGL 2020-10 data is missing.\n",
      "❌ GOOGL 2020-11 data is missing.\n",
      "❌ GOOGL 2020-12 data is missing.\n",
      "❌ GOOGL 2021-01 data is missing.\n",
      "❌ GOOGL 2021-02 data is missing.\n",
      "❌ GOOGL 2021-03 data is missing.\n",
      "❌ GOOGL 2021-04 data is missing.\n",
      "❌ GOOGL 2021-05 data is missing.\n",
      "❌ GOOGL 2021-06 data is missing.\n",
      "❌ GOOGL 2021-07 data is missing.\n",
      "❌ GOOGL 2021-08 data is missing.\n",
      "❌ GOOGL 2021-09 data is missing.\n",
      "❌ GOOGL 2021-10 data is missing.\n",
      "❌ GOOGL 2021-11 data is missing.\n",
      "❌ GOOGL 2021-12 data is missing.\n",
      "❌ GOOGL 2022-01 data is missing.\n",
      "❌ GOOGL 2022-02 data is missing.\n",
      "❌ GOOGL 2022-03 data is missing.\n",
      "❌ GOOGL 2022-04 data is missing.\n",
      "❌ GOOGL 2022-05 data is missing.\n",
      "❌ GOOGL 2022-06 data is missing.\n",
      "❌ GOOGL 2022-07 data is missing.\n",
      "❌ GOOGL 2022-08 data is missing.\n",
      "❌ GOOGL 2022-09 data is missing.\n",
      "❌ GOOGL 2022-10 data is missing.\n",
      "❌ GOOGL 2022-11 data is missing.\n",
      "❌ GOOGL 2022-12 data is missing.\n",
      "❌ GOOGL 2023-01 data is missing.\n",
      "❌ GOOGL 2023-02 data is missing.\n",
      "❌ GOOGL 2023-03 data is missing.\n",
      "❌ GOOGL 2023-04 data is missing.\n",
      "❌ GOOGL 2023-05 data is missing.\n",
      "❌ GOOGL 2023-06 data is missing.\n",
      "❌ GOOGL 2023-07 data is missing.\n",
      "❌ GOOGL 2023-08 data is missing.\n",
      "❌ GOOGL 2023-09 data is missing.\n",
      "❌ GOOGL 2023-10 data is missing.\n",
      "❌ GOOGL 2023-11 data is missing.\n",
      "❌ GOOGL 2023-12 data is missing.\n",
      "❌ GOOGL 2024-01 data is missing.\n",
      "❌ GOOGL 2024-02 data is missing.\n",
      "❌ GOOGL 2024-03 data is missing.\n",
      "❌ GOOGL 2024-04 data is missing.\n",
      "❌ GOOGL 2024-05 data is missing.\n",
      "❌ GOOGL 2024-06 data is missing.\n",
      "❌ GOOGL 2024-07 data is missing.\n",
      "❌ GOOGL 2024-08 data is missing.\n",
      "❌ GOOGL 2024-09 data is missing.\n",
      "❌ GOOGL 2024-10 data is missing.\n",
      "❌ GOOGL 2024-11 data is missing.\n",
      "❌ GOOGL 2024-12 data is missing.\n",
      "📊 GOOGL months that need to be fetched: ['2014-01', '2014-02', '2014-03', '2014-04', '2014-05', '2014-06', '2014-07', '2014-08', '2014-09', '2014-10', '2014-11', '2014-12', '2015-01', '2015-02', '2015-03', '2015-04', '2015-05', '2015-06', '2015-07', '2015-08', '2015-09', '2015-10', '2015-11', '2015-12', '2016-01', '2016-02', '2016-03', '2016-04', '2016-05', '2016-06', '2016-07', '2016-08', '2016-09', '2016-10', '2016-11', '2016-12', '2017-01', '2017-02', '2017-03', '2017-04', '2017-05', '2017-06', '2017-07', '2017-08', '2017-09', '2017-10', '2017-11', '2017-12', '2018-01', '2018-02', '2018-03', '2018-04', '2018-05', '2018-06', '2018-07', '2018-08', '2018-09', '2018-10', '2018-11', '2018-12', '2019-01', '2019-02', '2019-03', '2019-04', '2019-05', '2019-06', '2019-07', '2019-08', '2019-09', '2019-10', '2019-11', '2019-12', '2020-01', '2020-02', '2020-03', '2020-04', '2020-05', '2020-06', '2020-07', '2020-08', '2020-09', '2020-10', '2020-11', '2020-12', '2021-01', '2021-02', '2021-03', '2021-04', '2021-05', '2021-06', '2021-07', '2021-08', '2021-09', '2021-10', '2021-11', '2021-12', '2022-01', '2022-02', '2022-03', '2022-04', '2022-05', '2022-06', '2022-07', '2022-08', '2022-09', '2022-10', '2022-11', '2022-12', '2023-01', '2023-02', '2023-03', '2023-04', '2023-05', '2023-06', '2023-07', '2023-08', '2023-09', '2023-10', '2023-11', '2023-12', '2024-01', '2024-02', '2024-03', '2024-04', '2024-05', '2024-06', '2024-07', '2024-08', '2024-09', '2024-10', '2024-11', '2024-12']\n",
      "📝 Missing months list saved in GOOGL_30min_data\\missing_months_10yr.txt\n",
      "\n",
      "📦 Checking data for META...\n",
      "❌ META 2014-01 data is missing.\n",
      "❌ META 2014-02 data is missing.\n",
      "❌ META 2014-03 data is missing.\n",
      "❌ META 2014-04 data is missing.\n",
      "❌ META 2014-05 data is missing.\n",
      "❌ META 2014-06 data is missing.\n",
      "❌ META 2014-07 data is missing.\n",
      "❌ META 2014-08 data is missing.\n",
      "❌ META 2014-09 data is missing.\n",
      "❌ META 2014-10 data is missing.\n",
      "❌ META 2014-11 data is missing.\n",
      "❌ META 2014-12 data is missing.\n",
      "❌ META 2015-01 data is missing.\n",
      "❌ META 2015-02 data is missing.\n",
      "❌ META 2015-03 data is missing.\n",
      "❌ META 2015-04 data is missing.\n",
      "❌ META 2015-05 data is missing.\n",
      "❌ META 2015-06 data is missing.\n",
      "❌ META 2015-07 data is missing.\n",
      "❌ META 2015-08 data is missing.\n",
      "❌ META 2015-09 data is missing.\n",
      "❌ META 2015-10 data is missing.\n",
      "❌ META 2015-11 data is missing.\n",
      "❌ META 2015-12 data is missing.\n",
      "❌ META 2016-01 data is missing.\n",
      "❌ META 2016-02 data is missing.\n",
      "❌ META 2016-03 data is missing.\n",
      "❌ META 2016-04 data is missing.\n",
      "❌ META 2016-05 data is missing.\n",
      "❌ META 2016-06 data is missing.\n",
      "❌ META 2016-07 data is missing.\n",
      "❌ META 2016-08 data is missing.\n",
      "❌ META 2016-09 data is missing.\n",
      "❌ META 2016-10 data is missing.\n",
      "❌ META 2016-11 data is missing.\n",
      "❌ META 2016-12 data is missing.\n",
      "❌ META 2017-01 data is missing.\n",
      "❌ META 2017-02 data is missing.\n",
      "❌ META 2017-03 data is missing.\n",
      "❌ META 2017-04 data is missing.\n",
      "❌ META 2017-05 data is missing.\n",
      "❌ META 2017-06 data is missing.\n",
      "❌ META 2017-07 data is missing.\n",
      "❌ META 2017-08 data is missing.\n",
      "❌ META 2017-09 data is missing.\n",
      "❌ META 2017-10 data is missing.\n",
      "❌ META 2017-11 data is missing.\n",
      "❌ META 2017-12 data is missing.\n",
      "❌ META 2018-01 data is missing.\n",
      "❌ META 2018-02 data is missing.\n",
      "❌ META 2018-03 data is missing.\n",
      "❌ META 2018-04 data is missing.\n",
      "❌ META 2018-05 data is missing.\n",
      "❌ META 2018-06 data is missing.\n",
      "❌ META 2018-07 data is missing.\n",
      "❌ META 2018-08 data is missing.\n",
      "❌ META 2018-09 data is missing.\n",
      "❌ META 2018-10 data is missing.\n",
      "❌ META 2018-11 data is missing.\n",
      "❌ META 2018-12 data is missing.\n",
      "❌ META 2019-01 data is missing.\n",
      "❌ META 2019-02 data is missing.\n",
      "❌ META 2019-03 data is missing.\n",
      "❌ META 2019-04 data is missing.\n",
      "❌ META 2019-05 data is missing.\n",
      "❌ META 2019-06 data is missing.\n",
      "❌ META 2019-07 data is missing.\n",
      "❌ META 2019-08 data is missing.\n",
      "❌ META 2019-09 data is missing.\n",
      "❌ META 2019-10 data is missing.\n",
      "❌ META 2019-11 data is missing.\n",
      "❌ META 2019-12 data is missing.\n",
      "❌ META 2020-01 data is missing.\n",
      "❌ META 2020-02 data is missing.\n",
      "❌ META 2020-03 data is missing.\n",
      "❌ META 2020-04 data is missing.\n",
      "❌ META 2020-05 data is missing.\n",
      "❌ META 2020-06 data is missing.\n",
      "❌ META 2020-07 data is missing.\n",
      "❌ META 2020-08 data is missing.\n",
      "❌ META 2020-09 data is missing.\n",
      "❌ META 2020-10 data is missing.\n",
      "❌ META 2020-11 data is missing.\n",
      "❌ META 2020-12 data is missing.\n",
      "❌ META 2021-01 data is missing.\n",
      "❌ META 2021-02 data is missing.\n",
      "❌ META 2021-03 data is missing.\n",
      "❌ META 2021-04 data is missing.\n",
      "❌ META 2021-05 data is missing.\n",
      "❌ META 2021-06 data is missing.\n",
      "❌ META 2021-07 data is missing.\n",
      "❌ META 2021-08 data is missing.\n",
      "❌ META 2021-09 data is missing.\n",
      "❌ META 2021-10 data is missing.\n",
      "❌ META 2021-11 data is missing.\n",
      "❌ META 2021-12 data is missing.\n",
      "❌ META 2022-01 data is missing.\n",
      "❌ META 2022-02 data is missing.\n",
      "❌ META 2022-03 data is missing.\n",
      "❌ META 2022-04 data is missing.\n",
      "❌ META 2022-05 data is missing.\n",
      "❌ META 2022-06 data is missing.\n",
      "❌ META 2022-07 data is missing.\n",
      "❌ META 2022-08 data is missing.\n",
      "❌ META 2022-09 data is missing.\n",
      "❌ META 2022-10 data is missing.\n",
      "❌ META 2022-11 data is missing.\n",
      "❌ META 2022-12 data is missing.\n",
      "❌ META 2023-01 data is missing.\n",
      "❌ META 2023-02 data is missing.\n",
      "❌ META 2023-03 data is missing.\n",
      "❌ META 2023-04 data is missing.\n",
      "❌ META 2023-05 data is missing.\n",
      "❌ META 2023-06 data is missing.\n",
      "❌ META 2023-07 data is missing.\n",
      "❌ META 2023-08 data is missing.\n",
      "❌ META 2023-09 data is missing.\n",
      "❌ META 2023-10 data is missing.\n",
      "❌ META 2023-11 data is missing.\n",
      "❌ META 2023-12 data is missing.\n",
      "❌ META 2024-01 data is missing.\n",
      "❌ META 2024-02 data is missing.\n",
      "❌ META 2024-03 data is missing.\n",
      "❌ META 2024-04 data is missing.\n",
      "❌ META 2024-05 data is missing.\n",
      "❌ META 2024-06 data is missing.\n",
      "❌ META 2024-07 data is missing.\n",
      "❌ META 2024-08 data is missing.\n",
      "❌ META 2024-09 data is missing.\n",
      "❌ META 2024-10 data is missing.\n",
      "❌ META 2024-11 data is missing.\n",
      "❌ META 2024-12 data is missing.\n",
      "📊 META months that need to be fetched: ['2014-01', '2014-02', '2014-03', '2014-04', '2014-05', '2014-06', '2014-07', '2014-08', '2014-09', '2014-10', '2014-11', '2014-12', '2015-01', '2015-02', '2015-03', '2015-04', '2015-05', '2015-06', '2015-07', '2015-08', '2015-09', '2015-10', '2015-11', '2015-12', '2016-01', '2016-02', '2016-03', '2016-04', '2016-05', '2016-06', '2016-07', '2016-08', '2016-09', '2016-10', '2016-11', '2016-12', '2017-01', '2017-02', '2017-03', '2017-04', '2017-05', '2017-06', '2017-07', '2017-08', '2017-09', '2017-10', '2017-11', '2017-12', '2018-01', '2018-02', '2018-03', '2018-04', '2018-05', '2018-06', '2018-07', '2018-08', '2018-09', '2018-10', '2018-11', '2018-12', '2019-01', '2019-02', '2019-03', '2019-04', '2019-05', '2019-06', '2019-07', '2019-08', '2019-09', '2019-10', '2019-11', '2019-12', '2020-01', '2020-02', '2020-03', '2020-04', '2020-05', '2020-06', '2020-07', '2020-08', '2020-09', '2020-10', '2020-11', '2020-12', '2021-01', '2021-02', '2021-03', '2021-04', '2021-05', '2021-06', '2021-07', '2021-08', '2021-09', '2021-10', '2021-11', '2021-12', '2022-01', '2022-02', '2022-03', '2022-04', '2022-05', '2022-06', '2022-07', '2022-08', '2022-09', '2022-10', '2022-11', '2022-12', '2023-01', '2023-02', '2023-03', '2023-04', '2023-05', '2023-06', '2023-07', '2023-08', '2023-09', '2023-10', '2023-11', '2023-12', '2024-01', '2024-02', '2024-03', '2024-04', '2024-05', '2024-06', '2024-07', '2024-08', '2024-09', '2024-10', '2024-11', '2024-12']\n",
      "📝 Missing months list saved in META_30min_data\\missing_months_10yr.txt\n",
      "\n",
      "📦 Checking data for TSLA...\n",
      "❌ TSLA 2014-01 data is missing.\n",
      "❌ TSLA 2014-02 data is missing.\n",
      "❌ TSLA 2014-03 data is missing.\n",
      "❌ TSLA 2014-04 data is missing.\n",
      "❌ TSLA 2014-05 data is missing.\n",
      "❌ TSLA 2014-06 data is missing.\n",
      "❌ TSLA 2014-07 data is missing.\n",
      "❌ TSLA 2014-08 data is missing.\n",
      "❌ TSLA 2014-09 data is missing.\n",
      "❌ TSLA 2014-10 data is missing.\n",
      "❌ TSLA 2014-11 data is missing.\n",
      "❌ TSLA 2014-12 data is missing.\n",
      "❌ TSLA 2015-01 data is missing.\n",
      "❌ TSLA 2015-02 data is missing.\n",
      "❌ TSLA 2015-03 data is missing.\n",
      "❌ TSLA 2015-04 data is missing.\n",
      "❌ TSLA 2015-05 data is missing.\n",
      "❌ TSLA 2015-06 data is missing.\n",
      "❌ TSLA 2015-07 data is missing.\n",
      "❌ TSLA 2015-08 data is missing.\n",
      "❌ TSLA 2015-09 data is missing.\n",
      "❌ TSLA 2015-10 data is missing.\n",
      "❌ TSLA 2015-11 data is missing.\n",
      "❌ TSLA 2015-12 data is missing.\n",
      "❌ TSLA 2016-01 data is missing.\n",
      "❌ TSLA 2016-02 data is missing.\n",
      "❌ TSLA 2016-03 data is missing.\n",
      "❌ TSLA 2016-04 data is missing.\n",
      "❌ TSLA 2016-05 data is missing.\n",
      "❌ TSLA 2016-06 data is missing.\n",
      "❌ TSLA 2016-07 data is missing.\n",
      "❌ TSLA 2016-08 data is missing.\n",
      "❌ TSLA 2016-09 data is missing.\n",
      "❌ TSLA 2016-10 data is missing.\n",
      "❌ TSLA 2016-11 data is missing.\n",
      "❌ TSLA 2016-12 data is missing.\n",
      "❌ TSLA 2017-01 data is missing.\n",
      "❌ TSLA 2017-02 data is missing.\n",
      "❌ TSLA 2017-03 data is missing.\n",
      "❌ TSLA 2017-04 data is missing.\n",
      "❌ TSLA 2017-05 data is missing.\n",
      "❌ TSLA 2017-06 data is missing.\n",
      "❌ TSLA 2017-07 data is missing.\n",
      "❌ TSLA 2017-08 data is missing.\n",
      "❌ TSLA 2017-09 data is missing.\n",
      "❌ TSLA 2017-10 data is missing.\n",
      "❌ TSLA 2017-11 data is missing.\n",
      "❌ TSLA 2017-12 data is missing.\n",
      "❌ TSLA 2018-01 data is missing.\n",
      "❌ TSLA 2018-02 data is missing.\n",
      "❌ TSLA 2018-03 data is missing.\n",
      "❌ TSLA 2018-04 data is missing.\n",
      "❌ TSLA 2018-05 data is missing.\n",
      "❌ TSLA 2018-06 data is missing.\n",
      "❌ TSLA 2018-07 data is missing.\n",
      "❌ TSLA 2018-08 data is missing.\n",
      "❌ TSLA 2018-09 data is missing.\n",
      "❌ TSLA 2018-10 data is missing.\n",
      "❌ TSLA 2018-11 data is missing.\n",
      "❌ TSLA 2018-12 data is missing.\n",
      "❌ TSLA 2019-01 data is missing.\n",
      "❌ TSLA 2019-02 data is missing.\n",
      "❌ TSLA 2019-03 data is missing.\n",
      "❌ TSLA 2019-04 data is missing.\n",
      "❌ TSLA 2019-05 data is missing.\n",
      "❌ TSLA 2019-06 data is missing.\n",
      "❌ TSLA 2019-07 data is missing.\n",
      "❌ TSLA 2019-08 data is missing.\n",
      "❌ TSLA 2019-09 data is missing.\n",
      "❌ TSLA 2019-10 data is missing.\n",
      "❌ TSLA 2019-11 data is missing.\n",
      "❌ TSLA 2019-12 data is missing.\n",
      "❌ TSLA 2020-01 data is missing.\n",
      "❌ TSLA 2020-02 data is missing.\n",
      "❌ TSLA 2020-03 data is missing.\n",
      "❌ TSLA 2020-04 data is missing.\n",
      "❌ TSLA 2020-05 data is missing.\n",
      "❌ TSLA 2020-06 data is missing.\n",
      "❌ TSLA 2020-07 data is missing.\n",
      "❌ TSLA 2020-08 data is missing.\n",
      "❌ TSLA 2020-09 data is missing.\n",
      "❌ TSLA 2020-10 data is missing.\n",
      "❌ TSLA 2020-11 data is missing.\n",
      "❌ TSLA 2020-12 data is missing.\n",
      "❌ TSLA 2021-01 data is missing.\n",
      "❌ TSLA 2021-02 data is missing.\n",
      "❌ TSLA 2021-03 data is missing.\n",
      "❌ TSLA 2021-04 data is missing.\n",
      "❌ TSLA 2021-05 data is missing.\n",
      "❌ TSLA 2021-06 data is missing.\n",
      "❌ TSLA 2021-07 data is missing.\n",
      "❌ TSLA 2021-08 data is missing.\n",
      "❌ TSLA 2021-09 data is missing.\n",
      "❌ TSLA 2021-10 data is missing.\n",
      "❌ TSLA 2021-11 data is missing.\n",
      "❌ TSLA 2021-12 data is missing.\n",
      "❌ TSLA 2022-01 data is missing.\n",
      "❌ TSLA 2022-02 data is missing.\n",
      "❌ TSLA 2022-03 data is missing.\n",
      "❌ TSLA 2022-04 data is missing.\n",
      "❌ TSLA 2022-05 data is missing.\n",
      "❌ TSLA 2022-06 data is missing.\n",
      "❌ TSLA 2022-07 data is missing.\n",
      "❌ TSLA 2022-08 data is missing.\n",
      "❌ TSLA 2022-09 data is missing.\n",
      "❌ TSLA 2022-10 data is missing.\n",
      "❌ TSLA 2022-11 data is missing.\n",
      "❌ TSLA 2022-12 data is missing.\n",
      "❌ TSLA 2023-01 data is missing.\n",
      "❌ TSLA 2023-02 data is missing.\n",
      "❌ TSLA 2023-03 data is missing.\n",
      "❌ TSLA 2023-04 data is missing.\n",
      "❌ TSLA 2023-05 data is missing.\n",
      "❌ TSLA 2023-06 data is missing.\n",
      "❌ TSLA 2023-07 data is missing.\n",
      "❌ TSLA 2023-08 data is missing.\n",
      "❌ TSLA 2023-09 data is missing.\n",
      "❌ TSLA 2023-10 data is missing.\n",
      "❌ TSLA 2023-11 data is missing.\n",
      "❌ TSLA 2023-12 data is missing.\n",
      "❌ TSLA 2024-01 data is missing.\n",
      "❌ TSLA 2024-02 data is missing.\n",
      "❌ TSLA 2024-03 data is missing.\n",
      "❌ TSLA 2024-04 data is missing.\n",
      "❌ TSLA 2024-05 data is missing.\n",
      "❌ TSLA 2024-06 data is missing.\n",
      "❌ TSLA 2024-07 data is missing.\n",
      "❌ TSLA 2024-08 data is missing.\n",
      "❌ TSLA 2024-09 data is missing.\n",
      "❌ TSLA 2024-10 data is missing.\n",
      "❌ TSLA 2024-11 data is missing.\n",
      "❌ TSLA 2024-12 data is missing.\n",
      "📊 TSLA months that need to be fetched: ['2014-01', '2014-02', '2014-03', '2014-04', '2014-05', '2014-06', '2014-07', '2014-08', '2014-09', '2014-10', '2014-11', '2014-12', '2015-01', '2015-02', '2015-03', '2015-04', '2015-05', '2015-06', '2015-07', '2015-08', '2015-09', '2015-10', '2015-11', '2015-12', '2016-01', '2016-02', '2016-03', '2016-04', '2016-05', '2016-06', '2016-07', '2016-08', '2016-09', '2016-10', '2016-11', '2016-12', '2017-01', '2017-02', '2017-03', '2017-04', '2017-05', '2017-06', '2017-07', '2017-08', '2017-09', '2017-10', '2017-11', '2017-12', '2018-01', '2018-02', '2018-03', '2018-04', '2018-05', '2018-06', '2018-07', '2018-08', '2018-09', '2018-10', '2018-11', '2018-12', '2019-01', '2019-02', '2019-03', '2019-04', '2019-05', '2019-06', '2019-07', '2019-08', '2019-09', '2019-10', '2019-11', '2019-12', '2020-01', '2020-02', '2020-03', '2020-04', '2020-05', '2020-06', '2020-07', '2020-08', '2020-09', '2020-10', '2020-11', '2020-12', '2021-01', '2021-02', '2021-03', '2021-04', '2021-05', '2021-06', '2021-07', '2021-08', '2021-09', '2021-10', '2021-11', '2021-12', '2022-01', '2022-02', '2022-03', '2022-04', '2022-05', '2022-06', '2022-07', '2022-08', '2022-09', '2022-10', '2022-11', '2022-12', '2023-01', '2023-02', '2023-03', '2023-04', '2023-05', '2023-06', '2023-07', '2023-08', '2023-09', '2023-10', '2023-11', '2023-12', '2024-01', '2024-02', '2024-03', '2024-04', '2024-05', '2024-06', '2024-07', '2024-08', '2024-09', '2024-10', '2024-11', '2024-12']\n",
      "📝 Missing months list saved in TSLA_30min_data\\missing_months_10yr.txt\n",
      "\n",
      "📦 Checking data for AMD...\n",
      "✅ AMD already marked as complete. Skipping.\n",
      "\n",
      "📦 Checking data for NFLX...\n",
      "❌ NFLX 2014-01 data is missing.\n",
      "❌ NFLX 2014-02 data is missing.\n",
      "❌ NFLX 2014-03 data is missing.\n",
      "❌ NFLX 2014-04 data is missing.\n",
      "❌ NFLX 2014-05 data is missing.\n",
      "❌ NFLX 2014-06 data is missing.\n",
      "❌ NFLX 2014-07 data is missing.\n",
      "❌ NFLX 2014-08 data is missing.\n",
      "❌ NFLX 2014-09 data is missing.\n",
      "❌ NFLX 2014-10 data is missing.\n",
      "❌ NFLX 2014-11 data is missing.\n",
      "❌ NFLX 2014-12 data is missing.\n",
      "❌ NFLX 2015-01 data is missing.\n",
      "❌ NFLX 2015-02 data is missing.\n",
      "❌ NFLX 2015-03 data is missing.\n",
      "❌ NFLX 2015-04 data is missing.\n",
      "❌ NFLX 2015-05 data is missing.\n",
      "❌ NFLX 2015-06 data is missing.\n",
      "❌ NFLX 2015-07 data is missing.\n",
      "❌ NFLX 2015-08 data is missing.\n",
      "❌ NFLX 2015-09 data is missing.\n",
      "❌ NFLX 2015-10 data is missing.\n",
      "❌ NFLX 2015-11 data is missing.\n",
      "❌ NFLX 2015-12 data is missing.\n",
      "❌ NFLX 2016-01 data is missing.\n",
      "❌ NFLX 2016-02 data is missing.\n",
      "❌ NFLX 2016-03 data is missing.\n",
      "❌ NFLX 2016-04 data is missing.\n",
      "❌ NFLX 2016-05 data is missing.\n",
      "❌ NFLX 2016-06 data is missing.\n",
      "❌ NFLX 2016-07 data is missing.\n",
      "❌ NFLX 2016-08 data is missing.\n",
      "❌ NFLX 2016-09 data is missing.\n",
      "❌ NFLX 2016-10 data is missing.\n",
      "❌ NFLX 2016-11 data is missing.\n",
      "❌ NFLX 2016-12 data is missing.\n",
      "❌ NFLX 2017-01 data is missing.\n",
      "❌ NFLX 2017-02 data is missing.\n",
      "❌ NFLX 2017-03 data is missing.\n",
      "❌ NFLX 2017-04 data is missing.\n",
      "❌ NFLX 2017-05 data is missing.\n",
      "❌ NFLX 2017-06 data is missing.\n",
      "❌ NFLX 2017-07 data is missing.\n",
      "❌ NFLX 2017-08 data is missing.\n",
      "❌ NFLX 2017-09 data is missing.\n",
      "❌ NFLX 2017-10 data is missing.\n",
      "❌ NFLX 2017-11 data is missing.\n",
      "❌ NFLX 2017-12 data is missing.\n",
      "❌ NFLX 2018-01 data is missing.\n",
      "❌ NFLX 2018-02 data is missing.\n",
      "❌ NFLX 2018-03 data is missing.\n",
      "❌ NFLX 2018-04 data is missing.\n",
      "❌ NFLX 2018-05 data is missing.\n",
      "❌ NFLX 2018-06 data is missing.\n",
      "❌ NFLX 2018-07 data is missing.\n",
      "❌ NFLX 2018-08 data is missing.\n",
      "❌ NFLX 2018-09 data is missing.\n",
      "❌ NFLX 2018-10 data is missing.\n",
      "❌ NFLX 2018-11 data is missing.\n",
      "❌ NFLX 2018-12 data is missing.\n",
      "❌ NFLX 2019-01 data is missing.\n",
      "❌ NFLX 2019-02 data is missing.\n",
      "❌ NFLX 2019-03 data is missing.\n",
      "❌ NFLX 2019-04 data is missing.\n",
      "❌ NFLX 2019-05 data is missing.\n",
      "❌ NFLX 2019-06 data is missing.\n",
      "❌ NFLX 2019-07 data is missing.\n",
      "❌ NFLX 2019-08 data is missing.\n",
      "❌ NFLX 2019-09 data is missing.\n",
      "❌ NFLX 2019-10 data is missing.\n",
      "❌ NFLX 2019-11 data is missing.\n",
      "❌ NFLX 2019-12 data is missing.\n",
      "❌ NFLX 2020-01 data is missing.\n",
      "❌ NFLX 2020-02 data is missing.\n",
      "❌ NFLX 2020-03 data is missing.\n",
      "❌ NFLX 2020-04 data is missing.\n",
      "❌ NFLX 2020-05 data is missing.\n",
      "❌ NFLX 2020-06 data is missing.\n",
      "❌ NFLX 2020-07 data is missing.\n",
      "❌ NFLX 2020-08 data is missing.\n",
      "❌ NFLX 2020-09 data is missing.\n",
      "❌ NFLX 2020-10 data is missing.\n",
      "❌ NFLX 2020-11 data is missing.\n",
      "❌ NFLX 2020-12 data is missing.\n",
      "❌ NFLX 2021-01 data is missing.\n",
      "❌ NFLX 2021-02 data is missing.\n",
      "❌ NFLX 2021-03 data is missing.\n",
      "❌ NFLX 2021-04 data is missing.\n",
      "❌ NFLX 2021-05 data is missing.\n",
      "❌ NFLX 2021-06 data is missing.\n",
      "❌ NFLX 2021-07 data is missing.\n",
      "❌ NFLX 2021-08 data is missing.\n",
      "❌ NFLX 2021-09 data is missing.\n",
      "❌ NFLX 2021-10 data is missing.\n",
      "❌ NFLX 2021-11 data is missing.\n",
      "❌ NFLX 2021-12 data is missing.\n",
      "❌ NFLX 2022-01 data is missing.\n",
      "❌ NFLX 2022-02 data is missing.\n",
      "❌ NFLX 2022-03 data is missing.\n",
      "❌ NFLX 2022-04 data is missing.\n",
      "❌ NFLX 2022-05 data is missing.\n",
      "❌ NFLX 2022-06 data is missing.\n",
      "❌ NFLX 2022-07 data is missing.\n",
      "❌ NFLX 2022-08 data is missing.\n",
      "❌ NFLX 2022-09 data is missing.\n",
      "❌ NFLX 2022-10 data is missing.\n",
      "❌ NFLX 2022-11 data is missing.\n",
      "❌ NFLX 2022-12 data is missing.\n",
      "❌ NFLX 2023-01 data is missing.\n",
      "❌ NFLX 2023-02 data is missing.\n",
      "❌ NFLX 2023-03 data is missing.\n",
      "❌ NFLX 2023-04 data is missing.\n",
      "❌ NFLX 2023-05 data is missing.\n",
      "❌ NFLX 2023-06 data is missing.\n",
      "❌ NFLX 2023-07 data is missing.\n",
      "❌ NFLX 2023-08 data is missing.\n",
      "❌ NFLX 2023-09 data is missing.\n",
      "❌ NFLX 2023-10 data is missing.\n",
      "❌ NFLX 2023-11 data is missing.\n",
      "❌ NFLX 2023-12 data is missing.\n",
      "❌ NFLX 2024-01 data is missing.\n",
      "❌ NFLX 2024-02 data is missing.\n",
      "❌ NFLX 2024-03 data is missing.\n",
      "❌ NFLX 2024-04 data is missing.\n",
      "❌ NFLX 2024-05 data is missing.\n",
      "❌ NFLX 2024-06 data is missing.\n",
      "❌ NFLX 2024-07 data is missing.\n",
      "❌ NFLX 2024-08 data is missing.\n",
      "❌ NFLX 2024-09 data is missing.\n",
      "❌ NFLX 2024-10 data is missing.\n",
      "❌ NFLX 2024-11 data is missing.\n",
      "❌ NFLX 2024-12 data is missing.\n",
      "📊 NFLX months that need to be fetched: ['2014-01', '2014-02', '2014-03', '2014-04', '2014-05', '2014-06', '2014-07', '2014-08', '2014-09', '2014-10', '2014-11', '2014-12', '2015-01', '2015-02', '2015-03', '2015-04', '2015-05', '2015-06', '2015-07', '2015-08', '2015-09', '2015-10', '2015-11', '2015-12', '2016-01', '2016-02', '2016-03', '2016-04', '2016-05', '2016-06', '2016-07', '2016-08', '2016-09', '2016-10', '2016-11', '2016-12', '2017-01', '2017-02', '2017-03', '2017-04', '2017-05', '2017-06', '2017-07', '2017-08', '2017-09', '2017-10', '2017-11', '2017-12', '2018-01', '2018-02', '2018-03', '2018-04', '2018-05', '2018-06', '2018-07', '2018-08', '2018-09', '2018-10', '2018-11', '2018-12', '2019-01', '2019-02', '2019-03', '2019-04', '2019-05', '2019-06', '2019-07', '2019-08', '2019-09', '2019-10', '2019-11', '2019-12', '2020-01', '2020-02', '2020-03', '2020-04', '2020-05', '2020-06', '2020-07', '2020-08', '2020-09', '2020-10', '2020-11', '2020-12', '2021-01', '2021-02', '2021-03', '2021-04', '2021-05', '2021-06', '2021-07', '2021-08', '2021-09', '2021-10', '2021-11', '2021-12', '2022-01', '2022-02', '2022-03', '2022-04', '2022-05', '2022-06', '2022-07', '2022-08', '2022-09', '2022-10', '2022-11', '2022-12', '2023-01', '2023-02', '2023-03', '2023-04', '2023-05', '2023-06', '2023-07', '2023-08', '2023-09', '2023-10', '2023-11', '2023-12', '2024-01', '2024-02', '2024-03', '2024-04', '2024-05', '2024-06', '2024-07', '2024-08', '2024-09', '2024-10', '2024-11', '2024-12']\n",
      "📝 Missing months list saved in NFLX_30min_data\\missing_months_10yr.txt\n",
      "\n",
      "📦 Checking data for AVGO...\n",
      "❌ AVGO 2014-01 data is missing.\n",
      "❌ AVGO 2014-02 data is missing.\n",
      "❌ AVGO 2014-03 data is missing.\n",
      "❌ AVGO 2014-04 data is missing.\n",
      "❌ AVGO 2014-05 data is missing.\n",
      "❌ AVGO 2014-06 data is missing.\n",
      "❌ AVGO 2014-07 data is missing.\n",
      "❌ AVGO 2014-08 data is missing.\n",
      "❌ AVGO 2014-09 data is missing.\n",
      "❌ AVGO 2014-10 data is missing.\n",
      "❌ AVGO 2014-11 data is missing.\n",
      "❌ AVGO 2014-12 data is missing.\n",
      "❌ AVGO 2015-01 data is missing.\n",
      "❌ AVGO 2015-02 data is missing.\n",
      "❌ AVGO 2015-03 data is missing.\n",
      "❌ AVGO 2015-04 data is missing.\n",
      "❌ AVGO 2015-05 data is missing.\n",
      "❌ AVGO 2015-06 data is missing.\n",
      "❌ AVGO 2015-07 data is missing.\n",
      "❌ AVGO 2015-08 data is missing.\n",
      "❌ AVGO 2015-09 data is missing.\n",
      "❌ AVGO 2015-10 data is missing.\n",
      "❌ AVGO 2015-11 data is missing.\n",
      "❌ AVGO 2015-12 data is missing.\n",
      "❌ AVGO 2016-01 data is missing.\n",
      "❌ AVGO 2016-02 data is missing.\n",
      "❌ AVGO 2016-03 data is missing.\n",
      "❌ AVGO 2016-04 data is missing.\n",
      "❌ AVGO 2016-05 data is missing.\n",
      "❌ AVGO 2016-06 data is missing.\n",
      "❌ AVGO 2016-07 data is missing.\n",
      "❌ AVGO 2016-08 data is missing.\n",
      "❌ AVGO 2016-09 data is missing.\n",
      "❌ AVGO 2016-10 data is missing.\n",
      "❌ AVGO 2016-11 data is missing.\n",
      "❌ AVGO 2016-12 data is missing.\n",
      "❌ AVGO 2017-01 data is missing.\n",
      "❌ AVGO 2017-02 data is missing.\n",
      "❌ AVGO 2017-03 data is missing.\n",
      "❌ AVGO 2017-04 data is missing.\n",
      "❌ AVGO 2017-05 data is missing.\n",
      "❌ AVGO 2017-06 data is missing.\n",
      "❌ AVGO 2017-07 data is missing.\n",
      "❌ AVGO 2017-08 data is missing.\n",
      "❌ AVGO 2017-09 data is missing.\n",
      "❌ AVGO 2017-10 data is missing.\n",
      "❌ AVGO 2017-11 data is missing.\n",
      "❌ AVGO 2017-12 data is missing.\n",
      "❌ AVGO 2018-01 data is missing.\n",
      "❌ AVGO 2018-02 data is missing.\n",
      "❌ AVGO 2018-03 data is missing.\n",
      "❌ AVGO 2018-04 data is missing.\n",
      "❌ AVGO 2018-05 data is missing.\n",
      "❌ AVGO 2018-06 data is missing.\n",
      "❌ AVGO 2018-07 data is missing.\n",
      "❌ AVGO 2018-08 data is missing.\n",
      "❌ AVGO 2018-09 data is missing.\n",
      "❌ AVGO 2018-10 data is missing.\n",
      "❌ AVGO 2018-11 data is missing.\n",
      "❌ AVGO 2018-12 data is missing.\n",
      "❌ AVGO 2019-01 data is missing.\n",
      "❌ AVGO 2019-02 data is missing.\n",
      "❌ AVGO 2019-03 data is missing.\n",
      "❌ AVGO 2019-04 data is missing.\n",
      "❌ AVGO 2019-05 data is missing.\n",
      "❌ AVGO 2019-06 data is missing.\n",
      "❌ AVGO 2019-07 data is missing.\n",
      "❌ AVGO 2019-08 data is missing.\n",
      "❌ AVGO 2019-09 data is missing.\n",
      "❌ AVGO 2019-10 data is missing.\n",
      "❌ AVGO 2019-11 data is missing.\n",
      "❌ AVGO 2019-12 data is missing.\n",
      "❌ AVGO 2020-01 data is missing.\n",
      "❌ AVGO 2020-02 data is missing.\n",
      "❌ AVGO 2020-03 data is missing.\n",
      "❌ AVGO 2020-04 data is missing.\n",
      "❌ AVGO 2020-05 data is missing.\n",
      "❌ AVGO 2020-06 data is missing.\n",
      "❌ AVGO 2020-07 data is missing.\n",
      "❌ AVGO 2020-08 data is missing.\n",
      "❌ AVGO 2020-09 data is missing.\n",
      "❌ AVGO 2020-10 data is missing.\n",
      "❌ AVGO 2020-11 data is missing.\n",
      "❌ AVGO 2020-12 data is missing.\n",
      "❌ AVGO 2021-01 data is missing.\n",
      "❌ AVGO 2021-02 data is missing.\n",
      "❌ AVGO 2021-03 data is missing.\n",
      "❌ AVGO 2021-04 data is missing.\n",
      "❌ AVGO 2021-05 data is missing.\n",
      "❌ AVGO 2021-06 data is missing.\n",
      "❌ AVGO 2021-07 data is missing.\n",
      "❌ AVGO 2021-08 data is missing.\n",
      "❌ AVGO 2021-09 data is missing.\n",
      "❌ AVGO 2021-10 data is missing.\n",
      "❌ AVGO 2021-11 data is missing.\n",
      "❌ AVGO 2021-12 data is missing.\n",
      "❌ AVGO 2022-01 data is missing.\n",
      "❌ AVGO 2022-02 data is missing.\n",
      "❌ AVGO 2022-03 data is missing.\n",
      "❌ AVGO 2022-04 data is missing.\n",
      "❌ AVGO 2022-05 data is missing.\n",
      "❌ AVGO 2022-06 data is missing.\n",
      "❌ AVGO 2022-07 data is missing.\n",
      "❌ AVGO 2022-08 data is missing.\n",
      "❌ AVGO 2022-09 data is missing.\n",
      "❌ AVGO 2022-10 data is missing.\n",
      "❌ AVGO 2022-11 data is missing.\n",
      "❌ AVGO 2022-12 data is missing.\n",
      "❌ AVGO 2023-01 data is missing.\n",
      "❌ AVGO 2023-02 data is missing.\n",
      "❌ AVGO 2023-03 data is missing.\n",
      "❌ AVGO 2023-04 data is missing.\n",
      "❌ AVGO 2023-05 data is missing.\n",
      "❌ AVGO 2023-06 data is missing.\n",
      "❌ AVGO 2023-07 data is missing.\n",
      "❌ AVGO 2023-08 data is missing.\n",
      "❌ AVGO 2023-09 data is missing.\n",
      "❌ AVGO 2023-10 data is missing.\n",
      "❌ AVGO 2023-11 data is missing.\n",
      "❌ AVGO 2023-12 data is missing.\n",
      "❌ AVGO 2024-01 data is missing.\n",
      "❌ AVGO 2024-02 data is missing.\n",
      "❌ AVGO 2024-03 data is missing.\n",
      "❌ AVGO 2024-04 data is missing.\n",
      "❌ AVGO 2024-05 data is missing.\n",
      "❌ AVGO 2024-06 data is missing.\n",
      "❌ AVGO 2024-07 data is missing.\n",
      "❌ AVGO 2024-08 data is missing.\n",
      "❌ AVGO 2024-09 data is missing.\n",
      "❌ AVGO 2024-10 data is missing.\n",
      "❌ AVGO 2024-11 data is missing.\n",
      "❌ AVGO 2024-12 data is missing.\n",
      "📊 AVGO months that need to be fetched: ['2014-01', '2014-02', '2014-03', '2014-04', '2014-05', '2014-06', '2014-07', '2014-08', '2014-09', '2014-10', '2014-11', '2014-12', '2015-01', '2015-02', '2015-03', '2015-04', '2015-05', '2015-06', '2015-07', '2015-08', '2015-09', '2015-10', '2015-11', '2015-12', '2016-01', '2016-02', '2016-03', '2016-04', '2016-05', '2016-06', '2016-07', '2016-08', '2016-09', '2016-10', '2016-11', '2016-12', '2017-01', '2017-02', '2017-03', '2017-04', '2017-05', '2017-06', '2017-07', '2017-08', '2017-09', '2017-10', '2017-11', '2017-12', '2018-01', '2018-02', '2018-03', '2018-04', '2018-05', '2018-06', '2018-07', '2018-08', '2018-09', '2018-10', '2018-11', '2018-12', '2019-01', '2019-02', '2019-03', '2019-04', '2019-05', '2019-06', '2019-07', '2019-08', '2019-09', '2019-10', '2019-11', '2019-12', '2020-01', '2020-02', '2020-03', '2020-04', '2020-05', '2020-06', '2020-07', '2020-08', '2020-09', '2020-10', '2020-11', '2020-12', '2021-01', '2021-02', '2021-03', '2021-04', '2021-05', '2021-06', '2021-07', '2021-08', '2021-09', '2021-10', '2021-11', '2021-12', '2022-01', '2022-02', '2022-03', '2022-04', '2022-05', '2022-06', '2022-07', '2022-08', '2022-09', '2022-10', '2022-11', '2022-12', '2023-01', '2023-02', '2023-03', '2023-04', '2023-05', '2023-06', '2023-07', '2023-08', '2023-09', '2023-10', '2023-11', '2023-12', '2024-01', '2024-02', '2024-03', '2024-04', '2024-05', '2024-06', '2024-07', '2024-08', '2024-09', '2024-10', '2024-11', '2024-12']\n",
      "📝 Missing months list saved in AVGO_30min_data\\missing_months_10yr.txt\n"
     ]
    }
   ],
   "source": [
    "# List of stock symbols to process\n",
    "stock_list = [\"AAPL\", \"MSFT\", \"NVDA\", \"AMZN\", \"GOOGL\", \"META\", \"TSLA\", \"AMD\", \"NFLX\", \"AVGO\"]  # Add more if needed\n",
    "\n",
    "# List of years (2014-2024) and months\n",
    "years = list(range(2014, 2025))\n",
    "months_10yr = [f\"{y}-{str(m).zfill(2)}\" for y in years for m in range(1, 13)]\n",
    "\n",
    "# Stock market holidays (2014–2024)\n",
    "stock_market_holidays = [\n",
    "    \"2024-01-01\", \"2024-01-15\", \"2024-02-19\", \"2024-03-29\", \"2024-05-27\", \"2024-06-19\",\n",
    "    \"2024-07-04\", \"2024-09-02\", \"2024-11-28\", \"2024-12-25\", \"2023-01-02\", \"2023-01-16\",\n",
    "    \"2023-02-20\", \"2023-04-07\", \"2023-05-29\", \"2023-06-19\", \"2023-07-04\", \"2023-09-04\", \n",
    "    \"2023-11-23\", \"2023-12-25\", \"2022-01-01\", \"2022-01-17\", \"2022-02-21\", \"2022-04-15\", \n",
    "    \"2022-05-30\", \"2022-06-20\", \"2022-07-04\", \"2022-09-05\", \"2022-11-24\", \"2022-12-26\", \n",
    "    \"2021-01-01\", \"2021-01-18\", \"2021-02-15\", \"2021-04-02\", \"2021-05-31\", \"2021-07-05\", \n",
    "    \"2021-09-06\", \"2021-11-25\", \"2021-12-24\", \"2020-01-01\", \"2020-01-20\", \"2020-02-17\", \n",
    "    \"2020-04-10\", \"2020-05-25\", \"2020-07-03\", \"2020-09-07\", \"2020-11-26\", \"2020-12-25\", \n",
    "    \"2019-01-01\", \"2019-01-21\", \"2019-02-18\", \"2019-04-19\", \"2019-05-27\", \"2019-07-04\", \n",
    "    \"2019-09-02\", \"2019-11-28\", \"2019-12-25\", \"2018-01-01\", \"2018-01-15\", \"2018-02-19\",\n",
    "    \"2018-03-30\", \"2018-05-28\", \"2018-07-04\", \"2018-09-03\", \"2018-11-22\", \"2018-12-05\",\n",
    "    \"2018-12-25\", \"2017-01-02\", \"2017-01-16\", \"2017-02-20\", \"2017-04-14\", \"2017-05-29\",\n",
    "    \"2017-07-04\", \"2017-09-04\", \"2017-11-23\", \"2017-12-25\", \"2016-01-01\", \"2016-01-18\",\n",
    "    \"2016-02-15\", \"2016-03-25\", \"2016-05-30\", \"2016-07-04\", \"2016-09-05\", \"2016-11-24\",\n",
    "    \"2016-12-26\", \"2015-01-01\", \"2015-01-19\", \"2015-02-16\", \"2015-04-03\", \"2015-05-25\",\n",
    "    \"2015-07-03\", \"2015-09-07\", \"2015-11-26\", \"2015-12-25\", \"2014-01-01\", \"2014-01-20\", \n",
    "    \"2014-02-17\", \"2014-04-18\", \"2014-05-26\", \"2014-07-04\", \"2014-09-01\", \"2014-11-27\", \n",
    "    \"2014-12-25\"\n",
    "]\n",
    "stock_market_holidays = [pd.to_datetime(date).date() for date in stock_market_holidays]\n",
    "\n",
    "# Function to check if a month's data is complete\n",
    "def check_existing_data(symbol, month, output_dir):\n",
    "    file_path = os.path.join(output_dir, f\"{symbol}_30min_{month}.csv\")\n",
    "\n",
    "    if os.path.exists(file_path):\n",
    "        df = pd.read_csv(file_path, parse_dates=[\"date\"], index_col=\"date\")\n",
    "\n",
    "        # Generate expected business days (Mon–Fri)\n",
    "        expected_days = pd.date_range(start=f\"{month}-01\", end=f\"{month}-28\", freq=\"B\")\n",
    "\n",
    "        # Find missing weekdays (excluding holidays)\n",
    "        missing_days = [d.date() for d in expected_days if d.date() not in df.index.date and d.date() not in stock_market_holidays]\n",
    "\n",
    "        if missing_days:\n",
    "            print(f\"⚠️ WARNING: {symbol} {month} is missing these weekdays: {missing_days}\")\n",
    "            return False\n",
    "        else:\n",
    "            print(f\"✅ {symbol} {month} data is already complete.\")\n",
    "            return True\n",
    "    else:\n",
    "        print(f\"❌ {symbol} {month} data is missing.\")\n",
    "        return False\n",
    "\n",
    "# Loop through each stock\n",
    "for symbol in stock_list:\n",
    "    print(f\"\\n📦 Checking data for {symbol}...\")\n",
    "\n",
    "    output_dir = f\"{symbol}_30min_data\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Skip if already completed\n",
    "    completion_flag = os.path.join(output_dir, \"completed.flag\")\n",
    "    if os.path.exists(completion_flag):\n",
    "        print(f\"✅ {symbol} already marked as complete. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    # Check for missing months\n",
    "    months_to_fetch = [month for month in months_10yr if not check_existing_data(symbol, month, output_dir)]\n",
    "\n",
    "    # Save missing months list\n",
    "    missing_months_file = os.path.join(output_dir, \"missing_months_10yr.txt\")\n",
    "    with open(missing_months_file, \"w\") as f:\n",
    "        for month in months_to_fetch:\n",
    "            f.write(month + \"\\n\")\n",
    "\n",
    "    print(f\"📊 {symbol} months that need to be fetched: {months_to_fetch}\")\n",
    "    print(f\"📝 Missing months list saved in {missing_months_file}\")\n",
    "\n",
    "    # Create completion flag if nothing is missing\n",
    "    if not months_to_fetch:\n",
    "        with open(completion_flag, \"w\") as f:\n",
    "            f.write(\"complete\")\n",
    "        print(f\"🏁 All data fetched for {symbol}. Completion flag set.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c392adf-a674-418e-bd02-da512edc070c",
   "metadata": {},
   "source": [
    "Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fcf463cf-421e-4aa2-9570-7c89b0a57664",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🚀 Starting data collection for AAPL\n",
      "✅ AAPL already marked as complete. Skipping.\n",
      "\n",
      "🚀 Starting data collection for MSFT\n",
      "📊 Fetching MSFT data for 2018-01...\n",
      "✅ Saved MSFT data for 2018-01\n",
      "📊 Fetching MSFT data for 2018-02...\n",
      "✅ Saved MSFT data for 2018-02\n",
      "📊 Fetching MSFT data for 2018-03...\n",
      "✅ Saved MSFT data for 2018-03\n",
      "📊 Fetching MSFT data for 2018-04...\n",
      "✅ Saved MSFT data for 2018-04\n",
      "📊 Fetching MSFT data for 2018-05...\n",
      "✅ Saved MSFT data for 2018-05\n",
      "📊 Fetching MSFT data for 2018-06...\n",
      "✅ Saved MSFT data for 2018-06\n",
      "📊 Fetching MSFT data for 2018-07...\n",
      "✅ Saved MSFT data for 2018-07\n",
      "📊 Fetching MSFT data for 2018-08...\n",
      "✅ Saved MSFT data for 2018-08\n",
      "📊 Fetching MSFT data for 2018-09...\n",
      "✅ Saved MSFT data for 2018-09\n",
      "📊 Fetching MSFT data for 2018-10...\n",
      "✅ Saved MSFT data for 2018-10\n",
      "📊 Fetching MSFT data for 2018-11...\n",
      "✅ Saved MSFT data for 2018-11\n",
      "📊 Fetching MSFT data for 2018-12...\n",
      "✅ Saved MSFT data for 2018-12\n",
      "📊 Fetching MSFT data for 2019-01...\n",
      "✅ Saved MSFT data for 2019-01\n",
      "📊 Fetching MSFT data for 2019-02...\n",
      "✅ Saved MSFT data for 2019-02\n",
      "📊 Fetching MSFT data for 2019-03...\n",
      "✅ Saved MSFT data for 2019-03\n",
      "📊 Fetching MSFT data for 2019-04...\n",
      "✅ Saved MSFT data for 2019-04\n",
      "📊 Fetching MSFT data for 2019-05...\n",
      "✅ Saved MSFT data for 2019-05\n",
      "📊 Fetching MSFT data for 2019-06...\n",
      "✅ Saved MSFT data for 2019-06\n",
      "📊 Fetching MSFT data for 2019-07...\n",
      "✅ Saved MSFT data for 2019-07\n",
      "📊 Fetching MSFT data for 2019-08...\n",
      "✅ Saved MSFT data for 2019-08\n",
      "📊 Fetching MSFT data for 2019-09...\n",
      "✅ Saved MSFT data for 2019-09\n",
      "📊 Fetching MSFT data for 2019-10...\n",
      "✅ Saved MSFT data for 2019-10\n",
      "📊 Fetching MSFT data for 2019-11...\n",
      "✅ Saved MSFT data for 2019-11\n",
      "📊 Fetching MSFT data for 2019-12...\n",
      "✅ Saved MSFT data for 2019-12\n",
      "📊 Fetching MSFT data for 2020-01...\n",
      "✅ Saved MSFT data for 2020-01\n",
      "📊 Fetching MSFT data for 2020-02...\n",
      "✅ Saved MSFT data for 2020-02\n",
      "📊 Fetching MSFT data for 2020-03...\n",
      "❌ Error fetching MSFT data for 2020-03: We have detected your API key as SRKSUHDAW2DL6Y3B and our standard API rate limit is 25 requests per day. Please subscribe to any of the premium plans at https://www.alphavantage.co/premium/ to instantly remove all daily rate limits.\n",
      "⚠️ Stopping fetch for this stock. You can rerun to continue.\n",
      "\n",
      "🚀 Starting data collection for NVDA\n",
      "📊 Fetching NVDA data for 2014-01...\n",
      "❌ Error fetching NVDA data for 2014-01: We have detected your API key as SRKSUHDAW2DL6Y3B and our standard API rate limit is 25 requests per day. Please subscribe to any of the premium plans at https://www.alphavantage.co/premium/ to instantly remove all daily rate limits.\n",
      "⚠️ Stopping fetch for this stock. You can rerun to continue.\n",
      "\n",
      "🚀 Starting data collection for AMZN\n",
      "📊 Fetching AMZN data for 2014-01...\n",
      "❌ Error fetching AMZN data for 2014-01: We have detected your API key as SRKSUHDAW2DL6Y3B and our standard API rate limit is 25 requests per day. Please subscribe to any of the premium plans at https://www.alphavantage.co/premium/ to instantly remove all daily rate limits.\n",
      "⚠️ Stopping fetch for this stock. You can rerun to continue.\n",
      "\n",
      "🚀 Starting data collection for GOOGL\n",
      "📊 Fetching GOOGL data for 2014-01...\n",
      "❌ Error fetching GOOGL data for 2014-01: We have detected your API key as SRKSUHDAW2DL6Y3B and our standard API rate limit is 25 requests per day. Please subscribe to any of the premium plans at https://www.alphavantage.co/premium/ to instantly remove all daily rate limits.\n",
      "⚠️ Stopping fetch for this stock. You can rerun to continue.\n",
      "\n",
      "🚀 Starting data collection for META\n",
      "📊 Fetching META data for 2014-01...\n",
      "❌ Error fetching META data for 2014-01: We have detected your API key as SRKSUHDAW2DL6Y3B and our standard API rate limit is 25 requests per day. Please subscribe to any of the premium plans at https://www.alphavantage.co/premium/ to instantly remove all daily rate limits.\n",
      "⚠️ Stopping fetch for this stock. You can rerun to continue.\n",
      "\n",
      "🚀 Starting data collection for TSLA\n",
      "📊 Fetching TSLA data for 2014-01...\n",
      "❌ Error fetching TSLA data for 2014-01: We have detected your API key as SRKSUHDAW2DL6Y3B and our standard API rate limit is 25 requests per day. Please subscribe to any of the premium plans at https://www.alphavantage.co/premium/ to instantly remove all daily rate limits.\n",
      "⚠️ Stopping fetch for this stock. You can rerun to continue.\n",
      "\n",
      "🚀 Starting data collection for AMD\n",
      "✅ AMD already marked as complete. Skipping.\n",
      "\n",
      "🚀 Starting data collection for NFLX\n",
      "📊 Fetching NFLX data for 2014-01...\n",
      "❌ Error fetching NFLX data for 2014-01: We have detected your API key as SRKSUHDAW2DL6Y3B and our standard API rate limit is 25 requests per day. Please subscribe to any of the premium plans at https://www.alphavantage.co/premium/ to instantly remove all daily rate limits.\n",
      "⚠️ Stopping fetch for this stock. You can rerun to continue.\n",
      "\n",
      "🚀 Starting data collection for AVGO\n",
      "📊 Fetching AVGO data for 2014-01...\n",
      "❌ Error fetching AVGO data for 2014-01: We have detected your API key as SRKSUHDAW2DL6Y3B and our standard API rate limit is 25 requests per day. Please subscribe to any of the premium plans at https://www.alphavantage.co/premium/ to instantly remove all daily rate limits.\n",
      "⚠️ Stopping fetch for this stock. You can rerun to continue.\n",
      "\n",
      "✅ All stock data fetching processes completed.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "from alpha_vantage.timeseries import TimeSeries\n",
    "\n",
    "# Alpha Vantage API Key\n",
    "api_key = \"SRKSUHDAW2DL6Y3B\"\n",
    "ts = TimeSeries(key=api_key, output_format=\"pandas\")\n",
    "\n",
    "# List of stocks\n",
    "stock_list = [\"AAPL\", \"MSFT\", \"NVDA\", \"AMZN\", \"GOOGL\", \"META\", \"TSLA\", \"AMD\", \"NFLX\", \"AVGO\"]\n",
    "\n",
    "# Loop through each stock\n",
    "for symbol in stock_list:\n",
    "    print(f\"\\n🚀 Starting data collection for {symbol}\")\n",
    "\n",
    "    output_dir = f\"{symbol}_30min_data\"\n",
    "    missing_months_file = os.path.join(output_dir, \"missing_months_10yr.txt\")\n",
    "    completion_flag = os.path.join(output_dir, \"completed.flag\")\n",
    "\n",
    "    # Skip if already marked complete\n",
    "    if os.path.exists(completion_flag):\n",
    "        print(f\"✅ {symbol} already marked as complete. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    # Check if missing months file exists\n",
    "    try:\n",
    "        with open(missing_months_file, \"r\") as f:\n",
    "            months_to_fetch = f.read().splitlines()\n",
    "    except FileNotFoundError:\n",
    "        print(f\"✅ No missing months file for {symbol}. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    # Flag to detect if any errors occurred\n",
    "    error_occurred = False\n",
    "\n",
    "    # Fetch data month-by-month\n",
    "    for month in months_to_fetch:\n",
    "        output_file = os.path.join(output_dir, f\"{symbol}_30min_{month}.csv\")\n",
    "\n",
    "        try:\n",
    "            print(f\"📊 Fetching {symbol} data for {month}...\")\n",
    "\n",
    "            # Fetch data from Alpha Vantage\n",
    "            data, _ = ts.get_intraday(\n",
    "                symbol=symbol,\n",
    "                interval=\"30min\",\n",
    "                month=month,\n",
    "                adjusted=True,\n",
    "                extended_hours=False,\n",
    "                outputsize=\"full\"\n",
    "            )\n",
    "\n",
    "            # Convert index to datetime\n",
    "            data.index = pd.to_datetime(data.index)\n",
    "            data.columns = [\"Open\", \"High\", \"Low\", \"Close\", \"Volume\"]\n",
    "\n",
    "            # Save to CSV\n",
    "            data.to_csv(output_file)\n",
    "            print(f\"✅ Saved {symbol} data for {month}\")\n",
    "            time.sleep(12)  # Respect API rate limit\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error fetching {symbol} data for {month}: {e}\")\n",
    "            print(\"⚠️ Stopping fetch for this stock. You can rerun to continue.\")\n",
    "            error_occurred = True\n",
    "            break  # Stop current stock's loop\n",
    "\n",
    "    # Mark as complete if no errors\n",
    "    if not error_occurred:\n",
    "        with open(completion_flag, \"w\") as f:\n",
    "            f.write(\"complete\")\n",
    "        print(f\"🏁 All data for {symbol} fetched. Completion flag created.\")\n",
    "\n",
    "print(\"\\n✅ All stock data fetching processes completed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d2573bf-a699-46f0-bfbf-e3a88bdef2a4",
   "metadata": {},
   "source": [
    "### Merge All Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff477a26-b77c-4a85-8a2c-b1fb68aa0569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔄 Merging 30-minute data for AAPL...\n",
      "✅ Merged AAPL data saved to 30min_data\\AAPL.csv\n",
      "\n",
      "🔄 Merging 30-minute data for MSFT...\n",
      "✅ Merged MSFT data saved to 30min_data\\MSFT.csv\n",
      "\n",
      "🔄 Merging 30-minute data for NVDA...\n",
      "✅ Merged NVDA data saved to 30min_data\\NVDA.csv\n",
      "\n",
      "🔄 Merging 30-minute data for AMZN...\n",
      "✅ Merged AMZN data saved to 30min_data\\AMZN.csv\n",
      "\n",
      "🔄 Merging 30-minute data for GOOGL...\n",
      "✅ Merged GOOGL data saved to 30min_data\\GOOGL.csv\n",
      "\n",
      "🔄 Merging 30-minute data for META...\n",
      "✅ Merged META data saved to 30min_data\\META.csv\n",
      "\n",
      "🔄 Merging 30-minute data for TSLA...\n",
      "✅ Merged TSLA data saved to 30min_data\\TSLA.csv\n",
      "\n",
      "🔄 Merging 30-minute data for AMD...\n",
      "✅ Merged AMD data saved to 30min_data\\AMD.csv\n",
      "\n",
      "🔄 Merging 30-minute data for NFLX...\n",
      "✅ Merged NFLX data saved to 30min_data\\NFLX.csv\n",
      "\n",
      "🔄 Merging 30-minute data for AVGO...\n",
      "✅ Merged AVGO data saved to 30min_data\\AVGO.csv\n"
     ]
    }
   ],
   "source": [
    "# === List of all stock symbols you want to merge ===\n",
    "stock_list = [\"AAPL\", \"MSFT\", \"NVDA\", \"AMZN\", \"GOOGL\", \"META\", \"TSLA\", \"AMD\", \"NFLX\", \"AVGO\"]  # Add/remove symbols as needed\n",
    "\n",
    "# Create output directory for merged data\n",
    "output_dir = \"30min_data\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Loop through each stock symbol\n",
    "for symbol in stock_list:\n",
    "    print(f\"\\n🔄 Merging 30-minute data for {symbol}...\")\n",
    "\n",
    "    # Input directory for this stock\n",
    "    data_dir = f\"{symbol}_30min_data\"\n",
    "\n",
    "    # Find monthly CSV files\n",
    "    csv_files = [f for f in os.listdir(data_dir) if f.endswith(\".csv\") and f.startswith(f\"{symbol}_30min_\")]\n",
    "    csv_files.sort()  # Ensure chronological order\n",
    "\n",
    "    merged_df = pd.DataFrame()\n",
    "\n",
    "    # Load and concatenate each file\n",
    "    for file in csv_files:\n",
    "        file_path = os.path.join(data_dir, file)\n",
    "        df = pd.read_csv(file_path, parse_dates=[\"date\"], index_col=\"date\")\n",
    "        merged_df = pd.concat([merged_df, df])\n",
    "\n",
    "    # Sort the merged data\n",
    "    merged_df.sort_index(inplace=True)\n",
    "\n",
    "    # Save to final CSV\n",
    "    output_file = os.path.join(output_dir, f\"{symbol}.csv\")\n",
    "    merged_df.to_csv(output_file)\n",
    "\n",
    "    print(f\"✅ Merged {symbol} data saved to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3989aac2-6451-4bba-99b1-aa839f26ebf6",
   "metadata": {},
   "source": [
    "### yfinance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a86b0b-17d9-4989-9ca5-c441986e2918",
   "metadata": {},
   "source": [
    "#### Collect Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30cf5db-7f2a-4ea8-bcf9-66cf1fc934b3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define stock symbols (Choose tech stocks or other relevant ones)\n",
    "stock_symbols = [\"AAPL\", \"MSFT\", \"NVDA\", \"AMZN\", \"GOOGL\", \"META\", \"TSLA\", \"AMD\", \"NFLX\", \"AVGO\"]\n",
    "\n",
    "# Define output directory\n",
    "output_dir = \"yfinance\"\n",
    "os.makedirs(output_dir, exist_ok=True)  # Create directory if it doesn't exist\n",
    "\n",
    "# Function to fetch full historical stock data\n",
    "def fetch_full_stock_data(stock_symbol):\n",
    "    print(f\"📊 Fetching full historical data for {stock_symbol}...\")\n",
    "\n",
    "    df = yf.download(stock_symbol, start=\"1900-01-01\", interval=\"1d\")  # Fetch from the first available date\n",
    "\n",
    "    if df.empty:\n",
    "        print(f\"⚠️ No data found for {stock_symbol}!\")\n",
    "        return\n",
    "\n",
    "    # Save to CSV inside the yfinance directory\n",
    "    file_name = os.path.join(output_dir, f\"{stock_symbol}_full_history.csv\")\n",
    "    df.to_csv(file_name)\n",
    "\n",
    "    print(f\"✅ {stock_symbol} full history saved as {file_name}\")\n",
    "\n",
    "# Fetch data for all selected stocks\n",
    "for stock in stock_symbols:\n",
    "    fetch_full_stock_data(stock)\n",
    "\n",
    "print(\"📊 All stock historical data has been collected and saved in /yfinance/.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07001218-f02a-4e45-a906-527f4a9d74ae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define input and output directories\n",
    "input_dir = \"yfinance\"\n",
    "output_dir = \"cleaned_data\"\n",
    "os.makedirs(output_dir, exist_ok=True)  # Create output directory if it doesn't exist\n",
    "\n",
    "# List all CSV files in the yfinance folder\n",
    "csv_files = [f for f in os.listdir(input_dir) if f.endswith(\".csv\")]\n",
    "\n",
    "# Function to check stock data for issues\n",
    "def check_stock_data(file_path):\n",
    "    df = pd.read_csv(file_path, skiprows=2)  # Skip first two header rows\n",
    "\n",
    "    # Rename columns properly\n",
    "    df.columns = [\"Date\", \"Close\", \"High\", \"Low\", \"Open\", \"Volume\"]\n",
    "\n",
    "    # Convert Date column to datetime format\n",
    "    df[\"Date\"] = pd.to_datetime(df[\"Date\"], errors='coerce')\n",
    "\n",
    "    # Convert numeric columns to float\n",
    "    numeric_cols = [\"Close\", \"High\", \"Low\", \"Open\", \"Volume\"]\n",
    "    df[numeric_cols] = df[numeric_cols].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "    # Check for duplicates\n",
    "    duplicate_count = df.duplicated(subset=[\"Date\"]).sum()\n",
    "\n",
    "    # Check for missing values\n",
    "    missing_values = df.isnull().sum()\n",
    "\n",
    "    print(f\"\\n📊 Checking {file_path}...\")\n",
    "    print(f\"📅 Date Range: {df['Date'].min()} to {df['Date'].max()}\")\n",
    "    print(f\"🔄 Duplicate Dates: {duplicate_count}\")\n",
    "    print(\"❗ Missing Values Per Column:\\n\", missing_values)\n",
    "\n",
    "    return df, duplicate_count, missing_values\n",
    "\n",
    "# Function to clean and save stock data\n",
    "def clean_stock_data(df, output_path):\n",
    "    # Sort by date\n",
    "    df.sort_values(by=\"Date\", ascending=True, inplace=True)\n",
    "\n",
    "    # Save the cleaned file without dropping duplicates/missing values\n",
    "    df.to_csv(output_path, index=False)\n",
    "    print(f\"✅ Cleaned data saved as: {output_path}\")\n",
    "\n",
    "# Process all CSV files in yfinance directory\n",
    "for file in csv_files:\n",
    "    input_file_path = os.path.join(input_dir, file)\n",
    "    output_file_path = os.path.join(output_dir, file.replace(\".csv\", \"_cleaned.csv\"))\n",
    "    \n",
    "    df, duplicate_count, missing_values = check_stock_data(input_file_path)\n",
    "    \n",
    "    # Only save the cleaned file (without dropping data)\n",
    "    clean_stock_data(df, output_file_path)\n",
    "\n",
    "print(\"\\n✅ All stock data has been checked and saved in the 'cleaned_data/' folder.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d6d1ac-c3bf-4364-b169-d73d331b4822",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b26d9ac-8039-4532-8898-32cd4968a16b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d001b954-7f6b-449f-b1cc-2e4ada7b9071",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "124c7652-3b4c-417e-9557-63db46968e11",
   "metadata": {},
   "source": [
    "#### Avoid this first Check Missing Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d92dab2d-d813-48f1-a2e9-8dfdc0d21a7b",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'AAPL_historical_data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAAPL_historical_data.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# Replace with any stock CSV file\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(df\u001b[38;5;241m.\u001b[39minfo())  \u001b[38;5;66;03m# Check data types and missing values\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(df\u001b[38;5;241m.\u001b[39mhead())\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\FYP\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\FYP\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\FYP\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\FYP\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1881\u001b[0m     f,\n\u001b[0;32m   1882\u001b[0m     mode,\n\u001b[0;32m   1883\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1884\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1885\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m   1886\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[0;32m   1887\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1888\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1889\u001b[0m )\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\FYP\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    874\u001b[0m             handle,\n\u001b[0;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    876\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    877\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    879\u001b[0m         )\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'AAPL_historical_data.csv'"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"AAPL_historical_data.csv\")  # Replace with any stock CSV file\n",
    "print(df.info())  # Check data types and missing values\n",
    "print(df.head())  # Preview first few rows\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "330a2118-505f-4d74-98ca-74a61ab73595",
   "metadata": {},
   "source": [
    "## News Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86c110e9-5b50-41ad-858d-66a9290ab827",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "News data collected and saved to 'tech_stock_news.csv'.\n"
     ]
    }
   ],
   "source": [
    "# Your NewsAPI Key\n",
    "api_key = \"31dbe344e851496e950dc899ab1d0e93\"\n",
    "\n",
    "# List of tech stocks to search for\n",
    "tech_stocks = [\"Apple\", \"Microsoft\", \"Nvidia\", \"Amazon\", \"Google\", \"Meta\", \"Tesla\", \"AMD\", \"Netflix\", \"Broadcom\"]\n",
    "\n",
    "# Date range for news (last 7 days)\n",
    "end_date = datetime.today().strftime('%Y-%m-%d')\n",
    "start_date = (datetime.today() - timedelta(days=7)).strftime('%Y-%m-%d')\n",
    "\n",
    "# Function to fetch news for each stock\n",
    "def fetch_news(stock):\n",
    "    url = f\"https://newsapi.org/v2/everything?q={stock}&language=en&from={start_date}&to={end_date}&sortBy=publishedAt&apiKey={api_key}\"\n",
    "    response = requests.get(url)\n",
    "    return response.json()\n",
    "\n",
    "# Collect news for all stocks\n",
    "news_data = []\n",
    "for stock in tech_stocks:\n",
    "    data = fetch_news(stock)\n",
    "    if \"articles\" in data:\n",
    "        for article in data[\"articles\"]:\n",
    "            news_data.append({\n",
    "                \"Stock\": stock,\n",
    "                \"Title\": article[\"title\"],\n",
    "                \"content\": article[\"content\"],\n",
    "                \"Source\": article[\"source\"][\"name\"],\n",
    "                \"Published At\": article[\"publishedAt\"],\n",
    "                \"URL\": article[\"url\"]\n",
    "            })\n",
    "\n",
    "# Convert to DataFrame\n",
    "df_news = pd.DataFrame(news_data)\n",
    "\n",
    "# Save to CSV\n",
    "df_news.to_csv(\"tech_stock_news.csv\", index=False)\n",
    "\n",
    "print(\"News data collected and saved to 'tech_stock_news.csv'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9691011a-fe2f-4147-b2ff-b971f9bd5c2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Stock                                              Title  \\\n",
      "0  Apple        Veronica Mars Season 1-4 $4.99 via Apple TV   \n",
      "1  Apple  Protecting your iCloud data after Apple’s Adva...   \n",
      "2  Apple  Praying through Weaknesses as a Couple - Cross...   \n",
      "3  Apple  This hybrid smartwatch finally convinced me to...   \n",
      "4  Apple  Apple's New Passwords App Left Users Exposed T...   \n",
      "\n",
      "                                             content             Source  \\\n",
      "0  This collaborative space allows users to contr...     Slickdeals.net   \n",
      "1  Advanced Data Protection (ADP) secures iCloud ...  Help Net Security   \n",
      "2  Praying through Weaknesses as a CoupleBy Lynet...      Crosswalk.com   \n",
      "3  I used dozens of Wear OS smartwatches over the...    Android Central   \n",
      "4  Security researchers found that the Passwords ...         Biztoc.com   \n",
      "\n",
      "           Published At                                                URL  \n",
      "0  2025-03-19T05:01:02Z  https://slickdeals.net/f/18188056-veronica-mar...  \n",
      "1  2025-03-19T05:00:37Z  https://www.helpnetsecurity.com/2025/03/19/pro...  \n",
      "2  2025-03-19T05:00:00Z  https://www.crosswalk.com/devotionals/crosswal...  \n",
      "3  2025-03-19T04:48:02Z  https://www.androidcentral.com/wearables/withi...  \n",
      "4  2025-03-19T04:47:36Z              https://biztoc.com/x/257dd0a34ee8f6de  \n"
     ]
    }
   ],
   "source": [
    "# Load the collected news data\n",
    "df_news = pd.read_csv(\"tech_stock_news.csv\")\n",
    "\n",
    "# Display first few rows\n",
    "print(df_news.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91525d5b-37da-426d-9be9-7e3037522475",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "34f9bbc3-2532-4dc1-93b5-f2148c1a4bb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data cleaned and saved.\n"
     ]
    }
   ],
   "source": [
    "def clean_text(text):\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    text = re.sub(r'\\s+', ' ', text)  # Remove extra spaces\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n",
    "    text = text.strip()  # Remove leading/trailing spaces\n",
    "    return text\n",
    "\n",
    "# Apply cleaning\n",
    "df_news[\"Cleaned_Title\"] = df_news[\"Title\"].apply(clean_text)\n",
    "\n",
    "# Save cleaned data\n",
    "df_news.to_csv(\"cleaned_tech_stock_news1.csv\", index=False)\n",
    "\n",
    "print(\"Data cleaned and saved.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca1e3900-361b-408d-b701-123485429416",
   "metadata": {},
   "source": [
    "# Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ef9982-21a0-4f33-be86-0fb25f5067cf",
   "metadata": {},
   "source": [
    "## FinBERT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0f1c7325-9cd2-42aa-9dc9-cd634997ee4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load FinBERT tokenizer & model\n",
    "tokenizer = BertTokenizer.from_pretrained(\"yiyanghkust/finbert-tone\")\n",
    "model = BertForSequenceClassification.from_pretrained(\"yiyanghkust/finbert-tone\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0105c8e7-83e2-4c46-b1d9-2430b70ae25d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment: Neutral\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def predict_sentiment(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=512)\n",
    "    outputs = model(**inputs)\n",
    "    probs = F.softmax(outputs.logits, dim=-1)\n",
    "\n",
    "    # Labels: 0 = Negative, 1 = Neutral, 2 = Positive\n",
    "    labels = [\"Negative\", \"Neutral\", \"Positive\"]\n",
    "    sentiment = labels[torch.argmax(probs).item()]\n",
    "    \n",
    "    return sentiment\n",
    "\n",
    "# Test on an example headline\n",
    "example_headline = \"Apple stock soars as earnings beat expectations\"\n",
    "print(f\"Sentiment: {predict_sentiment(example_headline)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b7d7e2fe-9262-4495-b15b-b81424125fe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Removed invalid rows. Remaining data: 986 rows.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load dataset\n",
    "df_news = pd.read_csv(\"cleaned_tech_stock_news1.csv\")\n",
    "\n",
    "# Remove rows where \"Cleaned_Title\" is NaN or not a string\n",
    "df_news = df_news.dropna(subset=[\"Cleaned_Title\"])  # Drop missing values\n",
    "df_news = df_news[df_news[\"Cleaned_Title\"].apply(lambda x: isinstance(x, str))]  # Keep only string values\n",
    "\n",
    "# Save cleaned dataset\n",
    "df_news.to_csv(\"cleaned_tech_stock_news_filtered.csv\", index=False)\n",
    "\n",
    "print(f\"✅ Removed invalid rows. Remaining data: {len(df_news)} rows.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d430b25c-e584-4256-ba41-cf46bcc255ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Removed non-English titles. Remaining rows: 894\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from langdetect import detect\n",
    "\n",
    "# Load dataset\n",
    "df_news = pd.read_csv(\"cleaned_tech_stock_news1.csv\")\n",
    "\n",
    "# Function to detect language\n",
    "def is_english(text):\n",
    "    try:\n",
    "        return detect(text) == \"en\"  # Keep only English text\n",
    "    except:\n",
    "        return False  # If detection fails, remove the row\n",
    "\n",
    "# Apply language filter\n",
    "df_news = df_news[df_news[\"Cleaned_Title\"].apply(is_english)]\n",
    "\n",
    "# Save cleaned dataset\n",
    "df_news.to_csv(\"cleaned_tech_stock_news_english.csv\", index=False)\n",
    "\n",
    "print(f\"✅ Removed non-English titles. Remaining rows: {len(df_news)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cb9455d7-6c7f-49a6-a38b-8110bca72520",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment analysis complete. Results saved.\n"
     ]
    }
   ],
   "source": [
    "df_news = pd.read_csv(\"cleaned_tech_stock_news_filtered.csv\")\n",
    "\n",
    "# Apply sentiment analysis to each headline\n",
    "df_news[\"Sentiment\"] = df_news[\"Cleaned_Title\"].apply(predict_sentiment)\n",
    "\n",
    "# Save results\n",
    "df_news.to_csv(\"news_sentiment_analysis1.csv\", index=False)\n",
    "\n",
    "print(\"Sentiment analysis complete. Results saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4b666c7b-d058-4274-b5b9-43620e3a0cc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment\n",
      "Negative    723\n",
      "Neutral     150\n",
      "Positive    113\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset with sentiment analysis results\n",
    "df_news = pd.read_csv(\"news_sentiment_analysis1.csv\")\n",
    "\n",
    "# Count the occurrences of each sentiment category\n",
    "sentiment_counts = df_news[\"Sentiment\"].value_counts()\n",
    "\n",
    "# Display results\n",
    "print(sentiment_counts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f54411f-100c-4b2b-9633-7cd5bf7eb9b9",
   "metadata": {},
   "source": [
    "# Chart Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58a8d5b-50e6-4988-89a3-bda7b1983f8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e8dd2899-7026-4e28-b028-2a4b57767e7f",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "727fb073-a8f9-46b7-bcfe-a49885ff11ab",
   "metadata": {},
   "source": [
    "## Add Indicator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c64e17af-4b14-47d2-9a92-d24f3ad11b13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Processing indicators for AAPL...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sheng\\anaconda3\\envs\\FYP\\Lib\\site-packages\\ta\\trend.py:1030: FutureWarning: Series.__setitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To set a value by position, use `ser.iloc[pos] = value`\n",
      "  self._psar[i] = high2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved: lstm_input\\AAPL_with_indicators.csv\n",
      "📊 Processing indicators for MSFT...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sheng\\anaconda3\\envs\\FYP\\Lib\\site-packages\\ta\\trend.py:1030: FutureWarning: Series.__setitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To set a value by position, use `ser.iloc[pos] = value`\n",
      "  self._psar[i] = high2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved: lstm_input\\MSFT_with_indicators.csv\n",
      "📊 Processing indicators for NVDA...\n",
      "❌ Error processing NVDA: Missing column provided to 'parse_dates': 'date'\n",
      "📊 Processing indicators for AMZN...\n",
      "❌ Error processing AMZN: Missing column provided to 'parse_dates': 'date'\n",
      "📊 Processing indicators for GOOGL...\n",
      "❌ Error processing GOOGL: Missing column provided to 'parse_dates': 'date'\n",
      "📊 Processing indicators for META...\n",
      "❌ Error processing META: Missing column provided to 'parse_dates': 'date'\n",
      "📊 Processing indicators for TSLA...\n",
      "❌ Error processing TSLA: Missing column provided to 'parse_dates': 'date'\n",
      "📊 Processing indicators for AMD...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sheng\\anaconda3\\envs\\FYP\\Lib\\site-packages\\ta\\trend.py:1030: FutureWarning: Series.__setitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To set a value by position, use `ser.iloc[pos] = value`\n",
      "  self._psar[i] = high2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved: lstm_input\\AMD_with_indicators.csv\n",
      "📊 Processing indicators for NFLX...\n",
      "❌ Error processing NFLX: Missing column provided to 'parse_dates': 'date'\n",
      "📊 Processing indicators for AVGO...\n",
      "❌ Error processing AVGO: Missing column provided to 'parse_dates': 'date'\n",
      "🎯 All stock indicators processed.\n"
     ]
    }
   ],
   "source": [
    "# List of stock symbols\n",
    "stock_list = [\"AAPL\", \"MSFT\", \"NVDA\", \"AMZN\", \"GOOGL\", \"META\", \"TSLA\", \"AMD\", \"NFLX\", \"AVGO\"]\n",
    "\n",
    "# Input and output folders\n",
    "input_dir = \"30min_data\"\n",
    "output_dir = \"lstm_input\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Loop through each stock\n",
    "for symbol in stock_list:\n",
    "    input_file = os.path.join(input_dir, f\"{symbol}.csv\")\n",
    "    output_file = os.path.join(output_dir, f\"{symbol}_with_indicators.csv\")\n",
    "\n",
    "    # Check if file exists\n",
    "    if not os.path.exists(input_file):\n",
    "        print(f\"❌ Skipping {symbol}: Data file not found.\")\n",
    "        continue\n",
    "\n",
    "    print(f\"📊 Processing indicators for {symbol}...\")\n",
    "\n",
    "    try:\n",
    "        # Load data\n",
    "        df = pd.read_csv(input_file, parse_dates=[\"date\"], index_col=\"date\")\n",
    "\n",
    "        # Drop missing values (optional, can be replaced with fillna)\n",
    "        df.dropna(inplace=True)\n",
    "\n",
    "        # Add all TA indicators\n",
    "        df = ta.add_all_ta_features(\n",
    "            df,\n",
    "            open=\"Open\",\n",
    "            high=\"High\",\n",
    "            low=\"Low\",\n",
    "            close=\"Close\",\n",
    "            volume=\"Volume\",\n",
    "            fillna=True\n",
    "        )\n",
    "\n",
    "        # Save result\n",
    "        df.to_csv(output_file)\n",
    "        print(f\"✅ Saved: {output_file}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error processing {symbol}: {e}\")\n",
    "\n",
    "print(\"🎯 All stock indicators processed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9737abb5-c14b-4d10-85f0-908f216e9abf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Open', 'High', 'Low', 'Close', 'Volume', 'volume_adi', 'volume_obv',\n",
      "       'volume_cmf', 'volume_fi', 'volume_em', 'volume_sma_em', 'volume_vpt',\n",
      "       'volume_vwap', 'volume_mfi', 'volume_nvi', 'volatility_bbm',\n",
      "       'volatility_bbh', 'volatility_bbl', 'volatility_bbw', 'volatility_bbp',\n",
      "       'volatility_bbhi', 'volatility_bbli', 'volatility_kcc',\n",
      "       'volatility_kch', 'volatility_kcl', 'volatility_kcw', 'volatility_kcp',\n",
      "       'volatility_kchi', 'volatility_kcli', 'volatility_dcl',\n",
      "       'volatility_dch', 'volatility_dcm', 'volatility_dcw', 'volatility_dcp',\n",
      "       'volatility_atr', 'volatility_ui', 'trend_macd', 'trend_macd_signal',\n",
      "       'trend_macd_diff', 'trend_sma_fast', 'trend_sma_slow', 'trend_ema_fast',\n",
      "       'trend_ema_slow', 'trend_vortex_ind_pos', 'trend_vortex_ind_neg',\n",
      "       'trend_vortex_ind_diff', 'trend_trix', 'trend_mass_index', 'trend_dpo',\n",
      "       'trend_kst', 'trend_kst_sig', 'trend_kst_diff', 'trend_ichimoku_conv',\n",
      "       'trend_ichimoku_base', 'trend_ichimoku_a', 'trend_ichimoku_b',\n",
      "       'trend_stc', 'trend_adx', 'trend_adx_pos', 'trend_adx_neg', 'trend_cci',\n",
      "       'trend_visual_ichimoku_a', 'trend_visual_ichimoku_b', 'trend_aroon_up',\n",
      "       'trend_aroon_down', 'trend_aroon_ind', 'trend_psar_up',\n",
      "       'trend_psar_down', 'trend_psar_up_indicator',\n",
      "       'trend_psar_down_indicator', 'momentum_rsi', 'momentum_stoch_rsi',\n",
      "       'momentum_stoch_rsi_k', 'momentum_stoch_rsi_d', 'momentum_tsi',\n",
      "       'momentum_uo', 'momentum_stoch', 'momentum_stoch_signal', 'momentum_wr',\n",
      "       'momentum_ao', 'momentum_roc', 'momentum_ppo', 'momentum_ppo_signal',\n",
      "       'momentum_ppo_hist', 'momentum_pvo', 'momentum_pvo_signal',\n",
      "       'momentum_pvo_hist', 'momentum_kama', 'others_dr', 'others_dlr',\n",
      "       'others_cr'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "603bcb3c-6ba9-44d0-8689-730f335e3cf1",
   "metadata": {},
   "source": [
    "## Add Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "58d9f959-a932-4f35-b883-bf83a0f8975e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target\n",
      "0    43943\n",
      "1    43274\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your indicator-enriched data\n",
    "df = pd.read_csv(\"lstm_input/AAPL_with_indicators.csv\", parse_dates=[\"date\"], index_col=\"date\")\n",
    "\n",
    "# Create binary target based on next day's close price\n",
    "df[\"Target\"] = (df[\"Close\"].shift(-1) > df[\"Close\"]).astype(int)\n",
    "\n",
    "# Drop the last row (no label because of .shift(-1))\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Optional: Check label distribution\n",
    "print(df[\"Target\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ca2455-7121-4577-bbd8-7ba92dec6f90",
   "metadata": {},
   "source": [
    "## MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c43b0f62-203b-4c6d-8e48-57c33b94b84c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         Open      High       Low     Close    Volume  \\\n",
      "date                                                                    \n",
      "2014-01-02 04:00:00  0.007498  0.007322  0.007661  0.007818  0.000405   \n",
      "2014-01-02 04:30:00  0.007817  0.007286  0.007962  0.007795  0.000050   \n",
      "2014-01-02 05:00:00  0.007727  0.007199  0.007790  0.007623  0.000025   \n",
      "2014-01-02 05:30:00  0.007619  0.007132  0.007782  0.007651  0.000042   \n",
      "2014-01-02 06:00:00  0.007830  0.007310  0.007852  0.007685  0.000178   \n",
      "\n",
      "                     volume_adi  volume_obv  volume_cmf  volume_fi  volume_em  \\\n",
      "date                                                                            \n",
      "2014-01-02 04:00:00    0.018454    0.057775    0.919694   0.633601   0.825245   \n",
      "2014-01-02 04:30:00    0.018453    0.057773    0.814953   0.633600   0.825245   \n",
      "2014-01-02 05:00:00    0.018453    0.057772    0.770817   0.633599   0.825244   \n",
      "2014-01-02 05:30:00    0.018454    0.057773    0.790566   0.633600   0.825245   \n",
      "2014-01-02 06:00:00    0.018449    0.057780    0.582218   0.633601   0.825245   \n",
      "\n",
      "                     ...  momentum_ppo_signal  momentum_ppo_hist  \\\n",
      "date                 ...                                           \n",
      "2014-01-02 04:00:00  ...             0.564300           0.538748   \n",
      "2014-01-02 04:30:00  ...             0.564178           0.537900   \n",
      "2014-01-02 05:00:00  ...             0.563075           0.531054   \n",
      "2014-01-02 05:30:00  ...             0.561564           0.528214   \n",
      "2014-01-02 06:00:00  ...             0.560065           0.528301   \n",
      "\n",
      "                     momentum_pvo  momentum_pvo_signal  momentum_pvo_hist  \\\n",
      "date                                                                        \n",
      "2014-01-02 04:00:00      0.429115             0.526461           0.222207   \n",
      "2014-01-02 04:30:00      0.387080             0.514742           0.176749   \n",
      "2014-01-02 05:00:00      0.345886             0.493881           0.141290   \n",
      "2014-01-02 05:30:00      0.311467             0.467596           0.120251   \n",
      "2014-01-02 06:00:00      0.304797             0.444708           0.133428   \n",
      "\n",
      "                     momentum_kama  others_dr  others_dlr  others_cr  Target  \n",
      "date                                                                          \n",
      "2014-01-02 04:00:00       0.007554   0.493712    0.515492   0.007818       0  \n",
      "2014-01-02 04:30:00       0.007544   0.491854    0.513636   0.007795       0  \n",
      "2014-01-02 05:00:00       0.007461   0.479768    0.501551   0.007623       1  \n",
      "2014-01-02 05:30:00       0.007428   0.495975    0.517751   0.007651       1  \n",
      "2014-01-02 06:00:00       0.007425   0.496507    0.518282   0.007685       1  \n",
      "\n",
      "[5 rows x 92 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Separate features and target\n",
    "features = df.drop(columns=[\"Target\"])\n",
    "target = df[\"Target\"]\n",
    "\n",
    "# Initialize scaler and scale features\n",
    "scaler = MinMaxScaler()\n",
    "scaled_features = scaler.fit_transform(features)\n",
    "\n",
    "# Convert scaled features back to DataFrame\n",
    "df_scaled = pd.DataFrame(scaled_features, columns=features.columns, index=features.index)\n",
    "\n",
    "# Add the target column back\n",
    "df_scaled[\"Target\"] = target.values\n",
    "\n",
    "# Check the result\n",
    "print(df_scaled.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3738ebf8-6d06-4a0e-976d-6373adeef587",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ X shape: (87187, 30, 91)\n",
      "✅ y shape: (87187,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Convert to NumPy array\n",
    "data = df_scaled.values\n",
    "\n",
    "# Define time step window size\n",
    "time_steps = 30\n",
    "\n",
    "# Create sequences\n",
    "X, y = [], []\n",
    "for i in range(time_steps, len(data)):\n",
    "    X.append(data[i-time_steps:i, :-1])  # all features except Target\n",
    "    y.append(data[i, -1])                # only the Target column\n",
    "\n",
    "# Convert to arrays\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "print(f\"✅ X shape: {X.shape}\")  # (samples, time_steps, features)\n",
    "print(f\"✅ y shape: {y.shape}\")  # (samples,)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caee93ae-9783-4585-97a5-52defebcb4dc",
   "metadata": {},
   "source": [
    "## Train Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bc73845b-b659-4f6d-965b-fdf09f32037d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧪 Train samples: 69749\n",
      "🧪 Test samples: 17438\n"
     ]
    }
   ],
   "source": [
    "# Choose a split ratio\n",
    "train_size = int(len(X) * 0.8)\n",
    "\n",
    "# Split the sequences\n",
    "X_train, X_test = X[:train_size], X[train_size:]\n",
    "y_train, y_test = y[:train_size], y[train_size:]\n",
    "\n",
    "print(f\"🧪 Train samples: {X_train.shape[0]}\")\n",
    "print(f\"🧪 Test samples: {X_test.shape[0]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec31e546-6399-4c1b-9732-c029342ea29b",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "84380dc4-7df4-4b32-bb00-0a1e414d0275",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sheng\\anaconda3\\envs\\FYP\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m1090/1090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 12ms/step - accuracy: 0.5055 - loss: 0.6944 - val_accuracy: 0.5053 - val_loss: 0.6931\n",
      "Epoch 2/20\n",
      "\u001b[1m1090/1090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.5055 - loss: 0.6932 - val_accuracy: 0.4981 - val_loss: 0.6932\n",
      "Epoch 3/20\n",
      "\u001b[1m1090/1090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.5045 - loss: 0.6931 - val_accuracy: 0.4981 - val_loss: 0.6932\n",
      "Epoch 4/20\n",
      "\u001b[1m1090/1090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.5022 - loss: 0.6932 - val_accuracy: 0.4981 - val_loss: 0.6933\n",
      "Epoch 5/20\n",
      "\u001b[1m1090/1090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.5018 - loss: 0.6932 - val_accuracy: 0.4981 - val_loss: 0.6932\n",
      "Epoch 6/20\n",
      "\u001b[1m1090/1090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.5031 - loss: 0.6932 - val_accuracy: 0.4981 - val_loss: 0.6933\n",
      "Epoch 7/20\n",
      "\u001b[1m1090/1090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.5072 - loss: 0.6931 - val_accuracy: 0.5014 - val_loss: 0.6931\n",
      "Epoch 8/20\n",
      "\u001b[1m1090/1090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 11ms/step - accuracy: 0.5063 - loss: 0.6930 - val_accuracy: 0.4980 - val_loss: 0.6932\n",
      "Epoch 9/20\n",
      "\u001b[1m1090/1090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.5072 - loss: 0.6930 - val_accuracy: 0.5042 - val_loss: 0.6931\n",
      "Epoch 10/20\n",
      "\u001b[1m1090/1090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.5035 - loss: 0.6931 - val_accuracy: 0.4981 - val_loss: 0.6934\n",
      "Epoch 11/20\n",
      "\u001b[1m1090/1090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.5123 - loss: 0.6928 - val_accuracy: 0.4980 - val_loss: 0.6933\n",
      "Epoch 12/20\n",
      "\u001b[1m1090/1090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.5065 - loss: 0.6930 - val_accuracy: 0.5056 - val_loss: 0.6931\n",
      "Epoch 13/20\n",
      "\u001b[1m1090/1090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.5158 - loss: 0.6927 - val_accuracy: 0.4987 - val_loss: 0.6932\n",
      "Epoch 14/20\n",
      "\u001b[1m1090/1090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.5100 - loss: 0.6928 - val_accuracy: 0.5040 - val_loss: 0.6931\n",
      "Epoch 15/20\n",
      "\u001b[1m1090/1090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.5068 - loss: 0.6928 - val_accuracy: 0.5004 - val_loss: 0.6931\n",
      "Epoch 16/20\n",
      "\u001b[1m1090/1090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.5129 - loss: 0.6926 - val_accuracy: 0.4995 - val_loss: 0.6932\n",
      "Epoch 17/20\n",
      "\u001b[1m1090/1090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.5118 - loss: 0.6927 - val_accuracy: 0.5011 - val_loss: 0.6931\n",
      "Epoch 18/20\n",
      "\u001b[1m1090/1090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.5140 - loss: 0.6926 - val_accuracy: 0.5010 - val_loss: 0.6934\n",
      "Epoch 19/20\n",
      "\u001b[1m1090/1090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.5132 - loss: 0.6924 - val_accuracy: 0.5056 - val_loss: 0.6932\n",
      "Epoch 20/20\n",
      "\u001b[1m1090/1090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.5141 - loss: 0.6926 - val_accuracy: 0.4993 - val_loss: 0.6944\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Define the model\n",
    "model = Sequential([\n",
    "    LSTM(64, return_sequences=False, input_shape=(X_train.shape[1], X_train.shape[2])),\n",
    "    Dropout(0.2),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(1, activation='sigmoid')  # Binary classification\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer=Adam(learning_rate=0.001),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=20,\n",
    "    batch_size=64,\n",
    "    validation_data=(X_test, y_test),\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0021d65f-3057-414a-8b4c-ce0b7969cfb7",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a5e25595-8eed-4004-8c6a-f07d120a9846",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m545/545\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step\n",
      "✅ Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.50      0.94      0.65      8685\n",
      "         1.0       0.51      0.06      0.11      8753\n",
      "\n",
      "    accuracy                           0.50     17438\n",
      "   macro avg       0.50      0.50      0.38     17438\n",
      "weighted avg       0.50      0.50      0.38     17438\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sheng\\anaconda3\\envs\\FYP\\Lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 128202 (\\N{BAR CHART}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Predict probabilities\n",
    "y_pred_probs = model.predict(X_test)\n",
    "\n",
    "# Convert probabilities to binary classes (0 or 1)\n",
    "y_pred = (y_pred_probs > 0.5).astype(int).flatten()\n",
    "\n",
    "# Evaluate\n",
    "print(\"✅ Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(5, 4))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[\"Down\", \"Up\"], yticklabels=[\"Down\", \"Up\"])\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(\"📊 Confusion Matrix\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1e0e71-dfbc-4b8f-bc56-f973c5d08f1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
